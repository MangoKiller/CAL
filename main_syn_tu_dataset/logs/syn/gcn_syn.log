step_size..................................................................0.001
min_lr.....................................................................5e-06
pretrain......................................................................30
data_num....................................................................2000
node_num......................................................................15
max_degree....................................................................10
feature_dim...................................................................-1
noise........................................................................0.1
num_classes....................................................................4
shape_num......................................................................1
bias.........................................................................0.1
penalty_weight...............................................................0.1
train_type..................................................................base
epochs.......................................................................100
batch_size...................................................................128
the............................................................................0
with_random.................................................................True
eval_random................................................................False
normalize..................................................................False
save_model.................................................................False
inference..................................................................False
without_node_attention.....................................................False
without_edge_attention.....................................................False
k..............................................................................3
layers.........................................................................3
c............................................................................0.5
o............................................................................1.0
co...........................................................................0.5
harf_hidden..................................................................0.5
cat_or_add...................................................................add
num_layers.....................................................................3
folds.........................................................................10
fc_num.......................................................................222
data_root...................................................................data
save_dir...................................................................debug
dataset.....................................................................NCI1
epoch_select............................................................test_max
model........................................................................GCN
hidden.......................................................................128
seed.........................................................................666
lr.........................................................................0.002
lr_decay_factor..............................................................0.5
lr_decay_step_size...........................................................500
weight_decay...................................................................0
global_pool..................................................................sum

----------------------------------------------------------------------------------------------------
| graph: Tree-house | nodes num:246 | edges num:542 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: BA-house | nodes num:230 | edges num:996 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: Tree-cycle | nodes num:247 | edges num:542 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: BA-cycle | nodes num:231 | edges num:996 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: Tree-grid | nodes num:247 | edges num:544 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: BA-grid | nodes num:231 | edges num:998 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: Tree-diamond | nodes num:247 | edges num:546 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: BA-diamond | nodes num:231 | edges num:1000 |
----------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
Train Total:5597
| Tree: House:140  , Cycle:1260 , Grids:1260 , Diams:1260  
| BA  : House:1260 , Cycle:139  , Grids:139  , Diams:139   
| All : House:1400 , Cycle:1399 , Grids:1399 , Diams:1399  
| BIAS: House:10.0%, Cycle:90.1%, Grids:90.1%, Diams:90.1%
------------------------------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
Val    Total:797
| Tree: House:20   , Cycle:180  , Grids:180  , Diams:180   
| BA  : House:180  , Cycle:19   , Grids:19   , Diams:19    
| All : House:200  , Cycle:199  , Grids:199  , Diams:199   
| BIAS: House:10.0%, Cycle:90.5%, Grids:90.5%, Diams:90.5%
------------------------------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
Test   Total:1600
| Tree: House:200  , Cycle:200  , Grids:200  , Diams:200   
| BA  : House:200  , Cycle:200  , Grids:200  , Diams:200   
| All : House:400  , Cycle:400  , Grids:400  , Diams:400   
| BIAS: House:50.0%, Cycle:50.0%, Grids:50.0%, Diams:50.0%
------------------------------------------------------------------------------------------------------------------------------------------------------
BIAS:[0.10] | Model:[GCN] Epoch:[1/100] Loss:[0.5620] Train:[81.85] val:[56.34] Test:[32.88] | Best Val:[56.34] Update Test:[32.88] at Epoch:[1] | lr:0.002000
BIAS:[0.10] | Model:[GCN] Epoch:[2/100] Loss:[0.3189] Train:[89.42] val:[86.95] Test:[72.25] | Best Val:[86.95] Update Test:[72.25] at Epoch:[2] | lr:0.001998
BIAS:[0.10] | Model:[GCN] Epoch:[3/100] Loss:[0.2746] Train:[90.96] val:[90.97] Test:[67.31] | Best Val:[90.97] Update Test:[67.31] at Epoch:[3] | lr:0.001996
BIAS:[0.10] | Model:[GCN] Epoch:[4/100] Loss:[0.2158] Train:[92.87] val:[93.10] Test:[79.00] | Best Val:[93.10] Update Test:[79.00] at Epoch:[4] | lr:0.001992
BIAS:[0.10] | Model:[GCN] Epoch:[5/100] Loss:[0.2094] Train:[92.80] val:[90.21] Test:[61.88] | Best Val:[93.10] Update Test:[79.00] at Epoch:[4] | lr:0.001988
BIAS:[0.10] | Model:[GCN] Epoch:[6/100] Loss:[0.1900] Train:[93.69] val:[92.10] Test:[71.56] | Best Val:[93.10] Update Test:[79.00] at Epoch:[4] | lr:0.001982
BIAS:[0.10] | Model:[GCN] Epoch:[7/100] Loss:[0.1854] Train:[94.25] val:[93.73] Test:[73.69] | Best Val:[93.73] Update Test:[73.69] at Epoch:[7] | lr:0.001976
BIAS:[0.10] | Model:[GCN] Epoch:[8/100] Loss:[0.1860] Train:[93.96] val:[94.48] Test:[74.94] | Best Val:[94.48] Update Test:[74.94] at Epoch:[8] | lr:0.001969
BIAS:[0.10] | Model:[GCN] Epoch:[9/100] Loss:[0.1840] Train:[94.01] val:[94.35] Test:[77.56] | Best Val:[94.48] Update Test:[74.94] at Epoch:[8] | lr:0.001960
BIAS:[0.10] | Model:[GCN] Epoch:[10/100] Loss:[0.1909] Train:[93.76] val:[92.60] Test:[68.56] | Best Val:[94.48] Update Test:[74.94] at Epoch:[8] | lr:0.001951
BIAS:[0.10] | Model:[GCN] Epoch:[11/100] Loss:[0.1710] Train:[94.71] val:[89.59] Test:[74.38] | Best Val:[94.48] Update Test:[74.94] at Epoch:[8] | lr:0.001941
BIAS:[0.10] | Model:[GCN] Epoch:[12/100] Loss:[0.1674] Train:[94.57] val:[94.60] Test:[78.62] | Best Val:[94.60] Update Test:[78.62] at Epoch:[12] | lr:0.001930
BIAS:[0.10] | Model:[GCN] Epoch:[13/100] Loss:[0.1521] Train:[95.09] val:[94.73] Test:[79.12] | Best Val:[94.73] Update Test:[79.12] at Epoch:[13] | lr:0.001918
BIAS:[0.10] | Model:[GCN] Epoch:[14/100] Loss:[0.1433] Train:[95.34] val:[94.10] Test:[83.12] | Best Val:[94.73] Update Test:[79.12] at Epoch:[13] | lr:0.001905
BIAS:[0.10] | Model:[GCN] Epoch:[15/100] Loss:[0.1454] Train:[95.39] val:[95.23] Test:[80.50] | Best Val:[95.23] Update Test:[80.50] at Epoch:[15] | lr:0.001891
BIAS:[0.10] | Model:[GCN] Epoch:[16/100] Loss:[0.1404] Train:[95.53] val:[94.23] Test:[77.19] | Best Val:[95.23] Update Test:[80.50] at Epoch:[15] | lr:0.001877
BIAS:[0.10] | Model:[GCN] Epoch:[17/100] Loss:[0.1481] Train:[95.12] val:[94.48] Test:[76.56] | Best Val:[95.23] Update Test:[80.50] at Epoch:[15] | lr:0.001861
BIAS:[0.10] | Model:[GCN] Epoch:[18/100] Loss:[0.1804] Train:[94.34] val:[94.60] Test:[79.69] | Best Val:[95.23] Update Test:[80.50] at Epoch:[15] | lr:0.001845
BIAS:[0.10] | Model:[GCN] Epoch:[19/100] Loss:[0.1532] Train:[94.94] val:[93.60] Test:[80.94] | Best Val:[95.23] Update Test:[80.50] at Epoch:[15] | lr:0.001828
BIAS:[0.10] | Model:[GCN] Epoch:[20/100] Loss:[0.1399] Train:[95.77] val:[94.10] Test:[78.81] | Best Val:[95.23] Update Test:[80.50] at Epoch:[15] | lr:0.001809
BIAS:[0.10] | Model:[GCN] Epoch:[21/100] Loss:[0.1351] Train:[95.64] val:[95.23] Test:[82.06] | Best Val:[95.23] Update Test:[80.50] at Epoch:[15] | lr:0.001791
BIAS:[0.10] | Model:[GCN] Epoch:[22/100] Loss:[0.1366] Train:[95.85] val:[95.48] Test:[83.00] | Best Val:[95.48] Update Test:[83.00] at Epoch:[22] | lr:0.001771
BIAS:[0.10] | Model:[GCN] Epoch:[23/100] Loss:[0.1262] Train:[95.75] val:[95.36] Test:[82.75] | Best Val:[95.48] Update Test:[83.00] at Epoch:[22] | lr:0.001751
BIAS:[0.10] | Model:[GCN] Epoch:[24/100] Loss:[0.1252] Train:[96.00] val:[94.98] Test:[84.12] | Best Val:[95.48] Update Test:[83.00] at Epoch:[22] | lr:0.001730
BIAS:[0.10] | Model:[GCN] Epoch:[25/100] Loss:[0.1205] Train:[96.21] val:[91.47] Test:[84.12] | Best Val:[95.48] Update Test:[83.00] at Epoch:[22] | lr:0.001708
BIAS:[0.10] | Model:[GCN] Epoch:[26/100] Loss:[0.1198] Train:[96.02] val:[95.48] Test:[83.50] | Best Val:[95.48] Update Test:[83.00] at Epoch:[22] | lr:0.001685
BIAS:[0.10] | Model:[GCN] Epoch:[27/100] Loss:[0.1149] Train:[96.34] val:[93.85] Test:[80.19] | Best Val:[95.48] Update Test:[83.00] at Epoch:[22] | lr:0.001662
BIAS:[0.10] | Model:[GCN] Epoch:[28/100] Loss:[0.1083] Train:[96.50] val:[96.24] Test:[84.81] | Best Val:[96.24] Update Test:[84.81] at Epoch:[28] | lr:0.001638
BIAS:[0.10] | Model:[GCN] Epoch:[29/100] Loss:[0.1115] Train:[96.21] val:[95.86] Test:[83.19] | Best Val:[96.24] Update Test:[84.81] at Epoch:[28] | lr:0.001614
BIAS:[0.10] | Model:[GCN] Epoch:[30/100] Loss:[0.1126] Train:[96.53] val:[95.73] Test:[83.88] | Best Val:[96.24] Update Test:[84.81] at Epoch:[28] | lr:0.001589
BIAS:[0.10] | Model:[GCN] Epoch:[31/100] Loss:[0.1154] Train:[96.14] val:[65.87] Test:[57.31] | Best Val:[96.24] Update Test:[84.81] at Epoch:[28] | lr:0.001563
BIAS:[0.10] | Model:[GCN] Epoch:[32/100] Loss:[0.1074] Train:[96.43] val:[95.73] Test:[84.50] | Best Val:[96.24] Update Test:[84.81] at Epoch:[28] | lr:0.001537
BIAS:[0.10] | Model:[GCN] Epoch:[33/100] Loss:[0.0977] Train:[96.73] val:[94.23] Test:[84.75] | Best Val:[96.24] Update Test:[84.81] at Epoch:[28] | lr:0.001510
BIAS:[0.10] | Model:[GCN] Epoch:[34/100] Loss:[0.1069] Train:[96.48] val:[96.11] Test:[87.75] | Best Val:[96.24] Update Test:[84.81] at Epoch:[28] | lr:0.001483
BIAS:[0.10] | Model:[GCN] Epoch:[35/100] Loss:[0.1155] Train:[96.05] val:[84.94] Test:[66.81] | Best Val:[96.24] Update Test:[84.81] at Epoch:[28] | lr:0.001455
BIAS:[0.10] | Model:[GCN] Epoch:[36/100] Loss:[0.1163] Train:[95.89] val:[92.72] Test:[82.62] | Best Val:[96.24] Update Test:[84.81] at Epoch:[28] | lr:0.001427
BIAS:[0.10] | Model:[GCN] Epoch:[37/100] Loss:[0.0977] Train:[96.80] val:[95.61] Test:[85.62] | Best Val:[96.24] Update Test:[84.81] at Epoch:[28] | lr:0.001399
BIAS:[0.10] | Model:[GCN] Epoch:[38/100] Loss:[0.0924] Train:[97.11] val:[94.73] Test:[78.12] | Best Val:[96.24] Update Test:[84.81] at Epoch:[28] | lr:0.001370
BIAS:[0.10] | Model:[GCN] Epoch:[39/100] Loss:[0.0936] Train:[96.69] val:[61.86] Test:[60.19] | Best Val:[96.24] Update Test:[84.81] at Epoch:[28] | lr:0.001340
BIAS:[0.10] | Model:[GCN] Epoch:[40/100] Loss:[0.0921] Train:[97.05] val:[74.28] Test:[67.31] | Best Val:[96.24] Update Test:[84.81] at Epoch:[28] | lr:0.001311
BIAS:[0.10] | Model:[GCN] Epoch:[41/100] Loss:[0.0913] Train:[96.77] val:[96.11] Test:[84.12] | Best Val:[96.24] Update Test:[84.81] at Epoch:[28] | lr:0.001281
BIAS:[0.10] | Model:[GCN] Epoch:[42/100] Loss:[0.0826] Train:[97.19] val:[94.98] Test:[85.25] | Best Val:[96.24] Update Test:[84.81] at Epoch:[28] | lr:0.001251
BIAS:[0.10] | Model:[GCN] Epoch:[43/100] Loss:[0.0751] Train:[97.30] val:[94.86] Test:[80.69] | Best Val:[96.24] Update Test:[84.81] at Epoch:[28] | lr:0.001220
BIAS:[0.10] | Model:[GCN] Epoch:[44/100] Loss:[0.0766] Train:[97.68] val:[93.10] Test:[87.00] | Best Val:[96.24] Update Test:[84.81] at Epoch:[28] | lr:0.001189
BIAS:[0.10] | Model:[GCN] Epoch:[45/100] Loss:[0.0749] Train:[97.39] val:[92.85] Test:[85.31] | Best Val:[96.24] Update Test:[84.81] at Epoch:[28] | lr:0.001159
BIAS:[0.10] | Model:[GCN] Epoch:[46/100] Loss:[0.0768] Train:[97.41] val:[95.36] Test:[83.12] | Best Val:[96.24] Update Test:[84.81] at Epoch:[28] | lr:0.001128
BIAS:[0.10] | Model:[GCN] Epoch:[47/100] Loss:[0.0720] Train:[97.61] val:[91.84] Test:[85.25] | Best Val:[96.24] Update Test:[84.81] at Epoch:[28] | lr:0.001096
BIAS:[0.10] | Model:[GCN] Epoch:[48/100] Loss:[0.0747] Train:[97.41] val:[94.86] Test:[85.44] | Best Val:[96.24] Update Test:[84.81] at Epoch:[28] | lr:0.001065
BIAS:[0.10] | Model:[GCN] Epoch:[49/100] Loss:[0.0718] Train:[97.61] val:[85.19] Test:[73.75] | Best Val:[96.24] Update Test:[84.81] at Epoch:[28] | lr:0.001034
BIAS:[0.10] | Model:[GCN] Epoch:[50/100] Loss:[0.0663] Train:[97.84] val:[96.11] Test:[84.88] | Best Val:[96.24] Update Test:[84.81] at Epoch:[28] | lr:0.001003
BIAS:[0.10] | Model:[GCN] Epoch:[51/100] Loss:[0.0697] Train:[97.57] val:[96.24] Test:[86.38] | Best Val:[96.24] Update Test:[84.81] at Epoch:[28] | lr:0.000971
BIAS:[0.10] | Model:[GCN] Epoch:[52/100] Loss:[0.0740] Train:[97.50] val:[96.36] Test:[85.81] | Best Val:[96.36] Update Test:[85.81] at Epoch:[52] | lr:0.000940
BIAS:[0.10] | Model:[GCN] Epoch:[53/100] Loss:[0.0808] Train:[97.25] val:[95.48] Test:[87.31] | Best Val:[96.36] Update Test:[85.81] at Epoch:[52] | lr:0.000909
BIAS:[0.10] | Model:[GCN] Epoch:[54/100] Loss:[0.0624] Train:[97.93] val:[95.73] Test:[81.31] | Best Val:[96.36] Update Test:[85.81] at Epoch:[52] | lr:0.000877
BIAS:[0.10] | Model:[GCN] Epoch:[55/100] Loss:[0.0584] Train:[97.91] val:[96.11] Test:[84.69] | Best Val:[96.36] Update Test:[85.81] at Epoch:[52] | lr:0.000846
BIAS:[0.10] | Model:[GCN] Epoch:[56/100] Loss:[0.0570] Train:[98.09] val:[93.22] Test:[87.69] | Best Val:[96.36] Update Test:[85.81] at Epoch:[52] | lr:0.000816
BIAS:[0.10] | Model:[GCN] Epoch:[57/100] Loss:[0.0606] Train:[97.84] val:[96.49] Test:[85.06] | Best Val:[96.49] Update Test:[85.06] at Epoch:[57] | lr:0.000785
BIAS:[0.10] | Model:[GCN] Epoch:[58/100] Loss:[0.0555] Train:[97.96] val:[95.98] Test:[83.94] | Best Val:[96.49] Update Test:[85.06] at Epoch:[57] | lr:0.000754
BIAS:[0.10] | Model:[GCN] Epoch:[59/100] Loss:[0.0548] Train:[98.23] val:[95.48] Test:[88.12] | Best Val:[96.49] Update Test:[85.06] at Epoch:[57] | lr:0.000724
BIAS:[0.10] | Model:[GCN] Epoch:[60/100] Loss:[0.0466] Train:[98.28] val:[96.36] Test:[87.69] | Best Val:[96.49] Update Test:[85.06] at Epoch:[57] | lr:0.000694
BIAS:[0.10] | Model:[GCN] Epoch:[61/100] Loss:[0.0432] Train:[98.48] val:[96.36] Test:[85.50] | Best Val:[96.49] Update Test:[85.06] at Epoch:[57] | lr:0.000665
BIAS:[0.10] | Model:[GCN] Epoch:[62/100] Loss:[0.0376] Train:[98.61] val:[96.61] Test:[86.81] | Best Val:[96.61] Update Test:[86.81] at Epoch:[62] | lr:0.000635
BIAS:[0.10] | Model:[GCN] Epoch:[63/100] Loss:[0.0500] Train:[98.28] val:[95.11] Test:[85.50] | Best Val:[96.61] Update Test:[86.81] at Epoch:[62] | lr:0.000606
BIAS:[0.10] | Model:[GCN] Epoch:[64/100] Loss:[0.0422] Train:[98.39] val:[95.11] Test:[87.38] | Best Val:[96.61] Update Test:[86.81] at Epoch:[62] | lr:0.000578
BIAS:[0.10] | Model:[GCN] Epoch:[65/100] Loss:[0.0398] Train:[98.70] val:[95.73] Test:[85.62] | Best Val:[96.61] Update Test:[86.81] at Epoch:[62] | lr:0.000550
BIAS:[0.10] | Model:[GCN] Epoch:[66/100] Loss:[0.0490] Train:[98.27] val:[94.98] Test:[88.38] | Best Val:[96.61] Update Test:[86.81] at Epoch:[62] | lr:0.000522
BIAS:[0.10] | Model:[GCN] Epoch:[67/100] Loss:[0.0357] Train:[98.86] val:[96.11] Test:[87.00] | Best Val:[96.61] Update Test:[86.81] at Epoch:[62] | lr:0.000495
BIAS:[0.10] | Model:[GCN] Epoch:[68/100] Loss:[0.0320] Train:[98.89] val:[96.36] Test:[85.75] | Best Val:[96.61] Update Test:[86.81] at Epoch:[62] | lr:0.000468
BIAS:[0.10] | Model:[GCN] Epoch:[69/100] Loss:[0.0383] Train:[98.82] val:[96.36] Test:[84.75] | Best Val:[96.61] Update Test:[86.81] at Epoch:[62] | lr:0.000442
BIAS:[0.10] | Model:[GCN] Epoch:[70/100] Loss:[0.0354] Train:[98.89] val:[95.98] Test:[88.00] | Best Val:[96.61] Update Test:[86.81] at Epoch:[62] | lr:0.000416
BIAS:[0.10] | Model:[GCN] Epoch:[71/100] Loss:[0.0336] Train:[98.84] val:[95.36] Test:[84.75] | Best Val:[96.61] Update Test:[86.81] at Epoch:[62] | lr:0.000391
BIAS:[0.10] | Model:[GCN] Epoch:[72/100] Loss:[0.0320] Train:[98.91] val:[92.72] Test:[83.06] | Best Val:[96.61] Update Test:[86.81] at Epoch:[62] | lr:0.000367
BIAS:[0.10] | Model:[GCN] Epoch:[73/100] Loss:[0.0261] Train:[98.95] val:[96.11] Test:[86.25] | Best Val:[96.61] Update Test:[86.81] at Epoch:[62] | lr:0.000343
BIAS:[0.10] | Model:[GCN] Epoch:[74/100] Loss:[0.0232] Train:[99.32] val:[95.73] Test:[86.88] | Best Val:[96.61] Update Test:[86.81] at Epoch:[62] | lr:0.000320
BIAS:[0.10] | Model:[GCN] Epoch:[75/100] Loss:[0.0215] Train:[99.30] val:[96.11] Test:[86.62] | Best Val:[96.61] Update Test:[86.81] at Epoch:[62] | lr:0.000297
BIAS:[0.10] | Model:[GCN] Epoch:[76/100] Loss:[0.0215] Train:[99.23] val:[93.22] Test:[86.50] | Best Val:[96.61] Update Test:[86.81] at Epoch:[62] | lr:0.000275
BIAS:[0.10] | Model:[GCN] Epoch:[77/100] Loss:[0.0186] Train:[99.36] val:[95.36] Test:[87.81] | Best Val:[96.61] Update Test:[86.81] at Epoch:[62] | lr:0.000254
BIAS:[0.10] | Model:[GCN] Epoch:[78/100] Loss:[0.0169] Train:[99.46] val:[96.24] Test:[85.31] | Best Val:[96.61] Update Test:[86.81] at Epoch:[62] | lr:0.000234
BIAS:[0.10] | Model:[GCN] Epoch:[79/100] Loss:[0.0140] Train:[99.57] val:[95.73] Test:[87.69] | Best Val:[96.61] Update Test:[86.81] at Epoch:[62] | lr:0.000214
BIAS:[0.10] | Model:[GCN] Epoch:[80/100] Loss:[0.0121] Train:[99.70] val:[96.11] Test:[86.81] | Best Val:[96.61] Update Test:[86.81] at Epoch:[62] | lr:0.000196
BIAS:[0.10] | Model:[GCN] Epoch:[81/100] Loss:[0.0146] Train:[99.68] val:[95.36] Test:[88.94] | Best Val:[96.61] Update Test:[86.81] at Epoch:[62] | lr:0.000177
BIAS:[0.10] | Model:[GCN] Epoch:[82/100] Loss:[0.0111] Train:[99.73] val:[95.86] Test:[87.12] | Best Val:[96.61] Update Test:[86.81] at Epoch:[62] | lr:0.000160
BIAS:[0.10] | Model:[GCN] Epoch:[83/100] Loss:[0.0134] Train:[99.70] val:[96.24] Test:[87.38] | Best Val:[96.61] Update Test:[86.81] at Epoch:[62] | lr:0.000144
BIAS:[0.10] | Model:[GCN] Epoch:[84/100] Loss:[0.0106] Train:[99.71] val:[95.48] Test:[88.06] | Best Val:[96.61] Update Test:[86.81] at Epoch:[62] | lr:0.000128
BIAS:[0.10] | Model:[GCN] Epoch:[85/100] Loss:[0.0082] Train:[99.84] val:[96.11] Test:[86.94] | Best Val:[96.61] Update Test:[86.81] at Epoch:[62] | lr:0.000114
BIAS:[0.10] | Model:[GCN] Epoch:[86/100] Loss:[0.0097] Train:[99.80] val:[95.11] Test:[88.31] | Best Val:[96.61] Update Test:[86.81] at Epoch:[62] | lr:0.000100
BIAS:[0.10] | Model:[GCN] Epoch:[87/100] Loss:[0.0080] Train:[99.82] val:[96.11] Test:[86.88] | Best Val:[96.61] Update Test:[86.81] at Epoch:[62] | lr:0.000087
BIAS:[0.10] | Model:[GCN] Epoch:[88/100] Loss:[0.0076] Train:[99.91] val:[95.98] Test:[87.19] | Best Val:[96.61] Update Test:[86.81] at Epoch:[62] | lr:0.000075
BIAS:[0.10] | Model:[GCN] Epoch:[89/100] Loss:[0.0079] Train:[99.86] val:[95.98] Test:[86.88] | Best Val:[96.61] Update Test:[86.81] at Epoch:[62] | lr:0.000064
BIAS:[0.10] | Model:[GCN] Epoch:[90/100] Loss:[0.0070] Train:[99.91] val:[95.61] Test:[87.62] | Best Val:[96.61] Update Test:[86.81] at Epoch:[62] | lr:0.000054
BIAS:[0.10] | Model:[GCN] Epoch:[91/100] Loss:[0.0076] Train:[99.86] val:[95.98] Test:[87.38] | Best Val:[96.61] Update Test:[86.81] at Epoch:[62] | lr:0.000045
BIAS:[0.10] | Model:[GCN] Epoch:[92/100] Loss:[0.0076] Train:[99.84] val:[95.73] Test:[87.12] | Best Val:[96.61] Update Test:[86.81] at Epoch:[62] | lr:0.000036
BIAS:[0.10] | Model:[GCN] Epoch:[93/100] Loss:[0.0083] Train:[99.80] val:[95.73] Test:[87.62] | Best Val:[96.61] Update Test:[86.81] at Epoch:[62] | lr:0.000029
BIAS:[0.10] | Model:[GCN] Epoch:[94/100] Loss:[0.0088] Train:[99.73] val:[95.61] Test:[87.12] | Best Val:[96.61] Update Test:[86.81] at Epoch:[62] | lr:0.000023
BIAS:[0.10] | Model:[GCN] Epoch:[95/100] Loss:[0.0071] Train:[99.89] val:[95.86] Test:[87.38] | Best Val:[96.61] Update Test:[86.81] at Epoch:[62] | lr:0.000017
BIAS:[0.10] | Model:[GCN] Epoch:[96/100] Loss:[0.0077] Train:[99.82] val:[95.86] Test:[87.56] | Best Val:[96.61] Update Test:[86.81] at Epoch:[62] | lr:0.000013
BIAS:[0.10] | Model:[GCN] Epoch:[97/100] Loss:[0.0076] Train:[99.80] val:[95.61] Test:[87.50] | Best Val:[96.61] Update Test:[86.81] at Epoch:[62] | lr:0.000009
BIAS:[0.10] | Model:[GCN] Epoch:[98/100] Loss:[0.0071] Train:[99.91] val:[95.73] Test:[87.31] | Best Val:[96.61] Update Test:[86.81] at Epoch:[62] | lr:0.000007
BIAS:[0.10] | Model:[GCN] Epoch:[99/100] Loss:[0.0073] Train:[99.89] val:[95.73] Test:[87.31] | Best Val:[96.61] Update Test:[86.81] at Epoch:[62] | lr:0.000005
BIAS:[0.10] | Model:[GCN] Epoch:[100/100] Loss:[0.0061] Train:[99.91] val:[95.73] Test:[87.75] | Best Val:[96.61] Update Test:[86.81] at Epoch:[62] | lr:0.000005
syd: BIAS:[0.10] | Best Val acc:[96.61] Test acc:[86.81] at epoch:[62]
step_size..................................................................0.001
min_lr.....................................................................5e-06
pretrain......................................................................30
data_num....................................................................2000
node_num......................................................................15
max_degree....................................................................10
feature_dim...................................................................-1
noise........................................................................0.1
num_classes....................................................................4
shape_num......................................................................1
bias.........................................................................0.1
penalty_weight...............................................................0.1
train_type..................................................................base
epochs.......................................................................100
batch_size...................................................................128
the............................................................................0
with_random.................................................................True
eval_random................................................................False
normalize..................................................................False
save_model.................................................................False
inference..................................................................False
without_node_attention.....................................................False
without_edge_attention.....................................................False
k..............................................................................3
layers.........................................................................3
c............................................................................0.5
o............................................................................1.0
co...........................................................................0.5
harf_hidden..................................................................0.5
cat_or_add...................................................................add
num_layers.....................................................................3
folds.........................................................................10
fc_num.......................................................................222
data_root...................................................................data
save_dir...................................................................debug
dataset.....................................................................NCI1
epoch_select............................................................test_max
model..................................................................CausalGCN
hidden.......................................................................128
seed.........................................................................666
lr.........................................................................0.002
lr_decay_factor..............................................................0.5
lr_decay_step_size...........................................................500
weight_decay...................................................................0
global_pool..................................................................sum

----------------------------------------------------------------------------------------------------
| graph: Tree-house | nodes num:246 | edges num:542 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: BA-house | nodes num:230 | edges num:996 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: Tree-cycle | nodes num:247 | edges num:542 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: BA-cycle | nodes num:231 | edges num:996 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: Tree-grid | nodes num:247 | edges num:544 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: BA-grid | nodes num:231 | edges num:998 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: Tree-diamond | nodes num:247 | edges num:546 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: BA-diamond | nodes num:231 | edges num:1000 |
----------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
Train Total:5597
| Tree: House:140  , Cycle:1260 , Grids:1260 , Diams:1260  
| BA  : House:1260 , Cycle:139  , Grids:139  , Diams:139   
| All : House:1400 , Cycle:1399 , Grids:1399 , Diams:1399  
| BIAS: House:10.0%, Cycle:90.1%, Grids:90.1%, Diams:90.1%
------------------------------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
Val    Total:797
| Tree: House:20   , Cycle:180  , Grids:180  , Diams:180   
| BA  : House:180  , Cycle:19   , Grids:19   , Diams:19    
| All : House:200  , Cycle:199  , Grids:199  , Diams:199   
| BIAS: House:10.0%, Cycle:90.5%, Grids:90.5%, Diams:90.5%
------------------------------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
Test   Total:1600
| Tree: House:200  , Cycle:200  , Grids:200  , Diams:200   
| BA  : House:200  , Cycle:200  , Grids:200  , Diams:200   
| All : House:400  , Cycle:400  , Grids:400  , Diams:400   
| BIAS: House:50.0%, Cycle:50.0%, Grids:50.0%, Diams:50.0%
------------------------------------------------------------------------------------------------------------------------------------------------------
BIAS:[0.10] | Model:[CausalGCN] Epoch:[1/100] Loss:[0.7869=0.0157+0.4815+0.5951] Train:[84.01] val:[76.54] Test:[62.56] | Update Test:[co:51.88,c:25.62,o:62.56] at Epoch:[1] | lr:0.002000
BIAS:[0.10] | Model:[CausalGCN] Epoch:[2/100] Loss:[0.3973=0.0020+0.2529+0.2869] Train:[91.60] val:[86.20] Test:[65.81] | Update Test:[co:70.75,c:24.44,o:65.81] at Epoch:[2] | lr:0.001998
BIAS:[0.10] | Model:[CausalGCN] Epoch:[3/100] Loss:[0.3120=0.0007+0.2014+0.2206] Train:[93.16] val:[92.35] Test:[74.44] | Update Test:[co:68.56,c:24.69,o:74.44] at Epoch:[3] | lr:0.001996
BIAS:[0.10] | Model:[CausalGCN] Epoch:[4/100] Loss:[0.2676=0.0006+0.1708+0.1928] Train:[94.55] val:[93.73] Test:[78.81] | Update Test:[co:77.81,c:25.37,o:78.81] at Epoch:[4] | lr:0.001992
BIAS:[0.10] | Model:[CausalGCN] Epoch:[5/100] Loss:[0.2472=0.0004+0.1586+0.1769] Train:[95.02] val:[93.48] Test:[84.81] | Update Test:[co:77.81,c:25.37,o:78.81] at Epoch:[4] | lr:0.001988
BIAS:[0.10] | Model:[CausalGCN] Epoch:[6/100] Loss:[0.2345=0.0003+0.1522+0.1643] Train:[95.02] val:[87.20] Test:[75.69] | Update Test:[co:77.81,c:25.37,o:78.81] at Epoch:[4] | lr:0.001982
BIAS:[0.10] | Model:[CausalGCN] Epoch:[7/100] Loss:[0.2200=0.0002+0.1418+0.1562] Train:[95.37] val:[94.73] Test:[82.81] | Update Test:[co:82.12,c:24.94,o:82.81] at Epoch:[7] | lr:0.001976
BIAS:[0.10] | Model:[CausalGCN] Epoch:[8/100] Loss:[0.2242=0.0002+0.1456+0.1571] Train:[95.34] val:[93.98] Test:[79.06] | Update Test:[co:82.12,c:24.94,o:82.81] at Epoch:[7] | lr:0.001969
BIAS:[0.10] | Model:[CausalGCN] Epoch:[9/100] Loss:[0.2002=0.0001+0.1313+0.1378] Train:[95.60] val:[94.98] Test:[85.06] | Update Test:[co:71.75,c:24.56,o:85.06] at Epoch:[9] | lr:0.001960
BIAS:[0.10] | Model:[CausalGCN] Epoch:[10/100] Loss:[0.2007=0.0002+0.1280+0.1452] Train:[95.94] val:[85.57] Test:[66.75] | Update Test:[co:71.75,c:24.56,o:85.06] at Epoch:[9] | lr:0.001951
BIAS:[0.10] | Model:[CausalGCN] Epoch:[11/100] Loss:[0.1788=0.0002+0.1147+0.1281] Train:[96.50] val:[94.73] Test:[84.31] | Update Test:[co:71.75,c:24.56,o:85.06] at Epoch:[9] | lr:0.001941
BIAS:[0.10] | Model:[CausalGCN] Epoch:[12/100] Loss:[0.1716=0.0001+0.1098+0.1235] Train:[96.61] val:[94.10] Test:[86.12] | Update Test:[co:71.75,c:24.56,o:85.06] at Epoch:[9] | lr:0.001930
BIAS:[0.10] | Model:[CausalGCN] Epoch:[13/100] Loss:[0.1607=0.0002+0.1043+0.1126] Train:[96.69] val:[95.73] Test:[85.50] | Update Test:[co:87.62,c:25.00,o:85.50] at Epoch:[13] | lr:0.001918
BIAS:[0.10] | Model:[CausalGCN] Epoch:[14/100] Loss:[0.1687=0.0002+0.1102+0.1169] Train:[96.30] val:[92.47] Test:[81.94] | Update Test:[co:87.62,c:25.00,o:85.50] at Epoch:[13] | lr:0.001905
BIAS:[0.10] | Model:[CausalGCN] Epoch:[15/100] Loss:[0.1610=0.0001+0.1046+0.1127] Train:[96.53] val:[93.48] Test:[72.38] | Update Test:[co:87.62,c:25.00,o:85.50] at Epoch:[13] | lr:0.001891
BIAS:[0.10] | Model:[CausalGCN] Epoch:[16/100] Loss:[0.1647=0.0001+0.1075+0.1144] Train:[96.53] val:[94.98] Test:[81.81] | Update Test:[co:87.62,c:25.00,o:85.50] at Epoch:[13] | lr:0.001877
BIAS:[0.10] | Model:[CausalGCN] Epoch:[17/100] Loss:[0.1437=0.0002+0.0914+0.1045] Train:[97.16] val:[95.23] Test:[88.12] | Update Test:[co:87.62,c:25.00,o:85.50] at Epoch:[13] | lr:0.001861
BIAS:[0.10] | Model:[CausalGCN] Epoch:[18/100] Loss:[0.1369=0.0001+0.0862+0.1014] Train:[97.23] val:[96.11] Test:[87.75] | Update Test:[co:87.19,c:23.75,o:87.75] at Epoch:[18] | lr:0.001845
BIAS:[0.10] | Model:[CausalGCN] Epoch:[19/100] Loss:[0.1189=0.0001+0.0757+0.0862] Train:[97.66] val:[95.73] Test:[84.62] | Update Test:[co:87.19,c:23.75,o:87.75] at Epoch:[18] | lr:0.001828
BIAS:[0.10] | Model:[CausalGCN] Epoch:[20/100] Loss:[0.1188=0.0002+0.0765+0.0845] Train:[97.68] val:[95.86] Test:[85.19] | Update Test:[co:87.19,c:23.75,o:87.75] at Epoch:[18] | lr:0.001809
BIAS:[0.10] | Model:[CausalGCN] Epoch:[21/100] Loss:[0.1232=0.0001+0.0798+0.0866] Train:[97.43] val:[95.11] Test:[89.25] | Update Test:[co:87.19,c:23.75,o:87.75] at Epoch:[18] | lr:0.001791
BIAS:[0.10] | Model:[CausalGCN] Epoch:[22/100] Loss:[0.1227=0.0002+0.0798+0.0857] Train:[97.16] val:[95.48] Test:[88.31] | Update Test:[co:87.19,c:23.75,o:87.75] at Epoch:[18] | lr:0.001771
BIAS:[0.10] | Model:[CausalGCN] Epoch:[23/100] Loss:[0.1072=0.0001+0.0678+0.0786] Train:[97.77] val:[88.08] Test:[78.50] | Update Test:[co:87.19,c:23.75,o:87.75] at Epoch:[18] | lr:0.001751
BIAS:[0.10] | Model:[CausalGCN] Epoch:[24/100] Loss:[0.1143=0.0001+0.0717+0.0849] Train:[97.62] val:[95.86] Test:[87.38] | Update Test:[co:87.19,c:23.75,o:87.75] at Epoch:[18] | lr:0.001730
BIAS:[0.10] | Model:[CausalGCN] Epoch:[25/100] Loss:[0.1084=0.0002+0.0687+0.0792] Train:[97.87] val:[93.73] Test:[82.69] | Update Test:[co:87.19,c:23.75,o:87.75] at Epoch:[18] | lr:0.001708
BIAS:[0.10] | Model:[CausalGCN] Epoch:[26/100] Loss:[0.1119=0.0001+0.0709+0.0819] Train:[97.73] val:[91.72] Test:[70.75] | Update Test:[co:87.19,c:23.75,o:87.75] at Epoch:[18] | lr:0.001685
BIAS:[0.10] | Model:[CausalGCN] Epoch:[27/100] Loss:[0.0998=0.0001+0.0639+0.0716] Train:[97.96] val:[94.98] Test:[88.94] | Update Test:[co:87.19,c:23.75,o:87.75] at Epoch:[18] | lr:0.001662
BIAS:[0.10] | Model:[CausalGCN] Epoch:[28/100] Loss:[0.0955=0.0001+0.0608+0.0694] Train:[97.87] val:[95.86] Test:[87.88] | Update Test:[co:87.19,c:23.75,o:87.75] at Epoch:[18] | lr:0.001638
BIAS:[0.10] | Model:[CausalGCN] Epoch:[29/100] Loss:[0.0885=0.0001+0.0569+0.0631] Train:[98.07] val:[94.60] Test:[86.81] | Update Test:[co:87.19,c:23.75,o:87.75] at Epoch:[18] | lr:0.001614
BIAS:[0.10] | Model:[CausalGCN] Epoch:[30/100] Loss:[0.1092=0.0001+0.0716+0.0751] Train:[97.66] val:[95.98] Test:[87.56] | Update Test:[co:87.19,c:23.75,o:87.75] at Epoch:[18] | lr:0.001589
BIAS:[0.10] | Model:[CausalGCN] Epoch:[31/100] Loss:[0.0791=0.0001+0.0507+0.0566] Train:[98.37] val:[94.35] Test:[76.88] | Update Test:[co:87.19,c:23.75,o:87.75] at Epoch:[18] | lr:0.001563
BIAS:[0.10] | Model:[CausalGCN] Epoch:[32/100] Loss:[0.0810=0.0001+0.0522+0.0576] Train:[98.28] val:[96.61] Test:[87.19] | Update Test:[co:85.81,c:25.19,o:87.19] at Epoch:[32] | lr:0.001537
BIAS:[0.10] | Model:[CausalGCN] Epoch:[33/100] Loss:[0.0747=0.0001+0.0471+0.0551] Train:[98.39] val:[96.11] Test:[87.88] | Update Test:[co:85.81,c:25.19,o:87.19] at Epoch:[32] | lr:0.001510
BIAS:[0.10] | Model:[CausalGCN] Epoch:[34/100] Loss:[0.0665=0.0000+0.0424+0.0480] Train:[98.53] val:[96.36] Test:[88.94] | Update Test:[co:85.81,c:25.19,o:87.19] at Epoch:[32] | lr:0.001483
BIAS:[0.10] | Model:[CausalGCN] Epoch:[35/100] Loss:[0.0587=0.0000+0.0368+0.0438] Train:[98.80] val:[95.98] Test:[89.69] | Update Test:[co:85.81,c:25.19,o:87.19] at Epoch:[32] | lr:0.001455
BIAS:[0.10] | Model:[CausalGCN] Epoch:[36/100] Loss:[0.0715=0.0001+0.0455+0.0520] Train:[98.50] val:[96.86] Test:[89.38] | Update Test:[co:89.62,c:24.38,o:89.38] at Epoch:[36] | lr:0.001427
BIAS:[0.10] | Model:[CausalGCN] Epoch:[37/100] Loss:[0.0731=0.0000+0.0471+0.0520] Train:[98.62] val:[96.74] Test:[90.12] | Update Test:[co:89.62,c:24.38,o:89.38] at Epoch:[36] | lr:0.001399
BIAS:[0.10] | Model:[CausalGCN] Epoch:[38/100] Loss:[0.0508=0.0001+0.0322+0.0371] Train:[98.89] val:[96.86] Test:[89.12] | Update Test:[co:89.62,c:24.38,o:89.38] at Epoch:[36] | lr:0.001370
BIAS:[0.10] | Model:[CausalGCN] Epoch:[39/100] Loss:[0.0557=0.0000+0.0346+0.0422] Train:[98.77] val:[96.49] Test:[90.38] | Update Test:[co:89.62,c:24.38,o:89.38] at Epoch:[36] | lr:0.001340
BIAS:[0.10] | Model:[CausalGCN] Epoch:[40/100] Loss:[0.0539=0.0001+0.0341+0.0395] Train:[98.91] val:[96.49] Test:[90.25] | Update Test:[co:89.62,c:24.38,o:89.38] at Epoch:[36] | lr:0.001311
BIAS:[0.10] | Model:[CausalGCN] Epoch:[41/100] Loss:[0.0510=0.0000+0.0310+0.0400] Train:[98.98] val:[95.98] Test:[89.50] | Update Test:[co:89.62,c:24.38,o:89.38] at Epoch:[36] | lr:0.001281
BIAS:[0.10] | Model:[CausalGCN] Epoch:[42/100] Loss:[0.0616=0.0001+0.0395+0.0442] Train:[98.52] val:[94.98] Test:[90.00] | Update Test:[co:89.62,c:24.38,o:89.38] at Epoch:[36] | lr:0.001251
BIAS:[0.10] | Model:[CausalGCN] Epoch:[43/100] Loss:[0.0577=0.0000+0.0367+0.0420] Train:[98.82] val:[96.61] Test:[90.38] | Update Test:[co:89.62,c:24.38,o:89.38] at Epoch:[36] | lr:0.001220
BIAS:[0.10] | Model:[CausalGCN] Epoch:[44/100] Loss:[0.0463=0.0000+0.0293+0.0340] Train:[99.11] val:[96.11] Test:[89.12] | Update Test:[co:89.62,c:24.38,o:89.38] at Epoch:[36] | lr:0.001189
BIAS:[0.10] | Model:[CausalGCN] Epoch:[45/100] Loss:[0.0392=0.0001+0.0246+0.0291] Train:[99.16] val:[96.99] Test:[89.19] | Update Test:[co:89.94,c:25.56,o:89.19] at Epoch:[45] | lr:0.001159
BIAS:[0.10] | Model:[CausalGCN] Epoch:[46/100] Loss:[0.0342=0.0000+0.0209+0.0266] Train:[99.45] val:[93.35] Test:[89.75] | Update Test:[co:89.94,c:25.56,o:89.19] at Epoch:[45] | lr:0.001128
BIAS:[0.10] | Model:[CausalGCN] Epoch:[47/100] Loss:[0.0468=0.0001+0.0290+0.0354] Train:[99.02] val:[95.98] Test:[87.12] | Update Test:[co:89.94,c:25.56,o:89.19] at Epoch:[45] | lr:0.001096
BIAS:[0.10] | Model:[CausalGCN] Epoch:[48/100] Loss:[0.0379=0.0000+0.0237+0.0285] Train:[99.27] val:[96.74] Test:[89.44] | Update Test:[co:89.94,c:25.56,o:89.19] at Epoch:[45] | lr:0.001065
BIAS:[0.10] | Model:[CausalGCN] Epoch:[49/100] Loss:[0.0349=0.0000+0.0216+0.0265] Train:[99.30] val:[96.74] Test:[88.12] | Update Test:[co:89.94,c:25.56,o:89.19] at Epoch:[45] | lr:0.001034
BIAS:[0.10] | Model:[CausalGCN] Epoch:[50/100] Loss:[0.0393=0.0000+0.0245+0.0296] Train:[99.30] val:[97.11] Test:[90.88] | Update Test:[co:91.06,c:22.56,o:90.88] at Epoch:[50] | lr:0.001003
BIAS:[0.10] | Model:[CausalGCN] Epoch:[51/100] Loss:[0.0316=0.0000+0.0190+0.0252] Train:[99.37] val:[97.11] Test:[89.06] | Update Test:[co:91.06,c:22.56,o:90.88] at Epoch:[50] | lr:0.000971
BIAS:[0.10] | Model:[CausalGCN] Epoch:[52/100] Loss:[0.0274=0.0000+0.0171+0.0207] Train:[99.50] val:[97.37] Test:[89.31] | Update Test:[co:89.38,c:22.62,o:89.31] at Epoch:[52] | lr:0.000940
BIAS:[0.10] | Model:[CausalGCN] Epoch:[53/100] Loss:[0.0223=0.0000+0.0135+0.0176] Train:[99.62] val:[96.99] Test:[89.75] | Update Test:[co:89.38,c:22.62,o:89.31] at Epoch:[52] | lr:0.000909
BIAS:[0.10] | Model:[CausalGCN] Epoch:[54/100] Loss:[0.0282=0.0000+0.0176+0.0210] Train:[99.41] val:[96.74] Test:[89.38] | Update Test:[co:89.38,c:22.62,o:89.31] at Epoch:[52] | lr:0.000877
BIAS:[0.10] | Model:[CausalGCN] Epoch:[55/100] Loss:[0.0243=0.0000+0.0147+0.0192] Train:[99.57] val:[97.24] Test:[90.75] | Update Test:[co:89.38,c:22.62,o:89.31] at Epoch:[52] | lr:0.000846
BIAS:[0.10] | Model:[CausalGCN] Epoch:[56/100] Loss:[0.0194=0.0000+0.0118+0.0151] Train:[99.64] val:[97.49] Test:[90.25] | Update Test:[co:90.00,c:25.25,o:90.25] at Epoch:[56] | lr:0.000816
BIAS:[0.10] | Model:[CausalGCN] Epoch:[57/100] Loss:[0.0164=0.0000+0.0101+0.0126] Train:[99.79] val:[96.61] Test:[89.56] | Update Test:[co:90.00,c:25.25,o:90.25] at Epoch:[56] | lr:0.000785
BIAS:[0.10] | Model:[CausalGCN] Epoch:[58/100] Loss:[0.0132=0.0000+0.0078+0.0107] Train:[99.79] val:[97.24] Test:[89.31] | Update Test:[co:90.00,c:25.25,o:90.25] at Epoch:[56] | lr:0.000754
BIAS:[0.10] | Model:[CausalGCN] Epoch:[59/100] Loss:[0.0133=0.0000+0.0082+0.0101] Train:[99.82] val:[97.24] Test:[89.31] | Update Test:[co:90.00,c:25.25,o:90.25] at Epoch:[56] | lr:0.000724
BIAS:[0.10] | Model:[CausalGCN] Epoch:[60/100] Loss:[0.0215=0.0000+0.0127+0.0176] Train:[99.59] val:[97.37] Test:[89.88] | Update Test:[co:90.00,c:25.25,o:90.25] at Epoch:[56] | lr:0.000694
BIAS:[0.10] | Model:[CausalGCN] Epoch:[61/100] Loss:[0.0184=0.0000+0.0113+0.0143] Train:[99.73] val:[96.74] Test:[90.50] | Update Test:[co:90.00,c:25.25,o:90.25] at Epoch:[56] | lr:0.000665
BIAS:[0.10] | Model:[CausalGCN] Epoch:[62/100] Loss:[0.0157=0.0000+0.0094+0.0125] Train:[99.73] val:[96.49] Test:[89.19] | Update Test:[co:90.00,c:25.25,o:90.25] at Epoch:[56] | lr:0.000635
BIAS:[0.10] | Model:[CausalGCN] Epoch:[63/100] Loss:[0.0113=0.0000+0.0067+0.0092] Train:[99.82] val:[97.37] Test:[90.75] | Update Test:[co:90.00,c:25.25,o:90.25] at Epoch:[56] | lr:0.000606
BIAS:[0.10] | Model:[CausalGCN] Epoch:[64/100] Loss:[0.0117=0.0000+0.0068+0.0097] Train:[99.80] val:[97.37] Test:[90.31] | Update Test:[co:90.00,c:25.25,o:90.25] at Epoch:[56] | lr:0.000578
BIAS:[0.10] | Model:[CausalGCN] Epoch:[65/100] Loss:[0.0091=0.0000+0.0054+0.0074] Train:[99.91] val:[96.86] Test:[89.56] | Update Test:[co:90.00,c:25.25,o:90.25] at Epoch:[56] | lr:0.000550
BIAS:[0.10] | Model:[CausalGCN] Epoch:[66/100] Loss:[0.0091=0.0000+0.0050+0.0080] Train:[99.91] val:[97.49] Test:[89.81] | Update Test:[co:90.00,c:25.25,o:90.25] at Epoch:[56] | lr:0.000522
BIAS:[0.10] | Model:[CausalGCN] Epoch:[67/100] Loss:[0.0083=0.0000+0.0049+0.0068] Train:[99.82] val:[97.62] Test:[90.06] | Update Test:[co:90.06,c:26.12,o:90.06] at Epoch:[67] | lr:0.000495
BIAS:[0.10] | Model:[CausalGCN] Epoch:[68/100] Loss:[0.0074=0.0000+0.0044+0.0060] Train:[99.86] val:[97.74] Test:[90.19] | Update Test:[co:89.56,c:26.50,o:90.19] at Epoch:[68] | lr:0.000468
BIAS:[0.10] | Model:[CausalGCN] Epoch:[69/100] Loss:[0.0057=0.0000+0.0032+0.0050] Train:[99.93] val:[97.37] Test:[90.19] | Update Test:[co:89.56,c:26.50,o:90.19] at Epoch:[68] | lr:0.000442
BIAS:[0.10] | Model:[CausalGCN] Epoch:[70/100] Loss:[0.0047=0.0000+0.0025+0.0042] Train:[99.96] val:[97.24] Test:[90.00] | Update Test:[co:89.56,c:26.50,o:90.19] at Epoch:[68] | lr:0.000416
BIAS:[0.10] | Model:[CausalGCN] Epoch:[71/100] Loss:[0.0042=0.0000+0.0024+0.0035] Train:[99.96] val:[97.11] Test:[89.81] | Update Test:[co:89.56,c:26.50,o:90.19] at Epoch:[68] | lr:0.000391
BIAS:[0.10] | Model:[CausalGCN] Epoch:[72/100] Loss:[0.0065=0.0000+0.0038+0.0054] Train:[99.87] val:[96.86] Test:[89.81] | Update Test:[co:89.56,c:26.50,o:90.19] at Epoch:[68] | lr:0.000367
BIAS:[0.10] | Model:[CausalGCN] Epoch:[73/100] Loss:[0.0055=0.0000+0.0030+0.0049] Train:[99.91] val:[97.37] Test:[90.19] | Update Test:[co:89.56,c:26.50,o:90.19] at Epoch:[68] | lr:0.000343
BIAS:[0.10] | Model:[CausalGCN] Epoch:[74/100] Loss:[0.0055=0.0000+0.0033+0.0044] Train:[99.93] val:[97.62] Test:[90.19] | Update Test:[co:89.56,c:26.50,o:90.19] at Epoch:[68] | lr:0.000320
BIAS:[0.10] | Model:[CausalGCN] Epoch:[75/100] Loss:[0.0054=0.0000+0.0031+0.0047] Train:[99.93] val:[97.24] Test:[90.06] | Update Test:[co:89.56,c:26.50,o:90.19] at Epoch:[68] | lr:0.000297
BIAS:[0.10] | Model:[CausalGCN] Epoch:[76/100] Loss:[0.0036=0.0000+0.0020+0.0033] Train:[99.96] val:[97.24] Test:[90.12] | Update Test:[co:89.56,c:26.50,o:90.19] at Epoch:[68] | lr:0.000275
BIAS:[0.10] | Model:[CausalGCN] Epoch:[77/100] Loss:[0.0066=0.0000+0.0038+0.0057] Train:[99.93] val:[97.37] Test:[90.44] | Update Test:[co:89.56,c:26.50,o:90.19] at Epoch:[68] | lr:0.000254
BIAS:[0.10] | Model:[CausalGCN] Epoch:[78/100] Loss:[0.0026=0.0000+0.0014+0.0023] Train:[99.96] val:[97.11] Test:[89.94] | Update Test:[co:89.56,c:26.50,o:90.19] at Epoch:[68] | lr:0.000234
BIAS:[0.10] | Model:[CausalGCN] Epoch:[79/100] Loss:[0.0030=0.0000+0.0017+0.0026] Train:[99.98] val:[97.11] Test:[90.00] | Update Test:[co:89.56,c:26.50,o:90.19] at Epoch:[68] | lr:0.000214
BIAS:[0.10] | Model:[CausalGCN] Epoch:[80/100] Loss:[0.0034=0.0000+0.0019+0.0031] Train:[99.95] val:[96.99] Test:[90.19] | Update Test:[co:89.56,c:26.50,o:90.19] at Epoch:[68] | lr:0.000196
BIAS:[0.10] | Model:[CausalGCN] Epoch:[81/100] Loss:[0.0038=0.0000+0.0022+0.0033] Train:[99.93] val:[97.24] Test:[89.94] | Update Test:[co:89.56,c:26.50,o:90.19] at Epoch:[68] | lr:0.000177
BIAS:[0.10] | Model:[CausalGCN] Epoch:[82/100] Loss:[0.0034=0.0000+0.0017+0.0033] Train:[99.98] val:[97.37] Test:[90.19] | Update Test:[co:89.56,c:26.50,o:90.19] at Epoch:[68] | lr:0.000160
BIAS:[0.10] | Model:[CausalGCN] Epoch:[83/100] Loss:[0.0029=0.0000+0.0016+0.0026] Train:[99.96] val:[97.24] Test:[90.12] | Update Test:[co:89.56,c:26.50,o:90.19] at Epoch:[68] | lr:0.000144
BIAS:[0.10] | Model:[CausalGCN] Epoch:[84/100] Loss:[0.0034=0.0000+0.0020+0.0027] Train:[99.96] val:[97.37] Test:[89.81] | Update Test:[co:89.56,c:26.50,o:90.19] at Epoch:[68] | lr:0.000128
BIAS:[0.10] | Model:[CausalGCN] Epoch:[85/100] Loss:[0.0033=0.0000+0.0018+0.0031] Train:[99.95] val:[97.24] Test:[89.94] | Update Test:[co:89.56,c:26.50,o:90.19] at Epoch:[68] | lr:0.000114
BIAS:[0.10] | Model:[CausalGCN] Epoch:[86/100] Loss:[0.0028=0.0000+0.0016+0.0024] Train:[99.98] val:[97.24] Test:[90.38] | Update Test:[co:89.56,c:26.50,o:90.19] at Epoch:[68] | lr:0.000100
BIAS:[0.10] | Model:[CausalGCN] Epoch:[87/100] Loss:[0.0021=0.0000+0.0012+0.0019] Train:[99.96] val:[97.49] Test:[90.12] | Update Test:[co:89.56,c:26.50,o:90.19] at Epoch:[68] | lr:0.000087
BIAS:[0.10] | Model:[CausalGCN] Epoch:[88/100] Loss:[0.0030=0.0000+0.0017+0.0026] Train:[99.95] val:[97.24] Test:[89.94] | Update Test:[co:89.56,c:26.50,o:90.19] at Epoch:[68] | lr:0.000075
BIAS:[0.10] | Model:[CausalGCN] Epoch:[89/100] Loss:[0.0028=0.0000+0.0017+0.0023] Train:[99.96] val:[97.24] Test:[90.06] | Update Test:[co:89.56,c:26.50,o:90.19] at Epoch:[68] | lr:0.000064
BIAS:[0.10] | Model:[CausalGCN] Epoch:[90/100] Loss:[0.0033=0.0000+0.0019+0.0029] Train:[99.96] val:[97.62] Test:[89.94] | Update Test:[co:89.56,c:26.50,o:90.19] at Epoch:[68] | lr:0.000054
BIAS:[0.10] | Model:[CausalGCN] Epoch:[91/100] Loss:[0.0022=0.0000+0.0012+0.0020] Train:[99.98] val:[97.37] Test:[90.12] | Update Test:[co:89.56,c:26.50,o:90.19] at Epoch:[68] | lr:0.000045
BIAS:[0.10] | Model:[CausalGCN] Epoch:[92/100] Loss:[0.0025=0.0000+0.0014+0.0021] Train:[99.96] val:[97.37] Test:[89.88] | Update Test:[co:89.56,c:26.50,o:90.19] at Epoch:[68] | lr:0.000036
BIAS:[0.10] | Model:[CausalGCN] Epoch:[93/100] Loss:[0.0021=0.0000+0.0012+0.0019] Train:[99.96] val:[97.49] Test:[90.00] | Update Test:[co:89.56,c:26.50,o:90.19] at Epoch:[68] | lr:0.000029
BIAS:[0.10] | Model:[CausalGCN] Epoch:[94/100] Loss:[0.0026=0.0000+0.0016+0.0021] Train:[99.95] val:[97.24] Test:[90.25] | Update Test:[co:89.56,c:26.50,o:90.19] at Epoch:[68] | lr:0.000023
BIAS:[0.10] | Model:[CausalGCN] Epoch:[95/100] Loss:[0.0022=0.0000+0.0012+0.0020] Train:[99.98] val:[97.49] Test:[89.81] | Update Test:[co:89.56,c:26.50,o:90.19] at Epoch:[68] | lr:0.000017
BIAS:[0.10] | Model:[CausalGCN] Epoch:[96/100] Loss:[0.0028=0.0000+0.0017+0.0023] Train:[99.96] val:[97.24] Test:[90.00] | Update Test:[co:89.56,c:26.50,o:90.19] at Epoch:[68] | lr:0.000013
BIAS:[0.10] | Model:[CausalGCN] Epoch:[97/100] Loss:[0.0023=0.0000+0.0013+0.0019] Train:[99.98] val:[97.24] Test:[90.00] | Update Test:[co:89.56,c:26.50,o:90.19] at Epoch:[68] | lr:0.000009
BIAS:[0.10] | Model:[CausalGCN] Epoch:[98/100] Loss:[0.0030=0.0000+0.0018+0.0025] Train:[99.98] val:[97.24] Test:[89.62] | Update Test:[co:89.56,c:26.50,o:90.19] at Epoch:[68] | lr:0.000007
BIAS:[0.10] | Model:[CausalGCN] Epoch:[99/100] Loss:[0.0029=0.0000+0.0017+0.0023] Train:[99.96] val:[97.49] Test:[90.19] | Update Test:[co:89.56,c:26.50,o:90.19] at Epoch:[68] | lr:0.000005
BIAS:[0.10] | Model:[CausalGCN] Epoch:[100/100] Loss:[0.0028=0.0000+0.0016+0.0023] Train:[99.98] val:[97.24] Test:[89.81] | Update Test:[co:89.56,c:26.50,o:90.19] at Epoch:[68] | lr:0.000005
syd: BIAS:[0.10] | Val acc:[97.24] Test acc:[co:89.56,c:26.50,o:90.19] at epoch:[68]
step_size..................................................................0.001
min_lr.....................................................................5e-06
pretrain......................................................................30
data_num....................................................................2000
node_num......................................................................15
max_degree....................................................................10
feature_dim...................................................................-1
noise........................................................................0.1
num_classes....................................................................4
shape_num......................................................................1
bias.........................................................................0.3
penalty_weight...............................................................0.1
train_type..................................................................base
epochs.......................................................................100
batch_size...................................................................128
the............................................................................0
with_random.................................................................True
eval_random................................................................False
normalize..................................................................False
save_model.................................................................False
inference..................................................................False
without_node_attention.....................................................False
without_edge_attention.....................................................False
k..............................................................................3
layers.........................................................................3
c............................................................................0.5
o............................................................................1.0
co...........................................................................0.5
harf_hidden..................................................................0.5
cat_or_add...................................................................add
num_layers.....................................................................3
folds.........................................................................10
fc_num.......................................................................222
data_root...................................................................data
save_dir...................................................................debug
dataset.....................................................................NCI1
epoch_select............................................................test_max
model........................................................................GCN
hidden.......................................................................128
seed.........................................................................666
lr.........................................................................0.002
lr_decay_factor..............................................................0.5
lr_decay_step_size...........................................................500
weight_decay...................................................................0
global_pool..................................................................sum

----------------------------------------------------------------------------------------------------
| graph: Tree-house | nodes num:246 | edges num:542 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: BA-house | nodes num:230 | edges num:996 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: Tree-cycle | nodes num:247 | edges num:542 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: BA-cycle | nodes num:231 | edges num:996 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: Tree-grid | nodes num:247 | edges num:544 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: BA-grid | nodes num:231 | edges num:998 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: Tree-diamond | nodes num:247 | edges num:546 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: BA-diamond | nodes num:231 | edges num:1000 |
----------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
Train Total:5596
| Tree: House:420  , Cycle:979  , Grids:979  , Diams:979   
| BA  : House:979  , Cycle:420  , Grids:420  , Diams:420   
| All : House:1399 , Cycle:1399 , Grids:1399 , Diams:1399  
| BIAS: House:30.0%, Cycle:70.0%, Grids:70.0%, Diams:70.0%
------------------------------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
Val    Total:800
| Tree: House:60   , Cycle:140  , Grids:140  , Diams:140   
| BA  : House:140  , Cycle:60   , Grids:60   , Diams:60    
| All : House:200  , Cycle:200  , Grids:200  , Diams:200   
| BIAS: House:30.0%, Cycle:70.0%, Grids:70.0%, Diams:70.0%
------------------------------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
Test   Total:1600
| Tree: House:200  , Cycle:200  , Grids:200  , Diams:200   
| BA  : House:200  , Cycle:200  , Grids:200  , Diams:200   
| All : House:400  , Cycle:400  , Grids:400  , Diams:400   
| BIAS: House:50.0%, Cycle:50.0%, Grids:50.0%, Diams:50.0%
------------------------------------------------------------------------------------------------------------------------------------------------------
BIAS:[0.30] | Model:[GCN] Epoch:[1/100] Loss:[0.7938] Train:[69.60] val:[57.50] Test:[44.81] | Best Val:[57.50] Update Test:[44.81] at Epoch:[1] | lr:0.002000
BIAS:[0.30] | Model:[GCN] Epoch:[2/100] Loss:[0.4951] Train:[81.97] val:[83.38] Test:[77.06] | Best Val:[83.38] Update Test:[77.06] at Epoch:[2] | lr:0.001998
BIAS:[0.30] | Model:[GCN] Epoch:[3/100] Loss:[0.4187] Train:[84.52] val:[85.38] Test:[80.06] | Best Val:[85.38] Update Test:[80.06] at Epoch:[3] | lr:0.001996
BIAS:[0.30] | Model:[GCN] Epoch:[4/100] Loss:[0.4000] Train:[85.29] val:[87.38] Test:[82.25] | Best Val:[87.38] Update Test:[82.25] at Epoch:[4] | lr:0.001992
BIAS:[0.30] | Model:[GCN] Epoch:[5/100] Loss:[0.3446] Train:[87.12] val:[77.88] Test:[74.38] | Best Val:[87.38] Update Test:[82.25] at Epoch:[4] | lr:0.001988
BIAS:[0.30] | Model:[GCN] Epoch:[6/100] Loss:[0.3302] Train:[87.87] val:[75.50] Test:[72.25] | Best Val:[87.38] Update Test:[82.25] at Epoch:[4] | lr:0.001982
BIAS:[0.30] | Model:[GCN] Epoch:[7/100] Loss:[0.3120] Train:[88.81] val:[87.88] Test:[82.81] | Best Val:[87.88] Update Test:[82.81] at Epoch:[7] | lr:0.001976
BIAS:[0.30] | Model:[GCN] Epoch:[8/100] Loss:[0.2944] Train:[89.65] val:[82.25] Test:[75.62] | Best Val:[87.88] Update Test:[82.81] at Epoch:[7] | lr:0.001969
BIAS:[0.30] | Model:[GCN] Epoch:[9/100] Loss:[0.2913] Train:[89.81] val:[86.50] Test:[84.94] | Best Val:[87.88] Update Test:[82.81] at Epoch:[7] | lr:0.001960
BIAS:[0.30] | Model:[GCN] Epoch:[10/100] Loss:[0.2754] Train:[89.94] val:[84.25] Test:[83.75] | Best Val:[87.88] Update Test:[82.81] at Epoch:[7] | lr:0.001951
BIAS:[0.30] | Model:[GCN] Epoch:[11/100] Loss:[0.2530] Train:[90.81] val:[90.12] Test:[86.19] | Best Val:[90.12] Update Test:[86.19] at Epoch:[11] | lr:0.001941
BIAS:[0.30] | Model:[GCN] Epoch:[12/100] Loss:[0.2487] Train:[91.24] val:[88.50] Test:[85.38] | Best Val:[90.12] Update Test:[86.19] at Epoch:[11] | lr:0.001930
BIAS:[0.30] | Model:[GCN] Epoch:[13/100] Loss:[0.2437] Train:[91.21] val:[88.88] Test:[85.44] | Best Val:[90.12] Update Test:[86.19] at Epoch:[11] | lr:0.001918
BIAS:[0.30] | Model:[GCN] Epoch:[14/100] Loss:[0.2541] Train:[90.96] val:[85.00] Test:[80.94] | Best Val:[90.12] Update Test:[86.19] at Epoch:[11] | lr:0.001905
BIAS:[0.30] | Model:[GCN] Epoch:[15/100] Loss:[0.2245] Train:[91.96] val:[86.88] Test:[83.44] | Best Val:[90.12] Update Test:[86.19] at Epoch:[11] | lr:0.001891
BIAS:[0.30] | Model:[GCN] Epoch:[16/100] Loss:[0.2374] Train:[91.37] val:[88.50] Test:[82.38] | Best Val:[90.12] Update Test:[86.19] at Epoch:[11] | lr:0.001877
BIAS:[0.30] | Model:[GCN] Epoch:[17/100] Loss:[0.2333] Train:[91.67] val:[90.25] Test:[86.56] | Best Val:[90.25] Update Test:[86.56] at Epoch:[17] | lr:0.001861
BIAS:[0.30] | Model:[GCN] Epoch:[18/100] Loss:[0.2104] Train:[92.01] val:[89.62] Test:[87.56] | Best Val:[90.25] Update Test:[86.56] at Epoch:[17] | lr:0.001845
BIAS:[0.30] | Model:[GCN] Epoch:[19/100] Loss:[0.2064] Train:[92.44] val:[89.88] Test:[86.62] | Best Val:[90.25] Update Test:[86.56] at Epoch:[17] | lr:0.001828
BIAS:[0.30] | Model:[GCN] Epoch:[20/100] Loss:[0.2098] Train:[92.26] val:[91.00] Test:[88.81] | Best Val:[91.00] Update Test:[88.81] at Epoch:[20] | lr:0.001809
BIAS:[0.30] | Model:[GCN] Epoch:[21/100] Loss:[0.2027] Train:[92.67] val:[90.88] Test:[87.81] | Best Val:[91.00] Update Test:[88.81] at Epoch:[20] | lr:0.001791
BIAS:[0.30] | Model:[GCN] Epoch:[22/100] Loss:[0.1990] Train:[92.99] val:[90.62] Test:[86.81] | Best Val:[91.00] Update Test:[88.81] at Epoch:[20] | lr:0.001771
BIAS:[0.30] | Model:[GCN] Epoch:[23/100] Loss:[0.1844] Train:[93.39] val:[91.00] Test:[87.50] | Best Val:[91.00] Update Test:[88.81] at Epoch:[20] | lr:0.001751
BIAS:[0.30] | Model:[GCN] Epoch:[24/100] Loss:[0.1935] Train:[92.87] val:[91.00] Test:[87.31] | Best Val:[91.00] Update Test:[88.81] at Epoch:[20] | lr:0.001730
BIAS:[0.30] | Model:[GCN] Epoch:[25/100] Loss:[0.1836] Train:[93.46] val:[83.88] Test:[80.25] | Best Val:[91.00] Update Test:[88.81] at Epoch:[20] | lr:0.001708
BIAS:[0.30] | Model:[GCN] Epoch:[26/100] Loss:[0.1838] Train:[93.16] val:[91.38] Test:[88.12] | Best Val:[91.38] Update Test:[88.12] at Epoch:[26] | lr:0.001685
BIAS:[0.30] | Model:[GCN] Epoch:[27/100] Loss:[0.1805] Train:[93.67] val:[89.75] Test:[85.62] | Best Val:[91.38] Update Test:[88.12] at Epoch:[26] | lr:0.001662
BIAS:[0.30] | Model:[GCN] Epoch:[28/100] Loss:[0.1917] Train:[93.25] val:[87.62] Test:[84.44] | Best Val:[91.38] Update Test:[88.12] at Epoch:[26] | lr:0.001638
BIAS:[0.30] | Model:[GCN] Epoch:[29/100] Loss:[0.1727] Train:[93.80] val:[90.00] Test:[88.31] | Best Val:[91.38] Update Test:[88.12] at Epoch:[26] | lr:0.001614
BIAS:[0.30] | Model:[GCN] Epoch:[30/100] Loss:[0.1795] Train:[93.69] val:[90.50] Test:[88.38] | Best Val:[91.38] Update Test:[88.12] at Epoch:[26] | lr:0.001589
BIAS:[0.30] | Model:[GCN] Epoch:[31/100] Loss:[0.1676] Train:[93.92] val:[91.38] Test:[87.50] | Best Val:[91.38] Update Test:[88.12] at Epoch:[26] | lr:0.001563
BIAS:[0.30] | Model:[GCN] Epoch:[32/100] Loss:[0.1637] Train:[93.92] val:[88.25] Test:[84.31] | Best Val:[91.38] Update Test:[88.12] at Epoch:[26] | lr:0.001537
BIAS:[0.30] | Model:[GCN] Epoch:[33/100] Loss:[0.1561] Train:[94.46] val:[90.50] Test:[88.12] | Best Val:[91.38] Update Test:[88.12] at Epoch:[26] | lr:0.001510
BIAS:[0.30] | Model:[GCN] Epoch:[34/100] Loss:[0.1458] Train:[94.75] val:[91.62] Test:[88.56] | Best Val:[91.62] Update Test:[88.56] at Epoch:[34] | lr:0.001483
BIAS:[0.30] | Model:[GCN] Epoch:[35/100] Loss:[0.1631] Train:[94.28] val:[90.12] Test:[86.25] | Best Val:[91.62] Update Test:[88.56] at Epoch:[34] | lr:0.001455
BIAS:[0.30] | Model:[GCN] Epoch:[36/100] Loss:[0.1504] Train:[94.64] val:[91.12] Test:[89.44] | Best Val:[91.62] Update Test:[88.56] at Epoch:[34] | lr:0.001427
BIAS:[0.30] | Model:[GCN] Epoch:[37/100] Loss:[0.1586] Train:[94.26] val:[90.38] Test:[89.00] | Best Val:[91.62] Update Test:[88.56] at Epoch:[34] | lr:0.001399
BIAS:[0.30] | Model:[GCN] Epoch:[38/100] Loss:[0.1506] Train:[94.60] val:[89.50] Test:[87.31] | Best Val:[91.62] Update Test:[88.56] at Epoch:[34] | lr:0.001370
BIAS:[0.30] | Model:[GCN] Epoch:[39/100] Loss:[0.1382] Train:[94.80] val:[91.38] Test:[88.56] | Best Val:[91.62] Update Test:[88.56] at Epoch:[34] | lr:0.001340
BIAS:[0.30] | Model:[GCN] Epoch:[40/100] Loss:[0.1349] Train:[94.92] val:[92.88] Test:[88.81] | Best Val:[92.88] Update Test:[88.81] at Epoch:[40] | lr:0.001311
BIAS:[0.30] | Model:[GCN] Epoch:[41/100] Loss:[0.1283] Train:[95.23] val:[91.00] Test:[87.94] | Best Val:[92.88] Update Test:[88.81] at Epoch:[40] | lr:0.001281
BIAS:[0.30] | Model:[GCN] Epoch:[42/100] Loss:[0.1252] Train:[95.60] val:[91.38] Test:[89.75] | Best Val:[92.88] Update Test:[88.81] at Epoch:[40] | lr:0.001251
BIAS:[0.30] | Model:[GCN] Epoch:[43/100] Loss:[0.1313] Train:[95.46] val:[92.38] Test:[90.25] | Best Val:[92.88] Update Test:[88.81] at Epoch:[40] | lr:0.001220
BIAS:[0.30] | Model:[GCN] Epoch:[44/100] Loss:[0.1189] Train:[95.59] val:[89.88] Test:[88.12] | Best Val:[92.88] Update Test:[88.81] at Epoch:[40] | lr:0.001189
BIAS:[0.30] | Model:[GCN] Epoch:[45/100] Loss:[0.1285] Train:[95.09] val:[93.25] Test:[89.25] | Best Val:[93.25] Update Test:[89.25] at Epoch:[45] | lr:0.001159
BIAS:[0.30] | Model:[GCN] Epoch:[46/100] Loss:[0.1110] Train:[96.07] val:[92.38] Test:[88.31] | Best Val:[93.25] Update Test:[89.25] at Epoch:[45] | lr:0.001128
BIAS:[0.30] | Model:[GCN] Epoch:[47/100] Loss:[0.1068] Train:[96.14] val:[90.88] Test:[88.69] | Best Val:[93.25] Update Test:[89.25] at Epoch:[45] | lr:0.001096
BIAS:[0.30] | Model:[GCN] Epoch:[48/100] Loss:[0.1050] Train:[96.32] val:[93.50] Test:[88.62] | Best Val:[93.50] Update Test:[88.62] at Epoch:[48] | lr:0.001065
BIAS:[0.30] | Model:[GCN] Epoch:[49/100] Loss:[0.1109] Train:[95.75] val:[91.25] Test:[86.56] | Best Val:[93.50] Update Test:[88.62] at Epoch:[48] | lr:0.001034
BIAS:[0.30] | Model:[GCN] Epoch:[50/100] Loss:[0.1021] Train:[96.32] val:[92.88] Test:[89.56] | Best Val:[93.50] Update Test:[88.62] at Epoch:[48] | lr:0.001003
BIAS:[0.30] | Model:[GCN] Epoch:[51/100] Loss:[0.0952] Train:[96.44] val:[92.50] Test:[87.19] | Best Val:[93.50] Update Test:[88.62] at Epoch:[48] | lr:0.000971
BIAS:[0.30] | Model:[GCN] Epoch:[52/100] Loss:[0.0989] Train:[96.23] val:[92.00] Test:[87.50] | Best Val:[93.50] Update Test:[88.62] at Epoch:[48] | lr:0.000940
BIAS:[0.30] | Model:[GCN] Epoch:[53/100] Loss:[0.0925] Train:[96.75] val:[93.12] Test:[89.81] | Best Val:[93.50] Update Test:[88.62] at Epoch:[48] | lr:0.000909
BIAS:[0.30] | Model:[GCN] Epoch:[54/100] Loss:[0.0833] Train:[97.09] val:[91.00] Test:[87.44] | Best Val:[93.50] Update Test:[88.62] at Epoch:[48] | lr:0.000877
BIAS:[0.30] | Model:[GCN] Epoch:[55/100] Loss:[0.0958] Train:[96.48] val:[91.62] Test:[90.06] | Best Val:[93.50] Update Test:[88.62] at Epoch:[48] | lr:0.000846
BIAS:[0.30] | Model:[GCN] Epoch:[56/100] Loss:[0.0806] Train:[97.18] val:[89.88] Test:[90.12] | Best Val:[93.50] Update Test:[88.62] at Epoch:[48] | lr:0.000816
BIAS:[0.30] | Model:[GCN] Epoch:[57/100] Loss:[0.0880] Train:[96.66] val:[91.25] Test:[90.12] | Best Val:[93.50] Update Test:[88.62] at Epoch:[48] | lr:0.000785
BIAS:[0.30] | Model:[GCN] Epoch:[58/100] Loss:[0.0715] Train:[97.62] val:[91.88] Test:[90.19] | Best Val:[93.50] Update Test:[88.62] at Epoch:[48] | lr:0.000754
BIAS:[0.30] | Model:[GCN] Epoch:[59/100] Loss:[0.0748] Train:[96.98] val:[93.00] Test:[89.56] | Best Val:[93.50] Update Test:[88.62] at Epoch:[48] | lr:0.000724
BIAS:[0.30] | Model:[GCN] Epoch:[60/100] Loss:[0.0682] Train:[97.52] val:[93.25] Test:[89.50] | Best Val:[93.50] Update Test:[88.62] at Epoch:[48] | lr:0.000694
BIAS:[0.30] | Model:[GCN] Epoch:[61/100] Loss:[0.0685] Train:[97.55] val:[92.00] Test:[89.25] | Best Val:[93.50] Update Test:[88.62] at Epoch:[48] | lr:0.000665
BIAS:[0.30] | Model:[GCN] Epoch:[62/100] Loss:[0.0576] Train:[97.98] val:[93.25] Test:[90.12] | Best Val:[93.50] Update Test:[88.62] at Epoch:[48] | lr:0.000635
BIAS:[0.30] | Model:[GCN] Epoch:[63/100] Loss:[0.0585] Train:[97.98] val:[92.88] Test:[89.69] | Best Val:[93.50] Update Test:[88.62] at Epoch:[48] | lr:0.000606
BIAS:[0.30] | Model:[GCN] Epoch:[64/100] Loss:[0.0575] Train:[97.86] val:[93.25] Test:[90.50] | Best Val:[93.50] Update Test:[88.62] at Epoch:[48] | lr:0.000578
BIAS:[0.30] | Model:[GCN] Epoch:[65/100] Loss:[0.0479] Train:[98.21] val:[91.50] Test:[89.62] | Best Val:[93.50] Update Test:[88.62] at Epoch:[48] | lr:0.000550
BIAS:[0.30] | Model:[GCN] Epoch:[66/100] Loss:[0.0607] Train:[97.78] val:[92.62] Test:[90.25] | Best Val:[93.50] Update Test:[88.62] at Epoch:[48] | lr:0.000522
BIAS:[0.30] | Model:[GCN] Epoch:[67/100] Loss:[0.0612] Train:[97.62] val:[93.00] Test:[89.94] | Best Val:[93.50] Update Test:[88.62] at Epoch:[48] | lr:0.000495
BIAS:[0.30] | Model:[GCN] Epoch:[68/100] Loss:[0.0492] Train:[98.32] val:[92.75] Test:[90.75] | Best Val:[93.50] Update Test:[88.62] at Epoch:[48] | lr:0.000468
BIAS:[0.30] | Model:[GCN] Epoch:[69/100] Loss:[0.0433] Train:[98.48] val:[93.38] Test:[89.62] | Best Val:[93.50] Update Test:[88.62] at Epoch:[48] | lr:0.000442
BIAS:[0.30] | Model:[GCN] Epoch:[70/100] Loss:[0.0440] Train:[98.66] val:[91.62] Test:[89.62] | Best Val:[93.50] Update Test:[88.62] at Epoch:[48] | lr:0.000416
BIAS:[0.30] | Model:[GCN] Epoch:[71/100] Loss:[0.0405] Train:[98.61] val:[93.38] Test:[91.00] | Best Val:[93.50] Update Test:[88.62] at Epoch:[48] | lr:0.000391
BIAS:[0.30] | Model:[GCN] Epoch:[72/100] Loss:[0.0311] Train:[98.93] val:[93.62] Test:[90.06] | Best Val:[93.62] Update Test:[90.06] at Epoch:[72] | lr:0.000367
BIAS:[0.30] | Model:[GCN] Epoch:[73/100] Loss:[0.0286] Train:[99.14] val:[93.50] Test:[90.62] | Best Val:[93.62] Update Test:[90.06] at Epoch:[72] | lr:0.000343
BIAS:[0.30] | Model:[GCN] Epoch:[74/100] Loss:[0.0300] Train:[99.00] val:[93.25] Test:[90.50] | Best Val:[93.62] Update Test:[90.06] at Epoch:[72] | lr:0.000320
BIAS:[0.30] | Model:[GCN] Epoch:[75/100] Loss:[0.0266] Train:[99.20] val:[93.25] Test:[90.38] | Best Val:[93.62] Update Test:[90.06] at Epoch:[72] | lr:0.000297
BIAS:[0.30] | Model:[GCN] Epoch:[76/100] Loss:[0.0246] Train:[99.21] val:[93.75] Test:[90.75] | Best Val:[93.75] Update Test:[90.75] at Epoch:[76] | lr:0.000275
BIAS:[0.30] | Model:[GCN] Epoch:[77/100] Loss:[0.0233] Train:[99.27] val:[93.00] Test:[90.56] | Best Val:[93.75] Update Test:[90.75] at Epoch:[76] | lr:0.000254
BIAS:[0.30] | Model:[GCN] Epoch:[78/100] Loss:[0.0253] Train:[99.48] val:[93.38] Test:[90.25] | Best Val:[93.75] Update Test:[90.75] at Epoch:[76] | lr:0.000234
BIAS:[0.30] | Model:[GCN] Epoch:[79/100] Loss:[0.0251] Train:[99.20] val:[93.12] Test:[90.44] | Best Val:[93.75] Update Test:[90.75] at Epoch:[76] | lr:0.000214
BIAS:[0.30] | Model:[GCN] Epoch:[80/100] Loss:[0.0244] Train:[99.25] val:[93.12] Test:[89.94] | Best Val:[93.75] Update Test:[90.75] at Epoch:[76] | lr:0.000196
BIAS:[0.30] | Model:[GCN] Epoch:[81/100] Loss:[0.0209] Train:[99.48] val:[93.38] Test:[90.62] | Best Val:[93.75] Update Test:[90.75] at Epoch:[76] | lr:0.000177
BIAS:[0.30] | Model:[GCN] Epoch:[82/100] Loss:[0.0192] Train:[99.45] val:[93.50] Test:[90.50] | Best Val:[93.75] Update Test:[90.75] at Epoch:[76] | lr:0.000160
BIAS:[0.30] | Model:[GCN] Epoch:[83/100] Loss:[0.0150] Train:[99.73] val:[93.38] Test:[90.75] | Best Val:[93.75] Update Test:[90.75] at Epoch:[76] | lr:0.000144
BIAS:[0.30] | Model:[GCN] Epoch:[84/100] Loss:[0.0176] Train:[99.48] val:[93.62] Test:[90.38] | Best Val:[93.75] Update Test:[90.75] at Epoch:[76] | lr:0.000128
BIAS:[0.30] | Model:[GCN] Epoch:[85/100] Loss:[0.0123] Train:[99.86] val:[93.25] Test:[90.69] | Best Val:[93.75] Update Test:[90.75] at Epoch:[76] | lr:0.000114
BIAS:[0.30] | Model:[GCN] Epoch:[86/100] Loss:[0.0148] Train:[99.68] val:[93.50] Test:[90.56] | Best Val:[93.75] Update Test:[90.75] at Epoch:[76] | lr:0.000100
BIAS:[0.30] | Model:[GCN] Epoch:[87/100] Loss:[0.0154] Train:[99.64] val:[93.38] Test:[90.75] | Best Val:[93.75] Update Test:[90.75] at Epoch:[76] | lr:0.000087
BIAS:[0.30] | Model:[GCN] Epoch:[88/100] Loss:[0.0135] Train:[99.75] val:[93.00] Test:[90.38] | Best Val:[93.75] Update Test:[90.75] at Epoch:[76] | lr:0.000075
BIAS:[0.30] | Model:[GCN] Epoch:[89/100] Loss:[0.0119] Train:[99.75] val:[93.00] Test:[90.44] | Best Val:[93.75] Update Test:[90.75] at Epoch:[76] | lr:0.000064
BIAS:[0.30] | Model:[GCN] Epoch:[90/100] Loss:[0.0119] Train:[99.79] val:[93.75] Test:[90.38] | Best Val:[93.75] Update Test:[90.75] at Epoch:[76] | lr:0.000054
BIAS:[0.30] | Model:[GCN] Epoch:[91/100] Loss:[0.0109] Train:[99.79] val:[93.25] Test:[90.38] | Best Val:[93.75] Update Test:[90.75] at Epoch:[76] | lr:0.000045
BIAS:[0.30] | Model:[GCN] Epoch:[92/100] Loss:[0.0113] Train:[99.82] val:[93.38] Test:[90.31] | Best Val:[93.75] Update Test:[90.75] at Epoch:[76] | lr:0.000036
BIAS:[0.30] | Model:[GCN] Epoch:[93/100] Loss:[0.0124] Train:[99.73] val:[93.00] Test:[90.69] | Best Val:[93.75] Update Test:[90.75] at Epoch:[76] | lr:0.000029
BIAS:[0.30] | Model:[GCN] Epoch:[94/100] Loss:[0.0105] Train:[99.91] val:[93.25] Test:[90.06] | Best Val:[93.75] Update Test:[90.75] at Epoch:[76] | lr:0.000023
BIAS:[0.30] | Model:[GCN] Epoch:[95/100] Loss:[0.0109] Train:[99.93] val:[93.25] Test:[90.25] | Best Val:[93.75] Update Test:[90.75] at Epoch:[76] | lr:0.000017
BIAS:[0.30] | Model:[GCN] Epoch:[96/100] Loss:[0.0117] Train:[99.84] val:[93.12] Test:[90.44] | Best Val:[93.75] Update Test:[90.75] at Epoch:[76] | lr:0.000013
BIAS:[0.30] | Model:[GCN] Epoch:[97/100] Loss:[0.0108] Train:[99.84] val:[93.12] Test:[90.56] | Best Val:[93.75] Update Test:[90.75] at Epoch:[76] | lr:0.000009
BIAS:[0.30] | Model:[GCN] Epoch:[98/100] Loss:[0.0101] Train:[99.91] val:[93.50] Test:[90.44] | Best Val:[93.75] Update Test:[90.75] at Epoch:[76] | lr:0.000007
BIAS:[0.30] | Model:[GCN] Epoch:[99/100] Loss:[0.0112] Train:[99.84] val:[93.00] Test:[90.44] | Best Val:[93.75] Update Test:[90.75] at Epoch:[76] | lr:0.000005
BIAS:[0.30] | Model:[GCN] Epoch:[100/100] Loss:[0.0119] Train:[99.80] val:[92.88] Test:[90.31] | Best Val:[93.75] Update Test:[90.75] at Epoch:[76] | lr:0.000005
syd: BIAS:[0.30] | Best Val acc:[93.75] Test acc:[90.75] at epoch:[76]
step_size..................................................................0.001
min_lr.....................................................................5e-06
pretrain......................................................................30
data_num....................................................................2000
node_num......................................................................15
max_degree....................................................................10
feature_dim...................................................................-1
noise........................................................................0.1
num_classes....................................................................4
shape_num......................................................................1
bias.........................................................................0.3
penalty_weight...............................................................0.1
train_type..................................................................base
epochs.......................................................................100
batch_size...................................................................128
the............................................................................0
with_random.................................................................True
eval_random................................................................False
normalize..................................................................False
save_model.................................................................False
inference..................................................................False
without_node_attention.....................................................False
without_edge_attention.....................................................False
k..............................................................................3
layers.........................................................................3
c............................................................................0.5
o............................................................................1.0
co...........................................................................0.5
harf_hidden..................................................................0.5
cat_or_add...................................................................add
num_layers.....................................................................3
folds.........................................................................10
fc_num.......................................................................222
data_root...................................................................data
save_dir...................................................................debug
dataset.....................................................................NCI1
epoch_select............................................................test_max
model..................................................................CausalGCN
hidden.......................................................................128
seed.........................................................................666
lr.........................................................................0.002
lr_decay_factor..............................................................0.5
lr_decay_step_size...........................................................500
weight_decay...................................................................0
global_pool..................................................................sum

----------------------------------------------------------------------------------------------------
| graph: Tree-house | nodes num:246 | edges num:542 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: BA-house | nodes num:230 | edges num:996 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: Tree-cycle | nodes num:247 | edges num:542 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: BA-cycle | nodes num:231 | edges num:996 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: Tree-grid | nodes num:247 | edges num:544 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: BA-grid | nodes num:231 | edges num:998 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: Tree-diamond | nodes num:247 | edges num:546 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: BA-diamond | nodes num:231 | edges num:1000 |
----------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
Train Total:5596
| Tree: House:420  , Cycle:979  , Grids:979  , Diams:979   
| BA  : House:979  , Cycle:420  , Grids:420  , Diams:420   
| All : House:1399 , Cycle:1399 , Grids:1399 , Diams:1399  
| BIAS: House:30.0%, Cycle:70.0%, Grids:70.0%, Diams:70.0%
------------------------------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
Val    Total:800
| Tree: House:60   , Cycle:140  , Grids:140  , Diams:140   
| BA  : House:140  , Cycle:60   , Grids:60   , Diams:60    
| All : House:200  , Cycle:200  , Grids:200  , Diams:200   
| BIAS: House:30.0%, Cycle:70.0%, Grids:70.0%, Diams:70.0%
------------------------------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
Test   Total:1600
| Tree: House:200  , Cycle:200  , Grids:200  , Diams:200   
| BA  : House:200  , Cycle:200  , Grids:200  , Diams:200   
| All : House:400  , Cycle:400  , Grids:400  , Diams:400   
| BIAS: House:50.0%, Cycle:50.0%, Grids:50.0%, Diams:50.0%
------------------------------------------------------------------------------------------------------------------------------------------------------
BIAS:[0.30] | Model:[CausalGCN] Epoch:[1/100] Loss:[0.9732=0.0176+0.5994+0.7300] Train:[77.63] val:[70.25] Test:[65.75] | Update Test:[co:53.19,c:25.00,o:65.75] at Epoch:[1] | lr:0.002000
BIAS:[0.30] | Model:[CausalGCN] Epoch:[2/100] Loss:[0.5231=0.0017+0.3331+0.3785] Train:[87.40] val:[88.25] Test:[84.38] | Update Test:[co:82.38,c:24.31,o:84.38] at Epoch:[2] | lr:0.001998
BIAS:[0.30] | Model:[CausalGCN] Epoch:[3/100] Loss:[0.4636=0.0007+0.2964+0.3336] Train:[89.30] val:[88.88] Test:[86.06] | Update Test:[co:83.69,c:24.38,o:86.06] at Epoch:[3] | lr:0.001996
BIAS:[0.30] | Model:[CausalGCN] Epoch:[4/100] Loss:[0.4019=0.0004+0.2573+0.2888] Train:[90.65] val:[86.75] Test:[82.94] | Update Test:[co:83.69,c:24.38,o:86.06] at Epoch:[3] | lr:0.001992
BIAS:[0.30] | Model:[CausalGCN] Epoch:[5/100] Loss:[0.3934=0.0004+0.2546+0.2770] Train:[90.85] val:[87.75] Test:[85.31] | Update Test:[co:83.69,c:24.38,o:86.06] at Epoch:[3] | lr:0.001988
BIAS:[0.30] | Model:[CausalGCN] Epoch:[6/100] Loss:[0.3575=0.0003+0.2300+0.2547] Train:[92.07] val:[88.38] Test:[82.88] | Update Test:[co:83.69,c:24.38,o:86.06] at Epoch:[3] | lr:0.001982
BIAS:[0.30] | Model:[CausalGCN] Epoch:[7/100] Loss:[0.3421=0.0002+0.2182+0.2477] Train:[92.03] val:[90.62] Test:[85.19] | Update Test:[co:86.00,c:24.94,o:85.19] at Epoch:[7] | lr:0.001976
BIAS:[0.30] | Model:[CausalGCN] Epoch:[8/100] Loss:[0.3462=0.0002+0.2217+0.2486] Train:[91.76] val:[89.75] Test:[86.50] | Update Test:[co:86.00,c:24.94,o:85.19] at Epoch:[7] | lr:0.001969
BIAS:[0.30] | Model:[CausalGCN] Epoch:[9/100] Loss:[0.3013=0.0003+0.1926+0.2170] Train:[93.17] val:[90.88] Test:[87.75] | Update Test:[co:87.62,c:25.56,o:87.75] at Epoch:[9] | lr:0.001960
BIAS:[0.30] | Model:[CausalGCN] Epoch:[10/100] Loss:[0.3044=0.0002+0.1969+0.2147] Train:[93.01] val:[88.88] Test:[86.31] | Update Test:[co:87.62,c:25.56,o:87.75] at Epoch:[9] | lr:0.001951
BIAS:[0.30] | Model:[CausalGCN] Epoch:[11/100] Loss:[0.3052=0.0003+0.1985+0.2131] Train:[92.74] val:[91.25] Test:[86.62] | Update Test:[co:86.75,c:25.69,o:86.62] at Epoch:[11] | lr:0.001941
BIAS:[0.30] | Model:[CausalGCN] Epoch:[12/100] Loss:[0.3094=0.0002+0.1993+0.2199] Train:[92.89] val:[92.12] Test:[88.06] | Update Test:[co:87.25,c:25.56,o:88.06] at Epoch:[12] | lr:0.001930
BIAS:[0.30] | Model:[CausalGCN] Epoch:[13/100] Loss:[0.2745=0.0002+0.1750+0.1988] Train:[93.66] val:[89.12] Test:[88.94] | Update Test:[co:87.25,c:25.56,o:88.06] at Epoch:[12] | lr:0.001918
BIAS:[0.30] | Model:[CausalGCN] Epoch:[14/100] Loss:[0.2579=0.0002+0.1635+0.1886] Train:[94.05] val:[91.12] Test:[88.31] | Update Test:[co:87.25,c:25.56,o:88.06] at Epoch:[12] | lr:0.001905
BIAS:[0.30] | Model:[CausalGCN] Epoch:[15/100] Loss:[0.2551=0.0001+0.1614+0.1872] Train:[94.37] val:[92.12] Test:[90.38] | Update Test:[co:87.25,c:25.56,o:88.06] at Epoch:[12] | lr:0.001891
BIAS:[0.30] | Model:[CausalGCN] Epoch:[16/100] Loss:[0.2389=0.0002+0.1507+0.1763] Train:[94.25] val:[91.12] Test:[88.44] | Update Test:[co:87.25,c:25.56,o:88.06] at Epoch:[12] | lr:0.001877
BIAS:[0.30] | Model:[CausalGCN] Epoch:[17/100] Loss:[0.2440=0.0002+0.1541+0.1796] Train:[94.50] val:[94.25] Test:[91.50] | Update Test:[co:89.38,c:24.25,o:91.50] at Epoch:[17] | lr:0.001861
BIAS:[0.30] | Model:[CausalGCN] Epoch:[18/100] Loss:[0.2182=0.0002+0.1384+0.1594] Train:[95.16] val:[91.25] Test:[89.75] | Update Test:[co:89.38,c:24.25,o:91.50] at Epoch:[17] | lr:0.001845
BIAS:[0.30] | Model:[CausalGCN] Epoch:[19/100] Loss:[0.2107=0.0001+0.1317+0.1579] Train:[95.07] val:[93.62] Test:[90.12] | Update Test:[co:89.38,c:24.25,o:91.50] at Epoch:[17] | lr:0.001828
BIAS:[0.30] | Model:[CausalGCN] Epoch:[20/100] Loss:[0.2010=0.0001+0.1258+0.1502] Train:[95.76] val:[87.88] Test:[86.12] | Update Test:[co:89.38,c:24.25,o:91.50] at Epoch:[17] | lr:0.001809
BIAS:[0.30] | Model:[CausalGCN] Epoch:[21/100] Loss:[0.2038=0.0001+0.1297+0.1481] Train:[95.07] val:[94.25] Test:[92.06] | Update Test:[co:89.38,c:24.25,o:91.50] at Epoch:[17] | lr:0.001791
BIAS:[0.30] | Model:[CausalGCN] Epoch:[22/100] Loss:[0.2076=0.0001+0.1299+0.1553] Train:[95.50] val:[91.75] Test:[90.19] | Update Test:[co:89.38,c:24.25,o:91.50] at Epoch:[17] | lr:0.001771
BIAS:[0.30] | Model:[CausalGCN] Epoch:[23/100] Loss:[0.1891=0.0001+0.1193+0.1394] Train:[95.62] val:[93.00] Test:[91.56] | Update Test:[co:89.38,c:24.25,o:91.50] at Epoch:[17] | lr:0.001751
BIAS:[0.30] | Model:[CausalGCN] Epoch:[24/100] Loss:[0.1964=0.0001+0.1251+0.1425] Train:[95.64] val:[93.88] Test:[90.81] | Update Test:[co:89.38,c:24.25,o:91.50] at Epoch:[17] | lr:0.001730
BIAS:[0.30] | Model:[CausalGCN] Epoch:[25/100] Loss:[0.1793=0.0001+0.1123+0.1339] Train:[95.87] val:[94.62] Test:[91.88] | Update Test:[co:91.00,c:20.38,o:91.88] at Epoch:[25] | lr:0.001708
BIAS:[0.30] | Model:[CausalGCN] Epoch:[26/100] Loss:[0.1786=0.0001+0.1113+0.1346] Train:[96.28] val:[93.88] Test:[92.56] | Update Test:[co:91.00,c:20.38,o:91.88] at Epoch:[25] | lr:0.001685
BIAS:[0.30] | Model:[CausalGCN] Epoch:[27/100] Loss:[0.1602=0.0001+0.0996+0.1210] Train:[96.57] val:[93.12] Test:[92.75] | Update Test:[co:91.00,c:20.38,o:91.88] at Epoch:[25] | lr:0.001662
BIAS:[0.30] | Model:[CausalGCN] Epoch:[28/100] Loss:[0.1694=0.0001+0.1059+0.1268] Train:[96.03] val:[93.75] Test:[91.56] | Update Test:[co:91.00,c:20.38,o:91.88] at Epoch:[25] | lr:0.001638
BIAS:[0.30] | Model:[CausalGCN] Epoch:[29/100] Loss:[0.1453=0.0001+0.0898+0.1108] Train:[96.77] val:[93.38] Test:[92.19] | Update Test:[co:91.00,c:20.38,o:91.88] at Epoch:[25] | lr:0.001614
BIAS:[0.30] | Model:[CausalGCN] Epoch:[30/100] Loss:[0.1295=0.0001+0.0806+0.0978] Train:[97.18] val:[95.00] Test:[94.69] | Update Test:[co:93.50,c:25.00,o:94.69] at Epoch:[30] | lr:0.001589
BIAS:[0.30] | Model:[CausalGCN] Epoch:[31/100] Loss:[0.1410=0.0001+0.0892+0.1036] Train:[97.03] val:[94.25] Test:[92.56] | Update Test:[co:93.50,c:25.00,o:94.69] at Epoch:[30] | lr:0.001563
BIAS:[0.30] | Model:[CausalGCN] Epoch:[32/100] Loss:[0.1203=0.0001+0.0741+0.0924] Train:[97.30] val:[94.62] Test:[93.06] | Update Test:[co:93.50,c:25.00,o:94.69] at Epoch:[30] | lr:0.001537
BIAS:[0.30] | Model:[CausalGCN] Epoch:[33/100] Loss:[0.1229=0.0001+0.0764+0.0929] Train:[97.23] val:[94.12] Test:[93.19] | Update Test:[co:93.50,c:25.00,o:94.69] at Epoch:[30] | lr:0.001510
BIAS:[0.30] | Model:[CausalGCN] Epoch:[34/100] Loss:[0.1451=0.0001+0.0887+0.1127] Train:[96.93] val:[93.38] Test:[92.25] | Update Test:[co:93.50,c:25.00,o:94.69] at Epoch:[30] | lr:0.001483
BIAS:[0.30] | Model:[CausalGCN] Epoch:[35/100] Loss:[0.1394=0.0001+0.0866+0.1054] Train:[96.91] val:[95.00] Test:[91.62] | Update Test:[co:93.50,c:25.00,o:94.69] at Epoch:[30] | lr:0.001455
BIAS:[0.30] | Model:[CausalGCN] Epoch:[36/100] Loss:[0.1155=0.0001+0.0713+0.0884] Train:[97.23] val:[94.38] Test:[94.12] | Update Test:[co:93.50,c:25.00,o:94.69] at Epoch:[30] | lr:0.001427
BIAS:[0.30] | Model:[CausalGCN] Epoch:[37/100] Loss:[0.1102=0.0001+0.0678+0.0847] Train:[97.57] val:[95.12] Test:[93.44] | Update Test:[co:93.38,c:26.06,o:93.44] at Epoch:[37] | lr:0.001399
BIAS:[0.30] | Model:[CausalGCN] Epoch:[38/100] Loss:[0.0853=0.0000+0.0509+0.0688] Train:[98.25] val:[94.38] Test:[92.00] | Update Test:[co:93.38,c:26.06,o:93.44] at Epoch:[37] | lr:0.001370
BIAS:[0.30] | Model:[CausalGCN] Epoch:[39/100] Loss:[0.1039=0.0001+0.0626+0.0823] Train:[97.71] val:[93.62] Test:[92.06] | Update Test:[co:93.38,c:26.06,o:93.44] at Epoch:[37] | lr:0.001340
BIAS:[0.30] | Model:[CausalGCN] Epoch:[40/100] Loss:[0.1030=0.0001+0.0627+0.0805] Train:[97.75] val:[95.25] Test:[91.75] | Update Test:[co:93.38,c:25.50,o:91.75] at Epoch:[40] | lr:0.001311
BIAS:[0.30] | Model:[CausalGCN] Epoch:[41/100] Loss:[0.0944=0.0001+0.0585+0.0717] Train:[97.94] val:[95.25] Test:[93.62] | Update Test:[co:93.38,c:25.50,o:91.75] at Epoch:[40] | lr:0.001281
BIAS:[0.30] | Model:[CausalGCN] Epoch:[42/100] Loss:[0.0898=0.0001+0.0545+0.0706] Train:[98.27] val:[95.12] Test:[93.94] | Update Test:[co:93.38,c:25.50,o:91.75] at Epoch:[40] | lr:0.001251
BIAS:[0.30] | Model:[CausalGCN] Epoch:[43/100] Loss:[0.0963=0.0001+0.0594+0.0739] Train:[97.80] val:[95.00] Test:[93.75] | Update Test:[co:93.38,c:25.50,o:91.75] at Epoch:[40] | lr:0.001220
BIAS:[0.30] | Model:[CausalGCN] Epoch:[44/100] Loss:[0.0857=0.0001+0.0529+0.0655] Train:[98.11] val:[95.00] Test:[93.44] | Update Test:[co:93.38,c:25.50,o:91.75] at Epoch:[40] | lr:0.001189
BIAS:[0.30] | Model:[CausalGCN] Epoch:[45/100] Loss:[0.0681=0.0000+0.0412+0.0537] Train:[98.59] val:[95.88] Test:[94.50] | Update Test:[co:94.12,c:24.56,o:94.50] at Epoch:[45] | lr:0.001159
BIAS:[0.30] | Model:[CausalGCN] Epoch:[46/100] Loss:[0.0666=0.0001+0.0398+0.0535] Train:[98.70] val:[96.00] Test:[93.62] | Update Test:[co:92.81,c:26.06,o:93.62] at Epoch:[46] | lr:0.001128
BIAS:[0.30] | Model:[CausalGCN] Epoch:[47/100] Loss:[0.0677=0.0000+0.0423+0.0509] Train:[98.68] val:[95.88] Test:[93.38] | Update Test:[co:92.81,c:26.06,o:93.62] at Epoch:[46] | lr:0.001096
BIAS:[0.30] | Model:[CausalGCN] Epoch:[48/100] Loss:[0.0646=0.0000+0.0387+0.0517] Train:[98.73] val:[95.12] Test:[91.81] | Update Test:[co:92.81,c:26.06,o:93.62] at Epoch:[46] | lr:0.001065
BIAS:[0.30] | Model:[CausalGCN] Epoch:[49/100] Loss:[0.0711=0.0000+0.0441+0.0540] Train:[98.59] val:[96.38] Test:[93.88] | Update Test:[co:92.88,c:25.06,o:93.88] at Epoch:[49] | lr:0.001034
BIAS:[0.30] | Model:[CausalGCN] Epoch:[50/100] Loss:[0.0600=0.0000+0.0360+0.0480] Train:[98.86] val:[95.50] Test:[94.50] | Update Test:[co:92.88,c:25.06,o:93.88] at Epoch:[49] | lr:0.001003
BIAS:[0.30] | Model:[CausalGCN] Epoch:[51/100] Loss:[0.0509=0.0000+0.0303+0.0411] Train:[98.96] val:[95.88] Test:[93.56] | Update Test:[co:92.88,c:25.06,o:93.88] at Epoch:[49] | lr:0.000971
BIAS:[0.30] | Model:[CausalGCN] Epoch:[52/100] Loss:[0.0492=0.0000+0.0286+0.0412] Train:[98.95] val:[96.50] Test:[94.81] | Update Test:[co:94.44,c:24.25,o:94.81] at Epoch:[52] | lr:0.000940
BIAS:[0.30] | Model:[CausalGCN] Epoch:[53/100] Loss:[0.0449=0.0000+0.0260+0.0377] Train:[99.16] val:[96.25] Test:[95.19] | Update Test:[co:94.44,c:24.25,o:94.81] at Epoch:[52] | lr:0.000909
BIAS:[0.30] | Model:[CausalGCN] Epoch:[54/100] Loss:[0.0472=0.0000+0.0285+0.0374] Train:[99.21] val:[96.62] Test:[94.56] | Update Test:[co:94.06,c:24.19,o:94.56] at Epoch:[54] | lr:0.000877
BIAS:[0.30] | Model:[CausalGCN] Epoch:[55/100] Loss:[0.0435=0.0000+0.0257+0.0355] Train:[99.25] val:[96.38] Test:[94.38] | Update Test:[co:94.06,c:24.19,o:94.56] at Epoch:[54] | lr:0.000846
BIAS:[0.30] | Model:[CausalGCN] Epoch:[56/100] Loss:[0.0333=0.0000+0.0190+0.0286] Train:[99.48] val:[95.88] Test:[94.56] | Update Test:[co:94.06,c:24.19,o:94.56] at Epoch:[54] | lr:0.000816
BIAS:[0.30] | Model:[CausalGCN] Epoch:[57/100] Loss:[0.0306=0.0000+0.0176+0.0261] Train:[99.39] val:[96.38] Test:[93.94] | Update Test:[co:94.06,c:24.19,o:94.56] at Epoch:[54] | lr:0.000785
BIAS:[0.30] | Model:[CausalGCN] Epoch:[58/100] Loss:[0.0247=0.0000+0.0138+0.0218] Train:[99.57] val:[95.50] Test:[93.69] | Update Test:[co:94.06,c:24.19,o:94.56] at Epoch:[54] | lr:0.000754
BIAS:[0.30] | Model:[CausalGCN] Epoch:[59/100] Loss:[0.0371=0.0000+0.0221+0.0301] Train:[99.27] val:[96.50] Test:[94.31] | Update Test:[co:94.06,c:24.19,o:94.56] at Epoch:[54] | lr:0.000724
BIAS:[0.30] | Model:[CausalGCN] Epoch:[60/100] Loss:[0.0240=0.0000+0.0131+0.0218] Train:[99.59] val:[97.00] Test:[94.25] | Update Test:[co:93.62,c:25.00,o:94.25] at Epoch:[60] | lr:0.000694
BIAS:[0.30] | Model:[CausalGCN] Epoch:[61/100] Loss:[0.0255=0.0000+0.0138+0.0234] Train:[99.59] val:[96.75] Test:[94.00] | Update Test:[co:93.62,c:25.00,o:94.25] at Epoch:[60] | lr:0.000665
BIAS:[0.30] | Model:[CausalGCN] Epoch:[62/100] Loss:[0.0204=0.0000+0.0108+0.0192] Train:[99.77] val:[96.38] Test:[94.00] | Update Test:[co:93.62,c:25.00,o:94.25] at Epoch:[60] | lr:0.000635
BIAS:[0.30] | Model:[CausalGCN] Epoch:[63/100] Loss:[0.0178=0.0000+0.0096+0.0165] Train:[99.80] val:[97.00] Test:[94.31] | Update Test:[co:93.62,c:25.00,o:94.25] at Epoch:[60] | lr:0.000606
BIAS:[0.30] | Model:[CausalGCN] Epoch:[64/100] Loss:[0.0159=0.0000+0.0085+0.0148] Train:[99.80] val:[97.25] Test:[94.69] | Update Test:[co:94.44,c:26.56,o:94.69] at Epoch:[64] | lr:0.000578
BIAS:[0.30] | Model:[CausalGCN] Epoch:[65/100] Loss:[0.0163=0.0000+0.0090+0.0145] Train:[99.80] val:[96.38] Test:[95.00] | Update Test:[co:94.44,c:26.56,o:94.69] at Epoch:[64] | lr:0.000550
BIAS:[0.30] | Model:[CausalGCN] Epoch:[66/100] Loss:[0.0188=0.0000+0.0101+0.0175] Train:[99.71] val:[96.88] Test:[94.25] | Update Test:[co:94.44,c:26.56,o:94.69] at Epoch:[64] | lr:0.000522
BIAS:[0.30] | Model:[CausalGCN] Epoch:[67/100] Loss:[0.0165=0.0000+0.0093+0.0144] Train:[99.71] val:[95.88] Test:[93.62] | Update Test:[co:94.44,c:26.56,o:94.69] at Epoch:[64] | lr:0.000495
BIAS:[0.30] | Model:[CausalGCN] Epoch:[68/100] Loss:[0.0130=0.0000+0.0068+0.0124] Train:[99.87] val:[96.62] Test:[94.06] | Update Test:[co:94.44,c:26.56,o:94.69] at Epoch:[64] | lr:0.000468
BIAS:[0.30] | Model:[CausalGCN] Epoch:[69/100] Loss:[0.0135=0.0000+0.0072+0.0125] Train:[99.86] val:[96.38] Test:[94.00] | Update Test:[co:94.44,c:26.56,o:94.69] at Epoch:[64] | lr:0.000442
BIAS:[0.30] | Model:[CausalGCN] Epoch:[70/100] Loss:[0.0125=0.0000+0.0068+0.0113] Train:[99.93] val:[97.12] Test:[94.50] | Update Test:[co:94.44,c:26.56,o:94.69] at Epoch:[64] | lr:0.000416
BIAS:[0.30] | Model:[CausalGCN] Epoch:[71/100] Loss:[0.0135=0.0000+0.0072+0.0125] Train:[99.89] val:[96.88] Test:[93.00] | Update Test:[co:94.44,c:26.56,o:94.69] at Epoch:[64] | lr:0.000391
BIAS:[0.30] | Model:[CausalGCN] Epoch:[72/100] Loss:[0.0182=0.0000+0.0102+0.0161] Train:[99.75] val:[96.75] Test:[94.00] | Update Test:[co:94.44,c:26.56,o:94.69] at Epoch:[64] | lr:0.000367
BIAS:[0.30] | Model:[CausalGCN] Epoch:[73/100] Loss:[0.0117=0.0000+0.0062+0.0110] Train:[99.82] val:[96.62] Test:[93.94] | Update Test:[co:94.44,c:26.56,o:94.69] at Epoch:[64] | lr:0.000343
BIAS:[0.30] | Model:[CausalGCN] Epoch:[74/100] Loss:[0.0087=0.0000+0.0043+0.0088] Train:[99.95] val:[96.88] Test:[94.44] | Update Test:[co:94.44,c:26.56,o:94.69] at Epoch:[64] | lr:0.000320
BIAS:[0.30] | Model:[CausalGCN] Epoch:[75/100] Loss:[0.0082=0.0000+0.0042+0.0081] Train:[99.95] val:[96.50] Test:[93.69] | Update Test:[co:94.44,c:26.56,o:94.69] at Epoch:[64] | lr:0.000297
BIAS:[0.30] | Model:[CausalGCN] Epoch:[76/100] Loss:[0.0075=0.0000+0.0038+0.0074] Train:[99.93] val:[96.62] Test:[94.31] | Update Test:[co:94.44,c:26.56,o:94.69] at Epoch:[64] | lr:0.000275
BIAS:[0.30] | Model:[CausalGCN] Epoch:[77/100] Loss:[0.0075=0.0000+0.0039+0.0072] Train:[99.95] val:[96.88] Test:[94.50] | Update Test:[co:94.44,c:26.56,o:94.69] at Epoch:[64] | lr:0.000254
BIAS:[0.30] | Model:[CausalGCN] Epoch:[78/100] Loss:[0.0064=0.0000+0.0031+0.0066] Train:[99.98] val:[96.88] Test:[94.38] | Update Test:[co:94.44,c:26.56,o:94.69] at Epoch:[64] | lr:0.000234
BIAS:[0.30] | Model:[CausalGCN] Epoch:[79/100] Loss:[0.0059=0.0000+0.0028+0.0063] Train:[99.95] val:[97.00] Test:[94.62] | Update Test:[co:94.44,c:26.56,o:94.69] at Epoch:[64] | lr:0.000214
BIAS:[0.30] | Model:[CausalGCN] Epoch:[80/100] Loss:[0.0049=0.0000+0.0026+0.0045] Train:[99.98] val:[97.00] Test:[94.31] | Update Test:[co:94.44,c:26.56,o:94.69] at Epoch:[64] | lr:0.000196
BIAS:[0.30] | Model:[CausalGCN] Epoch:[81/100] Loss:[0.0055=0.0000+0.0028+0.0054] Train:[99.98] val:[97.12] Test:[94.56] | Update Test:[co:94.44,c:26.56,o:94.69] at Epoch:[64] | lr:0.000177
BIAS:[0.30] | Model:[CausalGCN] Epoch:[82/100] Loss:[0.0051=0.0000+0.0026+0.0050] Train:[99.96] val:[96.50] Test:[94.62] | Update Test:[co:94.44,c:26.56,o:94.69] at Epoch:[64] | lr:0.000160
BIAS:[0.30] | Model:[CausalGCN] Epoch:[83/100] Loss:[0.0064=0.0000+0.0033+0.0061] Train:[99.96] val:[97.00] Test:[94.56] | Update Test:[co:94.44,c:26.56,o:94.69] at Epoch:[64] | lr:0.000144
BIAS:[0.30] | Model:[CausalGCN] Epoch:[84/100] Loss:[0.0053=0.0000+0.0026+0.0054] Train:[99.98] val:[96.88] Test:[94.62] | Update Test:[co:94.44,c:26.56,o:94.69] at Epoch:[64] | lr:0.000128
BIAS:[0.30] | Model:[CausalGCN] Epoch:[85/100] Loss:[0.0045=0.0000+0.0024+0.0042] Train:[99.98] val:[97.12] Test:[94.25] | Update Test:[co:94.44,c:26.56,o:94.69] at Epoch:[64] | lr:0.000114
BIAS:[0.30] | Model:[CausalGCN] Epoch:[86/100] Loss:[0.0047=0.0000+0.0023+0.0049] Train:[100.00] val:[96.88] Test:[94.44] | Update Test:[co:94.44,c:26.56,o:94.69] at Epoch:[64] | lr:0.000100
BIAS:[0.30] | Model:[CausalGCN] Epoch:[87/100] Loss:[0.0041=0.0000+0.0020+0.0042] Train:[99.98] val:[96.50] Test:[94.00] | Update Test:[co:94.44,c:26.56,o:94.69] at Epoch:[64] | lr:0.000087
BIAS:[0.30] | Model:[CausalGCN] Epoch:[88/100] Loss:[0.0040=0.0000+0.0020+0.0042] Train:[99.98] val:[96.75] Test:[94.31] | Update Test:[co:94.44,c:26.56,o:94.69] at Epoch:[64] | lr:0.000075
BIAS:[0.30] | Model:[CausalGCN] Epoch:[89/100] Loss:[0.0056=0.0000+0.0028+0.0057] Train:[99.96] val:[97.00] Test:[94.69] | Update Test:[co:94.44,c:26.56,o:94.69] at Epoch:[64] | lr:0.000064
BIAS:[0.30] | Model:[CausalGCN] Epoch:[90/100] Loss:[0.0048=0.0000+0.0025+0.0045] Train:[99.98] val:[96.88] Test:[94.62] | Update Test:[co:94.44,c:26.56,o:94.69] at Epoch:[64] | lr:0.000054
BIAS:[0.30] | Model:[CausalGCN] Epoch:[91/100] Loss:[0.0051=0.0000+0.0026+0.0050] Train:[99.96] val:[96.75] Test:[94.50] | Update Test:[co:94.44,c:26.56,o:94.69] at Epoch:[64] | lr:0.000045
BIAS:[0.30] | Model:[CausalGCN] Epoch:[92/100] Loss:[0.0040=0.0000+0.0021+0.0037] Train:[99.98] val:[97.12] Test:[94.69] | Update Test:[co:94.44,c:26.56,o:94.69] at Epoch:[64] | lr:0.000036
BIAS:[0.30] | Model:[CausalGCN] Epoch:[93/100] Loss:[0.0038=0.0000+0.0020+0.0036] Train:[99.98] val:[96.75] Test:[94.56] | Update Test:[co:94.44,c:26.56,o:94.69] at Epoch:[64] | lr:0.000029
BIAS:[0.30] | Model:[CausalGCN] Epoch:[94/100] Loss:[0.0039=0.0000+0.0020+0.0039] Train:[99.98] val:[96.75] Test:[94.38] | Update Test:[co:94.44,c:26.56,o:94.69] at Epoch:[64] | lr:0.000023
BIAS:[0.30] | Model:[CausalGCN] Epoch:[95/100] Loss:[0.0036=0.0000+0.0018+0.0036] Train:[99.98] val:[97.12] Test:[94.50] | Update Test:[co:94.44,c:26.56,o:94.69] at Epoch:[64] | lr:0.000017
BIAS:[0.30] | Model:[CausalGCN] Epoch:[96/100] Loss:[0.0039=0.0000+0.0020+0.0038] Train:[99.98] val:[97.00] Test:[94.38] | Update Test:[co:94.44,c:26.56,o:94.69] at Epoch:[64] | lr:0.000013
BIAS:[0.30] | Model:[CausalGCN] Epoch:[97/100] Loss:[0.0041=0.0000+0.0021+0.0039] Train:[99.96] val:[96.88] Test:[94.69] | Update Test:[co:94.44,c:26.56,o:94.69] at Epoch:[64] | lr:0.000009
BIAS:[0.30] | Model:[CausalGCN] Epoch:[98/100] Loss:[0.0041=0.0000+0.0020+0.0043] Train:[99.98] val:[97.00] Test:[94.38] | Update Test:[co:94.44,c:26.56,o:94.69] at Epoch:[64] | lr:0.000007
BIAS:[0.30] | Model:[CausalGCN] Epoch:[99/100] Loss:[0.0056=0.0000+0.0026+0.0060] Train:[99.96] val:[96.88] Test:[94.69] | Update Test:[co:94.44,c:26.56,o:94.69] at Epoch:[64] | lr:0.000005
BIAS:[0.30] | Model:[CausalGCN] Epoch:[100/100] Loss:[0.0046=0.0000+0.0026+0.0040] Train:[99.96] val:[96.88] Test:[94.31] | Update Test:[co:94.44,c:26.56,o:94.69] at Epoch:[64] | lr:0.000005
syd: BIAS:[0.30] | Val acc:[96.88] Test acc:[co:94.44,c:26.56,o:94.69] at epoch:[64]
step_size..................................................................0.001
min_lr.....................................................................5e-06
pretrain......................................................................30
data_num....................................................................2000
node_num......................................................................15
max_degree....................................................................10
feature_dim...................................................................-1
noise........................................................................0.1
num_classes....................................................................4
shape_num......................................................................1
bias.........................................................................0.5
penalty_weight...............................................................0.1
train_type..................................................................base
epochs.......................................................................100
batch_size...................................................................128
the............................................................................0
with_random.................................................................True
eval_random................................................................False
normalize..................................................................False
save_model.................................................................False
inference..................................................................False
without_node_attention.....................................................False
without_edge_attention.....................................................False
k..............................................................................3
layers.........................................................................3
c............................................................................0.5
o............................................................................1.0
co...........................................................................0.5
harf_hidden..................................................................0.5
cat_or_add...................................................................add
num_layers.....................................................................3
folds.........................................................................10
fc_num.......................................................................222
data_root...................................................................data
save_dir...................................................................debug
dataset.....................................................................NCI1
epoch_select............................................................test_max
model........................................................................GCN
hidden.......................................................................128
seed.........................................................................666
lr.........................................................................0.002
lr_decay_factor..............................................................0.5
lr_decay_step_size...........................................................500
weight_decay...................................................................0
global_pool..................................................................sum

----------------------------------------------------------------------------------------------------
| graph: Tree-house | nodes num:246 | edges num:542 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: BA-house | nodes num:230 | edges num:996 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: Tree-cycle | nodes num:247 | edges num:542 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: BA-cycle | nodes num:231 | edges num:996 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: Tree-grid | nodes num:247 | edges num:544 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: BA-grid | nodes num:231 | edges num:998 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: Tree-diamond | nodes num:247 | edges num:546 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: BA-diamond | nodes num:231 | edges num:1000 |
----------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
Train Total:5600
| Tree: House:700  , Cycle:700  , Grids:700  , Diams:700   
| BA  : House:700  , Cycle:700  , Grids:700  , Diams:700   
| All : House:1400 , Cycle:1400 , Grids:1400 , Diams:1400  
| BIAS: House:50.0%, Cycle:50.0%, Grids:50.0%, Diams:50.0%
------------------------------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
Val    Total:800
| Tree: House:100  , Cycle:100  , Grids:100  , Diams:100   
| BA  : House:100  , Cycle:100  , Grids:100  , Diams:100   
| All : House:200  , Cycle:200  , Grids:200  , Diams:200   
| BIAS: House:50.0%, Cycle:50.0%, Grids:50.0%, Diams:50.0%
------------------------------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
Test   Total:1600
| Tree: House:200  , Cycle:200  , Grids:200  , Diams:200   
| BA  : House:200  , Cycle:200  , Grids:200  , Diams:200   
| All : House:400  , Cycle:400  , Grids:400  , Diams:400   
| BIAS: House:50.0%, Cycle:50.0%, Grids:50.0%, Diams:50.0%
------------------------------------------------------------------------------------------------------------------------------------------------------
BIAS:[0.50] | Model:[GCN] Epoch:[1/100] Loss:[0.8757] Train:[64.43] val:[49.62] Test:[49.81] | Best Val:[49.62] Update Test:[49.81] at Epoch:[1] | lr:0.002000
BIAS:[0.50] | Model:[GCN] Epoch:[2/100] Loss:[0.5541] Train:[78.86] val:[71.75] Test:[71.69] | Best Val:[71.75] Update Test:[71.69] at Epoch:[2] | lr:0.001998
BIAS:[0.50] | Model:[GCN] Epoch:[3/100] Loss:[0.4894] Train:[81.34] val:[81.75] Test:[81.44] | Best Val:[81.75] Update Test:[81.44] at Epoch:[3] | lr:0.001996
BIAS:[0.50] | Model:[GCN] Epoch:[4/100] Loss:[0.4534] Train:[82.50] val:[80.12] Test:[78.44] | Best Val:[81.75] Update Test:[81.44] at Epoch:[3] | lr:0.001992
BIAS:[0.50] | Model:[GCN] Epoch:[5/100] Loss:[0.4284] Train:[82.91] val:[80.75] Test:[80.81] | Best Val:[81.75] Update Test:[81.44] at Epoch:[3] | lr:0.001988
BIAS:[0.50] | Model:[GCN] Epoch:[6/100] Loss:[0.3942] Train:[84.89] val:[83.88] Test:[84.06] | Best Val:[83.88] Update Test:[84.06] at Epoch:[6] | lr:0.001982
BIAS:[0.50] | Model:[GCN] Epoch:[7/100] Loss:[0.3575] Train:[85.52] val:[82.50] Test:[81.19] | Best Val:[83.88] Update Test:[84.06] at Epoch:[6] | lr:0.001976
BIAS:[0.50] | Model:[GCN] Epoch:[8/100] Loss:[0.3743] Train:[85.14] val:[80.12] Test:[79.12] | Best Val:[83.88] Update Test:[84.06] at Epoch:[6] | lr:0.001969
BIAS:[0.50] | Model:[GCN] Epoch:[9/100] Loss:[0.3368] Train:[86.86] val:[85.50] Test:[85.00] | Best Val:[85.50] Update Test:[85.00] at Epoch:[9] | lr:0.001960
BIAS:[0.50] | Model:[GCN] Epoch:[10/100] Loss:[0.3309] Train:[87.54] val:[87.12] Test:[85.56] | Best Val:[87.12] Update Test:[85.56] at Epoch:[10] | lr:0.001951
BIAS:[0.50] | Model:[GCN] Epoch:[11/100] Loss:[0.3171] Train:[87.61] val:[85.12] Test:[83.69] | Best Val:[87.12] Update Test:[85.56] at Epoch:[10] | lr:0.001941
BIAS:[0.50] | Model:[GCN] Epoch:[12/100] Loss:[0.3094] Train:[88.38] val:[87.00] Test:[86.00] | Best Val:[87.12] Update Test:[85.56] at Epoch:[10] | lr:0.001930
BIAS:[0.50] | Model:[GCN] Epoch:[13/100] Loss:[0.3059] Train:[88.07] val:[86.12] Test:[84.62] | Best Val:[87.12] Update Test:[85.56] at Epoch:[10] | lr:0.001918
BIAS:[0.50] | Model:[GCN] Epoch:[14/100] Loss:[0.2879] Train:[88.80] val:[86.62] Test:[86.50] | Best Val:[87.12] Update Test:[85.56] at Epoch:[10] | lr:0.001905
BIAS:[0.50] | Model:[GCN] Epoch:[15/100] Loss:[0.2970] Train:[88.30] val:[87.88] Test:[88.25] | Best Val:[87.88] Update Test:[88.25] at Epoch:[15] | lr:0.001891
BIAS:[0.50] | Model:[GCN] Epoch:[16/100] Loss:[0.2815] Train:[88.82] val:[88.75] Test:[87.38] | Best Val:[88.75] Update Test:[87.38] at Epoch:[16] | lr:0.001877
BIAS:[0.50] | Model:[GCN] Epoch:[17/100] Loss:[0.2636] Train:[89.52] val:[90.50] Test:[88.81] | Best Val:[90.50] Update Test:[88.81] at Epoch:[17] | lr:0.001861
BIAS:[0.50] | Model:[GCN] Epoch:[18/100] Loss:[0.2632] Train:[89.79] val:[88.12] Test:[88.50] | Best Val:[90.50] Update Test:[88.81] at Epoch:[17] | lr:0.001845
BIAS:[0.50] | Model:[GCN] Epoch:[19/100] Loss:[0.2711] Train:[89.59] val:[88.00] Test:[86.31] | Best Val:[90.50] Update Test:[88.81] at Epoch:[17] | lr:0.001828
BIAS:[0.50] | Model:[GCN] Epoch:[20/100] Loss:[0.2578] Train:[90.14] val:[83.88] Test:[84.69] | Best Val:[90.50] Update Test:[88.81] at Epoch:[17] | lr:0.001809
BIAS:[0.50] | Model:[GCN] Epoch:[21/100] Loss:[0.2688] Train:[89.59] val:[86.62] Test:[86.19] | Best Val:[90.50] Update Test:[88.81] at Epoch:[17] | lr:0.001791
BIAS:[0.50] | Model:[GCN] Epoch:[22/100] Loss:[0.2459] Train:[90.64] val:[90.00] Test:[88.94] | Best Val:[90.50] Update Test:[88.81] at Epoch:[17] | lr:0.001771
BIAS:[0.50] | Model:[GCN] Epoch:[23/100] Loss:[0.2438] Train:[90.79] val:[86.00] Test:[87.12] | Best Val:[90.50] Update Test:[88.81] at Epoch:[17] | lr:0.001751
BIAS:[0.50] | Model:[GCN] Epoch:[24/100] Loss:[0.2292] Train:[91.05] val:[90.25] Test:[89.31] | Best Val:[90.50] Update Test:[88.81] at Epoch:[17] | lr:0.001730
BIAS:[0.50] | Model:[GCN] Epoch:[25/100] Loss:[0.2428] Train:[90.71] val:[88.50] Test:[88.19] | Best Val:[90.50] Update Test:[88.81] at Epoch:[17] | lr:0.001708
BIAS:[0.50] | Model:[GCN] Epoch:[26/100] Loss:[0.2221] Train:[91.70] val:[90.50] Test:[88.62] | Best Val:[90.50] Update Test:[88.81] at Epoch:[17] | lr:0.001685
BIAS:[0.50] | Model:[GCN] Epoch:[27/100] Loss:[0.2294] Train:[91.29] val:[90.75] Test:[88.50] | Best Val:[90.75] Update Test:[88.50] at Epoch:[27] | lr:0.001662
BIAS:[0.50] | Model:[GCN] Epoch:[28/100] Loss:[0.2159] Train:[92.02] val:[82.88] Test:[83.50] | Best Val:[90.75] Update Test:[88.50] at Epoch:[27] | lr:0.001638
BIAS:[0.50] | Model:[GCN] Epoch:[29/100] Loss:[0.2339] Train:[90.96] val:[90.50] Test:[89.75] | Best Val:[90.75] Update Test:[88.50] at Epoch:[27] | lr:0.001614
BIAS:[0.50] | Model:[GCN] Epoch:[30/100] Loss:[0.2236] Train:[91.12] val:[87.38] Test:[86.81] | Best Val:[90.75] Update Test:[88.50] at Epoch:[27] | lr:0.001589
BIAS:[0.50] | Model:[GCN] Epoch:[31/100] Loss:[0.2197] Train:[91.41] val:[89.50] Test:[88.25] | Best Val:[90.75] Update Test:[88.50] at Epoch:[27] | lr:0.001563
BIAS:[0.50] | Model:[GCN] Epoch:[32/100] Loss:[0.2072] Train:[91.77] val:[85.88] Test:[85.12] | Best Val:[90.75] Update Test:[88.50] at Epoch:[27] | lr:0.001537
BIAS:[0.50] | Model:[GCN] Epoch:[33/100] Loss:[0.2191] Train:[91.48] val:[90.38] Test:[89.19] | Best Val:[90.75] Update Test:[88.50] at Epoch:[27] | lr:0.001510
BIAS:[0.50] | Model:[GCN] Epoch:[34/100] Loss:[0.2023] Train:[92.05] val:[88.25] Test:[88.19] | Best Val:[90.75] Update Test:[88.50] at Epoch:[27] | lr:0.001483
BIAS:[0.50] | Model:[GCN] Epoch:[35/100] Loss:[0.1988] Train:[92.52] val:[82.50] Test:[82.94] | Best Val:[90.75] Update Test:[88.50] at Epoch:[27] | lr:0.001455
BIAS:[0.50] | Model:[GCN] Epoch:[36/100] Loss:[0.1839] Train:[93.29] val:[89.00] Test:[88.12] | Best Val:[90.75] Update Test:[88.50] at Epoch:[27] | lr:0.001427
BIAS:[0.50] | Model:[GCN] Epoch:[37/100] Loss:[0.1909] Train:[92.79] val:[92.00] Test:[90.38] | Best Val:[92.00] Update Test:[90.38] at Epoch:[37] | lr:0.001399
BIAS:[0.50] | Model:[GCN] Epoch:[38/100] Loss:[0.1814] Train:[93.07] val:[90.62] Test:[89.56] | Best Val:[92.00] Update Test:[90.38] at Epoch:[37] | lr:0.001370
BIAS:[0.50] | Model:[GCN] Epoch:[39/100] Loss:[0.1883] Train:[92.68] val:[86.75] Test:[87.12] | Best Val:[92.00] Update Test:[90.38] at Epoch:[37] | lr:0.001340
BIAS:[0.50] | Model:[GCN] Epoch:[40/100] Loss:[0.1713] Train:[93.46] val:[90.88] Test:[89.62] | Best Val:[92.00] Update Test:[90.38] at Epoch:[37] | lr:0.001311
BIAS:[0.50] | Model:[GCN] Epoch:[41/100] Loss:[0.1732] Train:[93.38] val:[91.75] Test:[90.44] | Best Val:[92.00] Update Test:[90.38] at Epoch:[37] | lr:0.001281
BIAS:[0.50] | Model:[GCN] Epoch:[42/100] Loss:[0.1666] Train:[93.66] val:[89.50] Test:[88.69] | Best Val:[92.00] Update Test:[90.38] at Epoch:[37] | lr:0.001251
BIAS:[0.50] | Model:[GCN] Epoch:[43/100] Loss:[0.1613] Train:[93.98] val:[89.62] Test:[88.75] | Best Val:[92.00] Update Test:[90.38] at Epoch:[37] | lr:0.001220
BIAS:[0.50] | Model:[GCN] Epoch:[44/100] Loss:[0.1752] Train:[93.27] val:[90.50] Test:[90.19] | Best Val:[92.00] Update Test:[90.38] at Epoch:[37] | lr:0.001189
BIAS:[0.50] | Model:[GCN] Epoch:[45/100] Loss:[0.1512] Train:[94.20] val:[92.38] Test:[91.44] | Best Val:[92.38] Update Test:[91.44] at Epoch:[45] | lr:0.001159
BIAS:[0.50] | Model:[GCN] Epoch:[46/100] Loss:[0.1564] Train:[94.30] val:[88.75] Test:[87.50] | Best Val:[92.38] Update Test:[91.44] at Epoch:[45] | lr:0.001128
BIAS:[0.50] | Model:[GCN] Epoch:[47/100] Loss:[0.1605] Train:[93.79] val:[90.38] Test:[90.75] | Best Val:[92.38] Update Test:[91.44] at Epoch:[45] | lr:0.001096
BIAS:[0.50] | Model:[GCN] Epoch:[48/100] Loss:[0.1412] Train:[95.00] val:[88.75] Test:[86.44] | Best Val:[92.38] Update Test:[91.44] at Epoch:[45] | lr:0.001065
BIAS:[0.50] | Model:[GCN] Epoch:[49/100] Loss:[0.1367] Train:[94.66] val:[90.12] Test:[90.50] | Best Val:[92.38] Update Test:[91.44] at Epoch:[45] | lr:0.001034
BIAS:[0.50] | Model:[GCN] Epoch:[50/100] Loss:[0.1335] Train:[95.20] val:[89.38] Test:[88.94] | Best Val:[92.38] Update Test:[91.44] at Epoch:[45] | lr:0.001003
BIAS:[0.50] | Model:[GCN] Epoch:[51/100] Loss:[0.1304] Train:[94.77] val:[91.75] Test:[90.38] | Best Val:[92.38] Update Test:[91.44] at Epoch:[45] | lr:0.000971
BIAS:[0.50] | Model:[GCN] Epoch:[52/100] Loss:[0.1309] Train:[95.05] val:[91.00] Test:[90.31] | Best Val:[92.38] Update Test:[91.44] at Epoch:[45] | lr:0.000940
BIAS:[0.50] | Model:[GCN] Epoch:[53/100] Loss:[0.1335] Train:[95.00] val:[89.88] Test:[88.81] | Best Val:[92.38] Update Test:[91.44] at Epoch:[45] | lr:0.000909
BIAS:[0.50] | Model:[GCN] Epoch:[54/100] Loss:[0.1179] Train:[95.68] val:[90.88] Test:[90.12] | Best Val:[92.38] Update Test:[91.44] at Epoch:[45] | lr:0.000877
BIAS:[0.50] | Model:[GCN] Epoch:[55/100] Loss:[0.1267] Train:[95.18] val:[89.38] Test:[87.94] | Best Val:[92.38] Update Test:[91.44] at Epoch:[45] | lr:0.000846
BIAS:[0.50] | Model:[GCN] Epoch:[56/100] Loss:[0.1058] Train:[95.91] val:[92.25] Test:[91.38] | Best Val:[92.38] Update Test:[91.44] at Epoch:[45] | lr:0.000816
BIAS:[0.50] | Model:[GCN] Epoch:[57/100] Loss:[0.1031] Train:[96.14] val:[91.50] Test:[90.88] | Best Val:[92.38] Update Test:[91.44] at Epoch:[45] | lr:0.000785
BIAS:[0.50] | Model:[GCN] Epoch:[58/100] Loss:[0.1095] Train:[95.71] val:[92.25] Test:[91.88] | Best Val:[92.38] Update Test:[91.44] at Epoch:[45] | lr:0.000754
BIAS:[0.50] | Model:[GCN] Epoch:[59/100] Loss:[0.0984] Train:[96.16] val:[92.75] Test:[91.25] | Best Val:[92.75] Update Test:[91.25] at Epoch:[59] | lr:0.000724
BIAS:[0.50] | Model:[GCN] Epoch:[60/100] Loss:[0.0924] Train:[96.50] val:[91.62] Test:[91.50] | Best Val:[92.75] Update Test:[91.25] at Epoch:[59] | lr:0.000694
BIAS:[0.50] | Model:[GCN] Epoch:[61/100] Loss:[0.0895] Train:[96.77] val:[88.38] Test:[88.25] | Best Val:[92.75] Update Test:[91.25] at Epoch:[59] | lr:0.000665
BIAS:[0.50] | Model:[GCN] Epoch:[62/100] Loss:[0.0867] Train:[96.59] val:[91.88] Test:[90.94] | Best Val:[92.75] Update Test:[91.25] at Epoch:[59] | lr:0.000635
BIAS:[0.50] | Model:[GCN] Epoch:[63/100] Loss:[0.0766] Train:[97.29] val:[93.50] Test:[91.31] | Best Val:[93.50] Update Test:[91.31] at Epoch:[63] | lr:0.000606
BIAS:[0.50] | Model:[GCN] Epoch:[64/100] Loss:[0.0757] Train:[97.52] val:[92.62] Test:[91.56] | Best Val:[93.50] Update Test:[91.31] at Epoch:[63] | lr:0.000578
BIAS:[0.50] | Model:[GCN] Epoch:[65/100] Loss:[0.0745] Train:[97.25] val:[91.12] Test:[90.94] | Best Val:[93.50] Update Test:[91.31] at Epoch:[63] | lr:0.000550
BIAS:[0.50] | Model:[GCN] Epoch:[66/100] Loss:[0.0653] Train:[97.80] val:[92.12] Test:[91.81] | Best Val:[93.50] Update Test:[91.31] at Epoch:[63] | lr:0.000522
BIAS:[0.50] | Model:[GCN] Epoch:[67/100] Loss:[0.0669] Train:[97.64] val:[90.62] Test:[89.56] | Best Val:[93.50] Update Test:[91.31] at Epoch:[63] | lr:0.000495
BIAS:[0.50] | Model:[GCN] Epoch:[68/100] Loss:[0.0573] Train:[98.20] val:[92.25] Test:[91.50] | Best Val:[93.50] Update Test:[91.31] at Epoch:[63] | lr:0.000468
BIAS:[0.50] | Model:[GCN] Epoch:[69/100] Loss:[0.0579] Train:[98.02] val:[91.75] Test:[91.06] | Best Val:[93.50] Update Test:[91.31] at Epoch:[63] | lr:0.000442
BIAS:[0.50] | Model:[GCN] Epoch:[70/100] Loss:[0.0590] Train:[97.77] val:[90.88] Test:[90.88] | Best Val:[93.50] Update Test:[91.31] at Epoch:[63] | lr:0.000416
BIAS:[0.50] | Model:[GCN] Epoch:[71/100] Loss:[0.0525] Train:[98.29] val:[92.62] Test:[92.12] | Best Val:[93.50] Update Test:[91.31] at Epoch:[63] | lr:0.000391
BIAS:[0.50] | Model:[GCN] Epoch:[72/100] Loss:[0.0455] Train:[98.59] val:[92.25] Test:[91.75] | Best Val:[93.50] Update Test:[91.31] at Epoch:[63] | lr:0.000367
BIAS:[0.50] | Model:[GCN] Epoch:[73/100] Loss:[0.0449] Train:[98.59] val:[90.88] Test:[91.06] | Best Val:[93.50] Update Test:[91.31] at Epoch:[63] | lr:0.000343
BIAS:[0.50] | Model:[GCN] Epoch:[74/100] Loss:[0.0441] Train:[98.71] val:[93.12] Test:[92.19] | Best Val:[93.50] Update Test:[91.31] at Epoch:[63] | lr:0.000320
BIAS:[0.50] | Model:[GCN] Epoch:[75/100] Loss:[0.0406] Train:[98.88] val:[91.75] Test:[92.25] | Best Val:[93.50] Update Test:[91.31] at Epoch:[63] | lr:0.000297
BIAS:[0.50] | Model:[GCN] Epoch:[76/100] Loss:[0.0375] Train:[98.98] val:[93.25] Test:[92.06] | Best Val:[93.50] Update Test:[91.31] at Epoch:[63] | lr:0.000275
BIAS:[0.50] | Model:[GCN] Epoch:[77/100] Loss:[0.0350] Train:[98.82] val:[91.00] Test:[91.50] | Best Val:[93.50] Update Test:[91.31] at Epoch:[63] | lr:0.000254
BIAS:[0.50] | Model:[GCN] Epoch:[78/100] Loss:[0.0302] Train:[99.18] val:[92.62] Test:[92.12] | Best Val:[93.50] Update Test:[91.31] at Epoch:[63] | lr:0.000234
BIAS:[0.50] | Model:[GCN] Epoch:[79/100] Loss:[0.0275] Train:[99.21] val:[92.62] Test:[92.00] | Best Val:[93.50] Update Test:[91.31] at Epoch:[63] | lr:0.000214
BIAS:[0.50] | Model:[GCN] Epoch:[80/100] Loss:[0.0273] Train:[99.34] val:[91.00] Test:[91.94] | Best Val:[93.50] Update Test:[91.31] at Epoch:[63] | lr:0.000196
BIAS:[0.50] | Model:[GCN] Epoch:[81/100] Loss:[0.0299] Train:[99.16] val:[91.50] Test:[91.81] | Best Val:[93.50] Update Test:[91.31] at Epoch:[63] | lr:0.000177
BIAS:[0.50] | Model:[GCN] Epoch:[82/100] Loss:[0.0251] Train:[99.52] val:[91.38] Test:[91.88] | Best Val:[93.50] Update Test:[91.31] at Epoch:[63] | lr:0.000160
BIAS:[0.50] | Model:[GCN] Epoch:[83/100] Loss:[0.0256] Train:[99.32] val:[92.62] Test:[91.69] | Best Val:[93.50] Update Test:[91.31] at Epoch:[63] | lr:0.000144
BIAS:[0.50] | Model:[GCN] Epoch:[84/100] Loss:[0.0236] Train:[99.46] val:[91.62] Test:[92.12] | Best Val:[93.50] Update Test:[91.31] at Epoch:[63] | lr:0.000128
BIAS:[0.50] | Model:[GCN] Epoch:[85/100] Loss:[0.0196] Train:[99.61] val:[92.50] Test:[92.00] | Best Val:[93.50] Update Test:[91.31] at Epoch:[63] | lr:0.000114
BIAS:[0.50] | Model:[GCN] Epoch:[86/100] Loss:[0.0192] Train:[99.62] val:[92.25] Test:[92.31] | Best Val:[93.50] Update Test:[91.31] at Epoch:[63] | lr:0.000100
BIAS:[0.50] | Model:[GCN] Epoch:[87/100] Loss:[0.0194] Train:[99.62] val:[92.38] Test:[92.00] | Best Val:[93.50] Update Test:[91.31] at Epoch:[63] | lr:0.000087
BIAS:[0.50] | Model:[GCN] Epoch:[88/100] Loss:[0.0180] Train:[99.71] val:[92.62] Test:[92.44] | Best Val:[93.50] Update Test:[91.31] at Epoch:[63] | lr:0.000075
BIAS:[0.50] | Model:[GCN] Epoch:[89/100] Loss:[0.0203] Train:[99.59] val:[90.88] Test:[91.12] | Best Val:[93.50] Update Test:[91.31] at Epoch:[63] | lr:0.000064
BIAS:[0.50] | Model:[GCN] Epoch:[90/100] Loss:[0.0192] Train:[99.62] val:[92.38] Test:[91.75] | Best Val:[93.50] Update Test:[91.31] at Epoch:[63] | lr:0.000054
BIAS:[0.50] | Model:[GCN] Epoch:[91/100] Loss:[0.0140] Train:[99.79] val:[91.62] Test:[91.81] | Best Val:[93.50] Update Test:[91.31] at Epoch:[63] | lr:0.000045
BIAS:[0.50] | Model:[GCN] Epoch:[92/100] Loss:[0.0174] Train:[99.70] val:[91.38] Test:[91.81] | Best Val:[93.50] Update Test:[91.31] at Epoch:[63] | lr:0.000036
BIAS:[0.50] | Model:[GCN] Epoch:[93/100] Loss:[0.0146] Train:[99.79] val:[91.25] Test:[91.62] | Best Val:[93.50] Update Test:[91.31] at Epoch:[63] | lr:0.000029
BIAS:[0.50] | Model:[GCN] Epoch:[94/100] Loss:[0.0191] Train:[99.66] val:[92.38] Test:[91.94] | Best Val:[93.50] Update Test:[91.31] at Epoch:[63] | lr:0.000023
BIAS:[0.50] | Model:[GCN] Epoch:[95/100] Loss:[0.0155] Train:[99.75] val:[92.12] Test:[92.00] | Best Val:[93.50] Update Test:[91.31] at Epoch:[63] | lr:0.000017
BIAS:[0.50] | Model:[GCN] Epoch:[96/100] Loss:[0.0168] Train:[99.66] val:[92.38] Test:[92.25] | Best Val:[93.50] Update Test:[91.31] at Epoch:[63] | lr:0.000013
BIAS:[0.50] | Model:[GCN] Epoch:[97/100] Loss:[0.0154] Train:[99.79] val:[92.00] Test:[92.25] | Best Val:[93.50] Update Test:[91.31] at Epoch:[63] | lr:0.000009
BIAS:[0.50] | Model:[GCN] Epoch:[98/100] Loss:[0.0160] Train:[99.71] val:[92.50] Test:[91.94] | Best Val:[93.50] Update Test:[91.31] at Epoch:[63] | lr:0.000007
BIAS:[0.50] | Model:[GCN] Epoch:[99/100] Loss:[0.0159] Train:[99.75] val:[91.88] Test:[92.06] | Best Val:[93.50] Update Test:[91.31] at Epoch:[63] | lr:0.000005
BIAS:[0.50] | Model:[GCN] Epoch:[100/100] Loss:[0.0150] Train:[99.79] val:[91.88] Test:[91.81] | Best Val:[93.50] Update Test:[91.31] at Epoch:[63] | lr:0.000005
syd: BIAS:[0.50] | Best Val acc:[93.50] Test acc:[91.31] at epoch:[63]
step_size..................................................................0.001
min_lr.....................................................................5e-06
pretrain......................................................................30
data_num....................................................................2000
node_num......................................................................15
max_degree....................................................................10
feature_dim...................................................................-1
noise........................................................................0.1
num_classes....................................................................4
shape_num......................................................................1
bias.........................................................................0.5
penalty_weight...............................................................0.1
train_type..................................................................base
epochs.......................................................................100
batch_size...................................................................128
the............................................................................0
with_random.................................................................True
eval_random................................................................False
normalize..................................................................False
save_model.................................................................False
inference..................................................................False
without_node_attention.....................................................False
without_edge_attention.....................................................False
k..............................................................................3
layers.........................................................................3
c............................................................................0.5
o............................................................................1.0
co...........................................................................0.5
harf_hidden..................................................................0.5
cat_or_add...................................................................add
num_layers.....................................................................3
folds.........................................................................10
fc_num.......................................................................222
data_root...................................................................data
save_dir...................................................................debug
dataset.....................................................................NCI1
epoch_select............................................................test_max
model..................................................................CausalGCN
hidden.......................................................................128
seed.........................................................................666
lr.........................................................................0.002
lr_decay_factor..............................................................0.5
lr_decay_step_size...........................................................500
weight_decay...................................................................0
global_pool..................................................................sum

----------------------------------------------------------------------------------------------------
| graph: Tree-house | nodes num:246 | edges num:542 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: BA-house | nodes num:230 | edges num:996 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: Tree-cycle | nodes num:247 | edges num:542 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: BA-cycle | nodes num:231 | edges num:996 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: Tree-grid | nodes num:247 | edges num:544 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: BA-grid | nodes num:231 | edges num:998 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: Tree-diamond | nodes num:247 | edges num:546 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: BA-diamond | nodes num:231 | edges num:1000 |
----------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
Train Total:5600
| Tree: House:700  , Cycle:700  , Grids:700  , Diams:700   
| BA  : House:700  , Cycle:700  , Grids:700  , Diams:700   
| All : House:1400 , Cycle:1400 , Grids:1400 , Diams:1400  
| BIAS: House:50.0%, Cycle:50.0%, Grids:50.0%, Diams:50.0%
------------------------------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
Val    Total:800
| Tree: House:100  , Cycle:100  , Grids:100  , Diams:100   
| BA  : House:100  , Cycle:100  , Grids:100  , Diams:100   
| All : House:200  , Cycle:200  , Grids:200  , Diams:200   
| BIAS: House:50.0%, Cycle:50.0%, Grids:50.0%, Diams:50.0%
------------------------------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
Test   Total:1600
| Tree: House:200  , Cycle:200  , Grids:200  , Diams:200   
| BA  : House:200  , Cycle:200  , Grids:200  , Diams:200   
| All : House:400  , Cycle:400  , Grids:400  , Diams:400   
| BIAS: House:50.0%, Cycle:50.0%, Grids:50.0%, Diams:50.0%
------------------------------------------------------------------------------------------------------------------------------------------------------
BIAS:[0.50] | Model:[CausalGCN] Epoch:[1/100] Loss:[1.1135=0.0160+0.6927+0.8257] Train:[71.70] val:[75.62] Test:[75.44] | Update Test:[co:65.62,c:26.44,o:75.44] at Epoch:[1] | lr:0.002000
BIAS:[0.50] | Model:[CausalGCN] Epoch:[2/100] Loss:[0.6442=0.0018+0.4075+0.4715] Train:[84.54] val:[84.88] Test:[84.81] | Update Test:[co:83.12,c:25.87,o:84.81] at Epoch:[2] | lr:0.001998
BIAS:[0.50] | Model:[CausalGCN] Epoch:[3/100] Loss:[0.5424=0.0011+0.3440+0.3958] Train:[87.29] val:[80.75] Test:[80.25] | Update Test:[co:83.12,c:25.87,o:84.81] at Epoch:[2] | lr:0.001996
BIAS:[0.50] | Model:[CausalGCN] Epoch:[4/100] Loss:[0.4927=0.0006+0.3159+0.3531] Train:[88.12] val:[83.50] Test:[84.06] | Update Test:[co:83.12,c:25.87,o:84.81] at Epoch:[2] | lr:0.001992
BIAS:[0.50] | Model:[CausalGCN] Epoch:[5/100] Loss:[0.4719=0.0004+0.3040+0.3353] Train:[88.25] val:[85.75] Test:[85.94] | Update Test:[co:79.31,c:24.25,o:85.94] at Epoch:[5] | lr:0.001988
BIAS:[0.50] | Model:[CausalGCN] Epoch:[6/100] Loss:[0.4628=0.0004+0.2971+0.3312] Train:[88.29] val:[89.50] Test:[89.00] | Update Test:[co:84.19,c:24.94,o:89.00] at Epoch:[6] | lr:0.001982
BIAS:[0.50] | Model:[CausalGCN] Epoch:[7/100] Loss:[0.4345=0.0005+0.2733+0.3219] Train:[89.79] val:[81.88] Test:[79.62] | Update Test:[co:84.19,c:24.94,o:89.00] at Epoch:[6] | lr:0.001976
BIAS:[0.50] | Model:[CausalGCN] Epoch:[8/100] Loss:[0.4213=0.0002+0.2705+0.3013] Train:[89.61] val:[89.00] Test:[88.50] | Update Test:[co:84.19,c:24.94,o:89.00] at Epoch:[6] | lr:0.001969
BIAS:[0.50] | Model:[CausalGCN] Epoch:[9/100] Loss:[0.3870=0.0002+0.2481+0.2776] Train:[90.77] val:[85.50] Test:[85.94] | Update Test:[co:84.19,c:24.94,o:89.00] at Epoch:[6] | lr:0.001960
BIAS:[0.50] | Model:[CausalGCN] Epoch:[10/100] Loss:[0.3708=0.0001+0.2381+0.2652] Train:[91.09] val:[92.00] Test:[90.75] | Update Test:[co:89.81,c:24.06,o:90.75] at Epoch:[10] | lr:0.001951
BIAS:[0.50] | Model:[CausalGCN] Epoch:[11/100] Loss:[0.3434=0.0001+0.2186+0.2494] Train:[91.84] val:[93.00] Test:[91.00] | Update Test:[co:90.62,c:25.37,o:91.00] at Epoch:[11] | lr:0.001941
BIAS:[0.50] | Model:[CausalGCN] Epoch:[12/100] Loss:[0.3394=0.0001+0.2143+0.2502] Train:[91.75] val:[90.00] Test:[89.00] | Update Test:[co:90.62,c:25.37,o:91.00] at Epoch:[11] | lr:0.001930
BIAS:[0.50] | Model:[CausalGCN] Epoch:[13/100] Loss:[0.3370=0.0001+0.2143+0.2454] Train:[92.25] val:[87.88] Test:[88.62] | Update Test:[co:90.62,c:25.37,o:91.00] at Epoch:[11] | lr:0.001918
BIAS:[0.50] | Model:[CausalGCN] Epoch:[14/100] Loss:[0.3276=0.0002+0.2055+0.2439] Train:[92.57] val:[83.00] Test:[84.06] | Update Test:[co:90.62,c:25.37,o:91.00] at Epoch:[11] | lr:0.001905
BIAS:[0.50] | Model:[CausalGCN] Epoch:[15/100] Loss:[0.3084=0.0002+0.1922+0.2323] Train:[92.98] val:[91.25] Test:[91.31] | Update Test:[co:90.62,c:25.37,o:91.00] at Epoch:[11] | lr:0.001891
BIAS:[0.50] | Model:[CausalGCN] Epoch:[16/100] Loss:[0.2932=0.0001+0.1824+0.2214] Train:[93.52] val:[91.88] Test:[92.12] | Update Test:[co:90.62,c:25.37,o:91.00] at Epoch:[11] | lr:0.001877
BIAS:[0.50] | Model:[CausalGCN] Epoch:[17/100] Loss:[0.2797=0.0001+0.1765+0.2062] Train:[93.29] val:[92.62] Test:[92.00] | Update Test:[co:90.62,c:25.37,o:91.00] at Epoch:[11] | lr:0.001861
BIAS:[0.50] | Model:[CausalGCN] Epoch:[18/100] Loss:[0.2831=0.0001+0.1726+0.2209] Train:[93.86] val:[92.50] Test:[90.81] | Update Test:[co:90.62,c:25.37,o:91.00] at Epoch:[11] | lr:0.001845
BIAS:[0.50] | Model:[CausalGCN] Epoch:[19/100] Loss:[0.2542=0.0001+0.1577+0.1928] Train:[94.59] val:[94.00] Test:[91.62] | Update Test:[co:90.31,c:26.06,o:91.62] at Epoch:[19] | lr:0.001828
BIAS:[0.50] | Model:[CausalGCN] Epoch:[20/100] Loss:[0.2526=0.0001+0.1553+0.1946] Train:[94.21] val:[92.12] Test:[92.44] | Update Test:[co:90.31,c:26.06,o:91.62] at Epoch:[19] | lr:0.001809
BIAS:[0.50] | Model:[CausalGCN] Epoch:[21/100] Loss:[0.2527=0.0001+0.1572+0.1908] Train:[94.11] val:[90.00] Test:[91.94] | Update Test:[co:90.31,c:26.06,o:91.62] at Epoch:[19] | lr:0.001791
BIAS:[0.50] | Model:[CausalGCN] Epoch:[22/100] Loss:[0.2505=0.0001+0.1553+0.1904] Train:[94.46] val:[93.25] Test:[93.00] | Update Test:[co:90.31,c:26.06,o:91.62] at Epoch:[19] | lr:0.001771
BIAS:[0.50] | Model:[CausalGCN] Epoch:[23/100] Loss:[0.2408=0.0001+0.1504+0.1808] Train:[94.52] val:[92.50] Test:[92.00] | Update Test:[co:90.31,c:26.06,o:91.62] at Epoch:[19] | lr:0.001751
BIAS:[0.50] | Model:[CausalGCN] Epoch:[24/100] Loss:[0.2155=0.0001+0.1324+0.1661] Train:[95.34] val:[93.50] Test:[91.88] | Update Test:[co:90.31,c:26.06,o:91.62] at Epoch:[19] | lr:0.001730
BIAS:[0.50] | Model:[CausalGCN] Epoch:[25/100] Loss:[0.2041=0.0001+0.1243+0.1595] Train:[95.73] val:[92.75] Test:[91.69] | Update Test:[co:90.31,c:26.06,o:91.62] at Epoch:[19] | lr:0.001708
BIAS:[0.50] | Model:[CausalGCN] Epoch:[26/100] Loss:[0.2000=0.0001+0.1219+0.1561] Train:[95.59] val:[92.50] Test:[91.12] | Update Test:[co:90.31,c:26.06,o:91.62] at Epoch:[19] | lr:0.001685
BIAS:[0.50] | Model:[CausalGCN] Epoch:[27/100] Loss:[0.2023=0.0001+0.1263+0.1519] Train:[95.48] val:[89.38] Test:[90.00] | Update Test:[co:90.31,c:26.06,o:91.62] at Epoch:[19] | lr:0.001662
BIAS:[0.50] | Model:[CausalGCN] Epoch:[28/100] Loss:[0.1980=0.0001+0.1224+0.1511] Train:[95.29] val:[93.75] Test:[92.50] | Update Test:[co:90.31,c:26.06,o:91.62] at Epoch:[19] | lr:0.001638
BIAS:[0.50] | Model:[CausalGCN] Epoch:[29/100] Loss:[0.1970=0.0001+0.1234+0.1469] Train:[95.48] val:[91.38] Test:[91.94] | Update Test:[co:90.31,c:26.06,o:91.62] at Epoch:[19] | lr:0.001614
BIAS:[0.50] | Model:[CausalGCN] Epoch:[30/100] Loss:[0.1537=0.0001+0.0916+0.1242] Train:[97.00] val:[92.12] Test:[92.69] | Update Test:[co:90.31,c:26.06,o:91.62] at Epoch:[19] | lr:0.001589
BIAS:[0.50] | Model:[CausalGCN] Epoch:[31/100] Loss:[0.1667=0.0001+0.1020+0.1295] Train:[96.45] val:[93.88] Test:[94.06] | Update Test:[co:90.31,c:26.06,o:91.62] at Epoch:[19] | lr:0.001563
BIAS:[0.50] | Model:[CausalGCN] Epoch:[32/100] Loss:[0.1506=0.0001+0.0915+0.1182] Train:[96.57] val:[93.50] Test:[93.12] | Update Test:[co:90.31,c:26.06,o:91.62] at Epoch:[19] | lr:0.001537
BIAS:[0.50] | Model:[CausalGCN] Epoch:[33/100] Loss:[0.1477=0.0000+0.0905+0.1144] Train:[97.04] val:[94.38] Test:[93.88] | Update Test:[co:91.88,c:24.69,o:93.88] at Epoch:[33] | lr:0.001510
BIAS:[0.50] | Model:[CausalGCN] Epoch:[34/100] Loss:[0.1531=0.0001+0.0923+0.1216] Train:[96.80] val:[93.88] Test:[93.00] | Update Test:[co:91.88,c:24.69,o:93.88] at Epoch:[33] | lr:0.001483
BIAS:[0.50] | Model:[CausalGCN] Epoch:[35/100] Loss:[0.1470=0.0001+0.0892+0.1155] Train:[96.95] val:[89.38] Test:[90.81] | Update Test:[co:91.88,c:24.69,o:93.88] at Epoch:[33] | lr:0.001455
BIAS:[0.50] | Model:[CausalGCN] Epoch:[36/100] Loss:[0.1386=0.0001+0.0841+0.1090] Train:[96.89] val:[92.00] Test:[93.00] | Update Test:[co:91.88,c:24.69,o:93.88] at Epoch:[33] | lr:0.001427
BIAS:[0.50] | Model:[CausalGCN] Epoch:[37/100] Loss:[0.1344=0.0001+0.0816+0.1054] Train:[97.18] val:[92.75] Test:[92.50] | Update Test:[co:91.88,c:24.69,o:93.88] at Epoch:[33] | lr:0.001399
BIAS:[0.50] | Model:[CausalGCN] Epoch:[38/100] Loss:[0.1201=0.0001+0.0736+0.0929] Train:[97.70] val:[94.62] Test:[93.56] | Update Test:[co:93.75,c:24.44,o:93.56] at Epoch:[38] | lr:0.001370
BIAS:[0.50] | Model:[CausalGCN] Epoch:[39/100] Loss:[0.1024=0.0001+0.0611+0.0824] Train:[97.98] val:[93.62] Test:[93.88] | Update Test:[co:93.75,c:24.44,o:93.56] at Epoch:[38] | lr:0.001340
BIAS:[0.50] | Model:[CausalGCN] Epoch:[40/100] Loss:[0.1001=0.0000+0.0583+0.0835] Train:[98.16] val:[93.62] Test:[93.00] | Update Test:[co:93.75,c:24.44,o:93.56] at Epoch:[38] | lr:0.001311
BIAS:[0.50] | Model:[CausalGCN] Epoch:[41/100] Loss:[0.1013=0.0001+0.0611+0.0802] Train:[98.09] val:[93.62] Test:[93.62] | Update Test:[co:93.75,c:24.44,o:93.56] at Epoch:[38] | lr:0.001281
BIAS:[0.50] | Model:[CausalGCN] Epoch:[42/100] Loss:[0.0872=0.0001+0.0500+0.0744] Train:[98.21] val:[94.00] Test:[93.38] | Update Test:[co:93.75,c:24.44,o:93.56] at Epoch:[38] | lr:0.001251
BIAS:[0.50] | Model:[CausalGCN] Epoch:[43/100] Loss:[0.0868=0.0000+0.0505+0.0726] Train:[98.27] val:[89.88] Test:[88.88] | Update Test:[co:93.75,c:24.44,o:93.56] at Epoch:[38] | lr:0.001220
BIAS:[0.50] | Model:[CausalGCN] Epoch:[44/100] Loss:[0.1033=0.0001+0.0632+0.0802] Train:[97.82] val:[94.00] Test:[93.88] | Update Test:[co:93.75,c:24.44,o:93.56] at Epoch:[38] | lr:0.001189
BIAS:[0.50] | Model:[CausalGCN] Epoch:[45/100] Loss:[0.0870=0.0000+0.0520+0.0701] Train:[98.18] val:[95.62] Test:[94.44] | Update Test:[co:93.75,c:25.00,o:94.44] at Epoch:[45] | lr:0.001159
BIAS:[0.50] | Model:[CausalGCN] Epoch:[46/100] Loss:[0.0778=0.0000+0.0457+0.0640] Train:[98.55] val:[95.12] Test:[94.06] | Update Test:[co:93.75,c:25.00,o:94.44] at Epoch:[45] | lr:0.001128
BIAS:[0.50] | Model:[CausalGCN] Epoch:[47/100] Loss:[0.0780=0.0000+0.0454+0.0652] Train:[98.41] val:[94.50] Test:[93.62] | Update Test:[co:93.75,c:25.00,o:94.44] at Epoch:[45] | lr:0.001096
BIAS:[0.50] | Model:[CausalGCN] Epoch:[48/100] Loss:[0.0715=0.0000+0.0424+0.0580] Train:[98.62] val:[93.00] Test:[92.75] | Update Test:[co:93.75,c:25.00,o:94.44] at Epoch:[45] | lr:0.001065
BIAS:[0.50] | Model:[CausalGCN] Epoch:[49/100] Loss:[0.0828=0.0000+0.0504+0.0648] Train:[98.27] val:[94.12] Test:[92.62] | Update Test:[co:93.75,c:25.00,o:94.44] at Epoch:[45] | lr:0.001034
BIAS:[0.50] | Model:[CausalGCN] Epoch:[50/100] Loss:[0.0844=0.0000+0.0516+0.0656] Train:[98.39] val:[94.25] Test:[94.31] | Update Test:[co:93.75,c:25.00,o:94.44] at Epoch:[45] | lr:0.001003
BIAS:[0.50] | Model:[CausalGCN] Epoch:[51/100] Loss:[0.0765=0.0000+0.0468+0.0592] Train:[98.50] val:[92.88] Test:[92.94] | Update Test:[co:93.75,c:25.00,o:94.44] at Epoch:[45] | lr:0.000971
BIAS:[0.50] | Model:[CausalGCN] Epoch:[52/100] Loss:[0.0678=0.0000+0.0391+0.0574] Train:[98.62] val:[95.25] Test:[94.31] | Update Test:[co:93.75,c:25.00,o:94.44] at Epoch:[45] | lr:0.000940
BIAS:[0.50] | Model:[CausalGCN] Epoch:[53/100] Loss:[0.0523=0.0000+0.0297+0.0451] Train:[99.07] val:[95.88] Test:[94.44] | Update Test:[co:94.31,c:26.25,o:94.44] at Epoch:[53] | lr:0.000909
BIAS:[0.50] | Model:[CausalGCN] Epoch:[54/100] Loss:[0.0425=0.0000+0.0233+0.0385] Train:[99.29] val:[94.75] Test:[94.31] | Update Test:[co:94.31,c:26.25,o:94.44] at Epoch:[53] | lr:0.000877
BIAS:[0.50] | Model:[CausalGCN] Epoch:[55/100] Loss:[0.0371=0.0000+0.0207+0.0326] Train:[99.48] val:[95.25] Test:[94.44] | Update Test:[co:94.31,c:26.25,o:94.44] at Epoch:[53] | lr:0.000846
BIAS:[0.50] | Model:[CausalGCN] Epoch:[56/100] Loss:[0.0335=0.0000+0.0189+0.0293] Train:[99.50] val:[95.12] Test:[93.88] | Update Test:[co:94.31,c:26.25,o:94.44] at Epoch:[53] | lr:0.000816
BIAS:[0.50] | Model:[CausalGCN] Epoch:[57/100] Loss:[0.0361=0.0000+0.0194+0.0334] Train:[99.39] val:[94.50] Test:[94.12] | Update Test:[co:94.31,c:26.25,o:94.44] at Epoch:[53] | lr:0.000785
BIAS:[0.50] | Model:[CausalGCN] Epoch:[58/100] Loss:[0.0277=0.0000+0.0146+0.0263] Train:[99.71] val:[95.25] Test:[94.31] | Update Test:[co:94.31,c:26.25,o:94.44] at Epoch:[53] | lr:0.000754
BIAS:[0.50] | Model:[CausalGCN] Epoch:[59/100] Loss:[0.0307=0.0000+0.0158+0.0297] Train:[99.46] val:[94.12] Test:[93.81] | Update Test:[co:94.31,c:26.25,o:94.44] at Epoch:[53] | lr:0.000724
BIAS:[0.50] | Model:[CausalGCN] Epoch:[60/100] Loss:[0.0367=0.0000+0.0199+0.0334] Train:[99.38] val:[95.75] Test:[94.38] | Update Test:[co:94.31,c:26.25,o:94.44] at Epoch:[53] | lr:0.000694
BIAS:[0.50] | Model:[CausalGCN] Epoch:[61/100] Loss:[0.0348=0.0000+0.0188+0.0320] Train:[99.32] val:[95.62] Test:[93.94] | Update Test:[co:94.31,c:26.25,o:94.44] at Epoch:[53] | lr:0.000665
BIAS:[0.50] | Model:[CausalGCN] Epoch:[62/100] Loss:[0.0269=0.0000+0.0143+0.0251] Train:[99.64] val:[95.00] Test:[93.81] | Update Test:[co:94.31,c:26.25,o:94.44] at Epoch:[53] | lr:0.000635
BIAS:[0.50] | Model:[CausalGCN] Epoch:[63/100] Loss:[0.0281=0.0000+0.0151+0.0258] Train:[99.55] val:[95.25] Test:[93.81] | Update Test:[co:94.31,c:26.25,o:94.44] at Epoch:[53] | lr:0.000606
BIAS:[0.50] | Model:[CausalGCN] Epoch:[64/100] Loss:[0.0246=0.0000+0.0130+0.0234] Train:[99.75] val:[95.62] Test:[94.12] | Update Test:[co:94.31,c:26.25,o:94.44] at Epoch:[53] | lr:0.000578
BIAS:[0.50] | Model:[CausalGCN] Epoch:[65/100] Loss:[0.0252=0.0000+0.0135+0.0232] Train:[99.71] val:[95.50] Test:[94.19] | Update Test:[co:94.31,c:26.25,o:94.44] at Epoch:[53] | lr:0.000550
BIAS:[0.50] | Model:[CausalGCN] Epoch:[66/100] Loss:[0.0334=0.0000+0.0177+0.0315] Train:[99.55] val:[94.75] Test:[93.62] | Update Test:[co:94.31,c:26.25,o:94.44] at Epoch:[53] | lr:0.000522
BIAS:[0.50] | Model:[CausalGCN] Epoch:[67/100] Loss:[0.0213=0.0000+0.0110+0.0205] Train:[99.73] val:[95.50] Test:[95.00] | Update Test:[co:94.31,c:26.25,o:94.44] at Epoch:[53] | lr:0.000495
BIAS:[0.50] | Model:[CausalGCN] Epoch:[68/100] Loss:[0.0143=0.0000+0.0067+0.0152] Train:[99.95] val:[95.62] Test:[94.38] | Update Test:[co:94.31,c:26.25,o:94.44] at Epoch:[53] | lr:0.000468
BIAS:[0.50] | Model:[CausalGCN] Epoch:[69/100] Loss:[0.0145=0.0000+0.0074+0.0141] Train:[99.89] val:[94.75] Test:[94.44] | Update Test:[co:94.31,c:26.25,o:94.44] at Epoch:[53] | lr:0.000442
BIAS:[0.50] | Model:[CausalGCN] Epoch:[70/100] Loss:[0.0166=0.0000+0.0080+0.0171] Train:[99.82] val:[95.88] Test:[94.69] | Update Test:[co:94.31,c:26.25,o:94.44] at Epoch:[53] | lr:0.000416
BIAS:[0.50] | Model:[CausalGCN] Epoch:[71/100] Loss:[0.0117=0.0000+0.0060+0.0114] Train:[99.89] val:[95.25] Test:[94.50] | Update Test:[co:94.31,c:26.25,o:94.44] at Epoch:[53] | lr:0.000391
BIAS:[0.50] | Model:[CausalGCN] Epoch:[72/100] Loss:[0.0123=0.0000+0.0060+0.0126] Train:[99.93] val:[95.75] Test:[94.69] | Update Test:[co:94.31,c:26.25,o:94.44] at Epoch:[53] | lr:0.000367
BIAS:[0.50] | Model:[CausalGCN] Epoch:[73/100] Loss:[0.0106=0.0000+0.0051+0.0108] Train:[99.93] val:[95.88] Test:[94.81] | Update Test:[co:94.31,c:26.25,o:94.44] at Epoch:[53] | lr:0.000343
BIAS:[0.50] | Model:[CausalGCN] Epoch:[74/100] Loss:[0.0100=0.0000+0.0047+0.0105] Train:[99.93] val:[95.62] Test:[95.00] | Update Test:[co:94.31,c:26.25,o:94.44] at Epoch:[53] | lr:0.000320
BIAS:[0.50] | Model:[CausalGCN] Epoch:[75/100] Loss:[0.0099=0.0000+0.0047+0.0104] Train:[99.95] val:[95.50] Test:[94.81] | Update Test:[co:94.31,c:26.25,o:94.44] at Epoch:[53] | lr:0.000297
BIAS:[0.50] | Model:[CausalGCN] Epoch:[76/100] Loss:[0.0128=0.0000+0.0066+0.0123] Train:[99.80] val:[95.62] Test:[94.94] | Update Test:[co:94.31,c:26.25,o:94.44] at Epoch:[53] | lr:0.000275
BIAS:[0.50] | Model:[CausalGCN] Epoch:[77/100] Loss:[0.0095=0.0000+0.0050+0.0090] Train:[99.91] val:[95.12] Test:[94.75] | Update Test:[co:94.31,c:26.25,o:94.44] at Epoch:[53] | lr:0.000254
BIAS:[0.50] | Model:[CausalGCN] Epoch:[78/100] Loss:[0.0088=0.0000+0.0047+0.0081] Train:[99.93] val:[95.62] Test:[94.81] | Update Test:[co:94.31,c:26.25,o:94.44] at Epoch:[53] | lr:0.000234
BIAS:[0.50] | Model:[CausalGCN] Epoch:[79/100] Loss:[0.0098=0.0000+0.0051+0.0095] Train:[99.95] val:[95.50] Test:[94.75] | Update Test:[co:94.31,c:26.25,o:94.44] at Epoch:[53] | lr:0.000214
BIAS:[0.50] | Model:[CausalGCN] Epoch:[80/100] Loss:[0.0078=0.0000+0.0038+0.0080] Train:[99.93] val:[95.62] Test:[94.75] | Update Test:[co:94.31,c:26.25,o:94.44] at Epoch:[53] | lr:0.000196
BIAS:[0.50] | Model:[CausalGCN] Epoch:[81/100] Loss:[0.0085=0.0000+0.0045+0.0081] Train:[99.91] val:[95.62] Test:[94.94] | Update Test:[co:94.31,c:26.25,o:94.44] at Epoch:[53] | lr:0.000177
BIAS:[0.50] | Model:[CausalGCN] Epoch:[82/100] Loss:[0.0081=0.0000+0.0043+0.0077] Train:[99.96] val:[95.75] Test:[95.06] | Update Test:[co:94.31,c:26.25,o:94.44] at Epoch:[53] | lr:0.000160
BIAS:[0.50] | Model:[CausalGCN] Epoch:[83/100] Loss:[0.0061=0.0000+0.0031+0.0060] Train:[99.95] val:[95.75] Test:[95.38] | Update Test:[co:94.31,c:26.25,o:94.44] at Epoch:[53] | lr:0.000144
BIAS:[0.50] | Model:[CausalGCN] Epoch:[84/100] Loss:[0.0059=0.0000+0.0029+0.0061] Train:[99.96] val:[95.75] Test:[94.94] | Update Test:[co:94.31,c:26.25,o:94.44] at Epoch:[53] | lr:0.000128
BIAS:[0.50] | Model:[CausalGCN] Epoch:[85/100] Loss:[0.0076=0.0000+0.0038+0.0076] Train:[99.96] val:[95.25] Test:[95.12] | Update Test:[co:94.31,c:26.25,o:94.44] at Epoch:[53] | lr:0.000114
BIAS:[0.50] | Model:[CausalGCN] Epoch:[86/100] Loss:[0.0091=0.0000+0.0047+0.0087] Train:[99.93] val:[95.88] Test:[94.75] | Update Test:[co:94.31,c:26.25,o:94.44] at Epoch:[53] | lr:0.000100
BIAS:[0.50] | Model:[CausalGCN] Epoch:[87/100] Loss:[0.0063=0.0000+0.0032+0.0060] Train:[99.96] val:[95.50] Test:[94.81] | Update Test:[co:94.31,c:26.25,o:94.44] at Epoch:[53] | lr:0.000087
BIAS:[0.50] | Model:[CausalGCN] Epoch:[88/100] Loss:[0.0054=0.0000+0.0027+0.0053] Train:[99.96] val:[95.62] Test:[94.94] | Update Test:[co:94.31,c:26.25,o:94.44] at Epoch:[53] | lr:0.000075
BIAS:[0.50] | Model:[CausalGCN] Epoch:[89/100] Loss:[0.0067=0.0000+0.0033+0.0068] Train:[99.95] val:[95.62] Test:[94.81] | Update Test:[co:94.31,c:26.25,o:94.44] at Epoch:[53] | lr:0.000064
BIAS:[0.50] | Model:[CausalGCN] Epoch:[90/100] Loss:[0.0051=0.0000+0.0024+0.0054] Train:[99.98] val:[95.50] Test:[94.81] | Update Test:[co:94.31,c:26.25,o:94.44] at Epoch:[53] | lr:0.000054
BIAS:[0.50] | Model:[CausalGCN] Epoch:[91/100] Loss:[0.0063=0.0000+0.0032+0.0061] Train:[99.96] val:[95.38] Test:[95.31] | Update Test:[co:94.31,c:26.25,o:94.44] at Epoch:[53] | lr:0.000045
BIAS:[0.50] | Model:[CausalGCN] Epoch:[92/100] Loss:[0.0051=0.0000+0.0027+0.0047] Train:[99.96] val:[95.62] Test:[94.94] | Update Test:[co:94.31,c:26.25,o:94.44] at Epoch:[53] | lr:0.000036
BIAS:[0.50] | Model:[CausalGCN] Epoch:[93/100] Loss:[0.0060=0.0000+0.0030+0.0060] Train:[99.98] val:[95.50] Test:[95.06] | Update Test:[co:94.31,c:26.25,o:94.44] at Epoch:[53] | lr:0.000029
BIAS:[0.50] | Model:[CausalGCN] Epoch:[94/100] Loss:[0.0056=0.0000+0.0028+0.0055] Train:[99.98] val:[95.50] Test:[94.88] | Update Test:[co:94.31,c:26.25,o:94.44] at Epoch:[53] | lr:0.000023
BIAS:[0.50] | Model:[CausalGCN] Epoch:[95/100] Loss:[0.0061=0.0000+0.0031+0.0059] Train:[99.98] val:[95.62] Test:[95.19] | Update Test:[co:94.31,c:26.25,o:94.44] at Epoch:[53] | lr:0.000017
BIAS:[0.50] | Model:[CausalGCN] Epoch:[96/100] Loss:[0.0059=0.0000+0.0029+0.0060] Train:[99.96] val:[95.75] Test:[94.94] | Update Test:[co:94.31,c:26.25,o:94.44] at Epoch:[53] | lr:0.000013
BIAS:[0.50] | Model:[CausalGCN] Epoch:[97/100] Loss:[0.0061=0.0000+0.0031+0.0059] Train:[99.98] val:[96.00] Test:[94.94] | Update Test:[co:95.12,c:24.38,o:94.94] at Epoch:[97] | lr:0.000009
BIAS:[0.50] | Model:[CausalGCN] Epoch:[98/100] Loss:[0.0051=0.0000+0.0026+0.0049] Train:[99.98] val:[95.62] Test:[94.88] | Update Test:[co:95.12,c:24.38,o:94.94] at Epoch:[97] | lr:0.000007
BIAS:[0.50] | Model:[CausalGCN] Epoch:[99/100] Loss:[0.0062=0.0000+0.0033+0.0060] Train:[99.95] val:[95.62] Test:[94.88] | Update Test:[co:95.12,c:24.38,o:94.94] at Epoch:[97] | lr:0.000005
BIAS:[0.50] | Model:[CausalGCN] Epoch:[100/100] Loss:[0.0058=0.0000+0.0030+0.0056] Train:[99.95] val:[95.50] Test:[94.94] | Update Test:[co:95.12,c:24.38,o:94.94] at Epoch:[97] | lr:0.000005
syd: BIAS:[0.50] | Val acc:[95.50] Test acc:[co:95.12,c:24.38,o:94.94] at epoch:[97]
step_size..................................................................0.001
min_lr.....................................................................5e-06
pretrain......................................................................30
data_num....................................................................2000
node_num......................................................................15
max_degree....................................................................10
feature_dim...................................................................-1
noise........................................................................0.1
num_classes....................................................................4
shape_num......................................................................1
bias.........................................................................0.7
penalty_weight...............................................................0.1
train_type..................................................................base
epochs.......................................................................100
batch_size...................................................................128
the............................................................................0
with_random.................................................................True
eval_random................................................................False
normalize..................................................................False
save_model.................................................................False
inference..................................................................False
without_node_attention.....................................................False
without_edge_attention.....................................................False
k..............................................................................3
layers.........................................................................3
c............................................................................0.5
o............................................................................1.0
co...........................................................................0.5
harf_hidden..................................................................0.5
cat_or_add...................................................................add
num_layers.....................................................................3
folds.........................................................................10
fc_num.......................................................................222
data_root...................................................................data
save_dir...................................................................debug
dataset.....................................................................NCI1
epoch_select............................................................test_max
model........................................................................GCN
hidden.......................................................................128
seed.........................................................................666
lr.........................................................................0.002
lr_decay_factor..............................................................0.5
lr_decay_step_size...........................................................500
weight_decay...................................................................0
global_pool..................................................................sum

----------------------------------------------------------------------------------------------------
| graph: Tree-house | nodes num:246 | edges num:542 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: BA-house | nodes num:230 | edges num:996 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: Tree-cycle | nodes num:247 | edges num:542 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: BA-cycle | nodes num:231 | edges num:996 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: Tree-grid | nodes num:247 | edges num:544 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: BA-grid | nodes num:231 | edges num:998 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: Tree-diamond | nodes num:247 | edges num:546 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: BA-diamond | nodes num:231 | edges num:1000 |
----------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
Train Total:5596
| Tree: House:979  , Cycle:420  , Grids:420  , Diams:420   
| BA  : House:420  , Cycle:979  , Grids:979  , Diams:979   
| All : House:1399 , Cycle:1399 , Grids:1399 , Diams:1399  
| BIAS: House:70.0%, Cycle:30.0%, Grids:30.0%, Diams:30.0%
------------------------------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
Val    Total:800
| Tree: House:140  , Cycle:60   , Grids:60   , Diams:60    
| BA  : House:60   , Cycle:140  , Grids:140  , Diams:140   
| All : House:200  , Cycle:200  , Grids:200  , Diams:200   
| BIAS: House:70.0%, Cycle:30.0%, Grids:30.0%, Diams:30.0%
------------------------------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
Test   Total:1600
| Tree: House:200  , Cycle:200  , Grids:200  , Diams:200   
| BA  : House:200  , Cycle:200  , Grids:200  , Diams:200   
| All : House:400  , Cycle:400  , Grids:400  , Diams:400   
| BIAS: House:50.0%, Cycle:50.0%, Grids:50.0%, Diams:50.0%
------------------------------------------------------------------------------------------------------------------------------------------------------
BIAS:[0.70] | Model:[GCN] Epoch:[1/100] Loss:[0.8740] Train:[62.76] val:[48.38] Test:[38.12] | Best Val:[48.38] Update Test:[38.12] at Epoch:[1] | lr:0.002000
BIAS:[0.70] | Model:[GCN] Epoch:[2/100] Loss:[0.5942] Train:[76.48] val:[75.50] Test:[72.31] | Best Val:[75.50] Update Test:[72.31] at Epoch:[2] | lr:0.001998
BIAS:[0.70] | Model:[GCN] Epoch:[3/100] Loss:[0.5060] Train:[79.61] val:[81.00] Test:[81.62] | Best Val:[81.00] Update Test:[81.62] at Epoch:[3] | lr:0.001996
BIAS:[0.70] | Model:[GCN] Epoch:[4/100] Loss:[0.4702] Train:[80.90] val:[81.50] Test:[77.00] | Best Val:[81.50] Update Test:[77.00] at Epoch:[4] | lr:0.001992
BIAS:[0.70] | Model:[GCN] Epoch:[5/100] Loss:[0.4096] Train:[83.67] val:[80.62] Test:[84.12] | Best Val:[81.50] Update Test:[77.00] at Epoch:[4] | lr:0.001988
BIAS:[0.70] | Model:[GCN] Epoch:[6/100] Loss:[0.3962] Train:[83.93] val:[81.88] Test:[80.38] | Best Val:[81.88] Update Test:[80.38] at Epoch:[6] | lr:0.001982
BIAS:[0.70] | Model:[GCN] Epoch:[7/100] Loss:[0.3889] Train:[84.58] val:[82.88] Test:[84.88] | Best Val:[82.88] Update Test:[84.88] at Epoch:[7] | lr:0.001976
BIAS:[0.70] | Model:[GCN] Epoch:[8/100] Loss:[0.3613] Train:[85.36] val:[81.62] Test:[80.12] | Best Val:[82.88] Update Test:[84.88] at Epoch:[7] | lr:0.001969
BIAS:[0.70] | Model:[GCN] Epoch:[9/100] Loss:[0.3371] Train:[86.87] val:[84.50] Test:[80.81] | Best Val:[84.50] Update Test:[80.81] at Epoch:[9] | lr:0.001960
BIAS:[0.70] | Model:[GCN] Epoch:[10/100] Loss:[0.3467] Train:[86.58] val:[76.38] Test:[70.81] | Best Val:[84.50] Update Test:[80.81] at Epoch:[9] | lr:0.001951
BIAS:[0.70] | Model:[GCN] Epoch:[11/100] Loss:[0.3222] Train:[87.12] val:[86.50] Test:[85.69] | Best Val:[86.50] Update Test:[85.69] at Epoch:[11] | lr:0.001941
BIAS:[0.70] | Model:[GCN] Epoch:[12/100] Loss:[0.3367] Train:[86.95] val:[84.25] Test:[83.81] | Best Val:[86.50] Update Test:[85.69] at Epoch:[11] | lr:0.001930
BIAS:[0.70] | Model:[GCN] Epoch:[13/100] Loss:[0.3081] Train:[87.92] val:[84.00] Test:[86.25] | Best Val:[86.50] Update Test:[85.69] at Epoch:[11] | lr:0.001918
BIAS:[0.70] | Model:[GCN] Epoch:[14/100] Loss:[0.3114] Train:[88.13] val:[85.38] Test:[84.31] | Best Val:[86.50] Update Test:[85.69] at Epoch:[11] | lr:0.001905
BIAS:[0.70] | Model:[GCN] Epoch:[15/100] Loss:[0.2962] Train:[88.17] val:[86.00] Test:[85.12] | Best Val:[86.50] Update Test:[85.69] at Epoch:[11] | lr:0.001891
BIAS:[0.70] | Model:[GCN] Epoch:[16/100] Loss:[0.2832] Train:[88.80] val:[85.12] Test:[86.12] | Best Val:[86.50] Update Test:[85.69] at Epoch:[11] | lr:0.001877
BIAS:[0.70] | Model:[GCN] Epoch:[17/100] Loss:[0.2842] Train:[88.81] val:[88.12] Test:[87.81] | Best Val:[88.12] Update Test:[87.81] at Epoch:[17] | lr:0.001861
BIAS:[0.70] | Model:[GCN] Epoch:[18/100] Loss:[0.2871] Train:[88.87] val:[86.88] Test:[85.81] | Best Val:[88.12] Update Test:[87.81] at Epoch:[17] | lr:0.001845
BIAS:[0.70] | Model:[GCN] Epoch:[19/100] Loss:[0.2690] Train:[89.46] val:[87.88] Test:[87.19] | Best Val:[88.12] Update Test:[87.81] at Epoch:[17] | lr:0.001828
BIAS:[0.70] | Model:[GCN] Epoch:[20/100] Loss:[0.2720] Train:[89.31] val:[87.50] Test:[87.56] | Best Val:[88.12] Update Test:[87.81] at Epoch:[17] | lr:0.001809
BIAS:[0.70] | Model:[GCN] Epoch:[21/100] Loss:[0.2716] Train:[89.58] val:[85.25] Test:[85.19] | Best Val:[88.12] Update Test:[87.81] at Epoch:[17] | lr:0.001791
BIAS:[0.70] | Model:[GCN] Epoch:[22/100] Loss:[0.2557] Train:[90.21] val:[87.12] Test:[85.50] | Best Val:[88.12] Update Test:[87.81] at Epoch:[17] | lr:0.001771
BIAS:[0.70] | Model:[GCN] Epoch:[23/100] Loss:[0.2416] Train:[90.42] val:[87.00] Test:[86.50] | Best Val:[88.12] Update Test:[87.81] at Epoch:[17] | lr:0.001751
BIAS:[0.70] | Model:[GCN] Epoch:[24/100] Loss:[0.2382] Train:[90.83] val:[89.25] Test:[89.62] | Best Val:[89.25] Update Test:[89.62] at Epoch:[24] | lr:0.001730
BIAS:[0.70] | Model:[GCN] Epoch:[25/100] Loss:[0.2347] Train:[90.99] val:[89.12] Test:[88.94] | Best Val:[89.25] Update Test:[89.62] at Epoch:[24] | lr:0.001708
BIAS:[0.70] | Model:[GCN] Epoch:[26/100] Loss:[0.2711] Train:[89.37] val:[88.88] Test:[87.19] | Best Val:[89.25] Update Test:[89.62] at Epoch:[24] | lr:0.001685
BIAS:[0.70] | Model:[GCN] Epoch:[27/100] Loss:[0.2500] Train:[89.96] val:[88.25] Test:[88.12] | Best Val:[89.25] Update Test:[89.62] at Epoch:[24] | lr:0.001662
BIAS:[0.70] | Model:[GCN] Epoch:[28/100] Loss:[0.2220] Train:[91.26] val:[88.12] Test:[88.25] | Best Val:[89.25] Update Test:[89.62] at Epoch:[24] | lr:0.001638
BIAS:[0.70] | Model:[GCN] Epoch:[29/100] Loss:[0.2126] Train:[92.05] val:[88.38] Test:[87.62] | Best Val:[89.25] Update Test:[89.62] at Epoch:[24] | lr:0.001614
BIAS:[0.70] | Model:[GCN] Epoch:[30/100] Loss:[0.2190] Train:[91.60] val:[89.12] Test:[87.94] | Best Val:[89.25] Update Test:[89.62] at Epoch:[24] | lr:0.001589
BIAS:[0.70] | Model:[GCN] Epoch:[31/100] Loss:[0.1998] Train:[92.17] val:[87.75] Test:[89.69] | Best Val:[89.25] Update Test:[89.62] at Epoch:[24] | lr:0.001563
BIAS:[0.70] | Model:[GCN] Epoch:[32/100] Loss:[0.2037] Train:[92.14] val:[85.50] Test:[85.88] | Best Val:[89.25] Update Test:[89.62] at Epoch:[24] | lr:0.001537
BIAS:[0.70] | Model:[GCN] Epoch:[33/100] Loss:[0.1999] Train:[92.14] val:[89.00] Test:[89.06] | Best Val:[89.25] Update Test:[89.62] at Epoch:[24] | lr:0.001510
BIAS:[0.70] | Model:[GCN] Epoch:[34/100] Loss:[0.1961] Train:[92.39] val:[86.25] Test:[84.12] | Best Val:[89.25] Update Test:[89.62] at Epoch:[24] | lr:0.001483
BIAS:[0.70] | Model:[GCN] Epoch:[35/100] Loss:[0.1879] Train:[92.83] val:[89.88] Test:[88.31] | Best Val:[89.88] Update Test:[88.31] at Epoch:[35] | lr:0.001455
BIAS:[0.70] | Model:[GCN] Epoch:[36/100] Loss:[0.1814] Train:[92.80] val:[89.12] Test:[89.00] | Best Val:[89.88] Update Test:[88.31] at Epoch:[35] | lr:0.001427
BIAS:[0.70] | Model:[GCN] Epoch:[37/100] Loss:[0.1732] Train:[93.41] val:[91.00] Test:[89.25] | Best Val:[91.00] Update Test:[89.25] at Epoch:[37] | lr:0.001399
BIAS:[0.70] | Model:[GCN] Epoch:[38/100] Loss:[0.1737] Train:[93.16] val:[90.00] Test:[89.19] | Best Val:[91.00] Update Test:[89.25] at Epoch:[37] | lr:0.001370
BIAS:[0.70] | Model:[GCN] Epoch:[39/100] Loss:[0.1704] Train:[93.32] val:[89.12] Test:[89.56] | Best Val:[91.00] Update Test:[89.25] at Epoch:[37] | lr:0.001340
BIAS:[0.70] | Model:[GCN] Epoch:[40/100] Loss:[0.1473] Train:[94.30] val:[88.38] Test:[89.69] | Best Val:[91.00] Update Test:[89.25] at Epoch:[37] | lr:0.001311
BIAS:[0.70] | Model:[GCN] Epoch:[41/100] Loss:[0.1601] Train:[93.80] val:[88.88] Test:[89.56] | Best Val:[91.00] Update Test:[89.25] at Epoch:[37] | lr:0.001281
BIAS:[0.70] | Model:[GCN] Epoch:[42/100] Loss:[0.1542] Train:[93.96] val:[90.62] Test:[87.75] | Best Val:[91.00] Update Test:[89.25] at Epoch:[37] | lr:0.001251
BIAS:[0.70] | Model:[GCN] Epoch:[43/100] Loss:[0.1513] Train:[94.35] val:[89.75] Test:[90.38] | Best Val:[91.00] Update Test:[89.25] at Epoch:[37] | lr:0.001220
BIAS:[0.70] | Model:[GCN] Epoch:[44/100] Loss:[0.1394] Train:[94.51] val:[87.88] Test:[90.12] | Best Val:[91.00] Update Test:[89.25] at Epoch:[37] | lr:0.001189
BIAS:[0.70] | Model:[GCN] Epoch:[45/100] Loss:[0.1255] Train:[95.00] val:[90.88] Test:[89.69] | Best Val:[91.00] Update Test:[89.25] at Epoch:[37] | lr:0.001159
BIAS:[0.70] | Model:[GCN] Epoch:[46/100] Loss:[0.1382] Train:[94.75] val:[90.50] Test:[89.38] | Best Val:[91.00] Update Test:[89.25] at Epoch:[37] | lr:0.001128
BIAS:[0.70] | Model:[GCN] Epoch:[47/100] Loss:[0.1281] Train:[95.18] val:[90.38] Test:[88.31] | Best Val:[91.00] Update Test:[89.25] at Epoch:[37] | lr:0.001096
BIAS:[0.70] | Model:[GCN] Epoch:[48/100] Loss:[0.1162] Train:[95.60] val:[91.12] Test:[89.38] | Best Val:[91.12] Update Test:[89.38] at Epoch:[48] | lr:0.001065
BIAS:[0.70] | Model:[GCN] Epoch:[49/100] Loss:[0.1198] Train:[95.43] val:[89.62] Test:[89.69] | Best Val:[91.12] Update Test:[89.38] at Epoch:[48] | lr:0.001034
BIAS:[0.70] | Model:[GCN] Epoch:[50/100] Loss:[0.1140] Train:[95.80] val:[89.88] Test:[90.31] | Best Val:[91.12] Update Test:[89.38] at Epoch:[48] | lr:0.001003
BIAS:[0.70] | Model:[GCN] Epoch:[51/100] Loss:[0.0983] Train:[96.43] val:[91.75] Test:[90.94] | Best Val:[91.75] Update Test:[90.94] at Epoch:[51] | lr:0.000971
BIAS:[0.70] | Model:[GCN] Epoch:[52/100] Loss:[0.1021] Train:[96.14] val:[90.25] Test:[90.31] | Best Val:[91.75] Update Test:[90.94] at Epoch:[51] | lr:0.000940
BIAS:[0.70] | Model:[GCN] Epoch:[53/100] Loss:[0.0858] Train:[96.94] val:[89.62] Test:[89.06] | Best Val:[91.75] Update Test:[90.94] at Epoch:[51] | lr:0.000909
BIAS:[0.70] | Model:[GCN] Epoch:[54/100] Loss:[0.0798] Train:[97.05] val:[89.00] Test:[89.19] | Best Val:[91.75] Update Test:[90.94] at Epoch:[51] | lr:0.000877
BIAS:[0.70] | Model:[GCN] Epoch:[55/100] Loss:[0.0795] Train:[97.27] val:[91.12] Test:[89.38] | Best Val:[91.75] Update Test:[90.94] at Epoch:[51] | lr:0.000846
BIAS:[0.70] | Model:[GCN] Epoch:[56/100] Loss:[0.0832] Train:[97.07] val:[91.38] Test:[90.12] | Best Val:[91.75] Update Test:[90.94] at Epoch:[51] | lr:0.000816
BIAS:[0.70] | Model:[GCN] Epoch:[57/100] Loss:[0.0691] Train:[97.62] val:[89.38] Test:[88.94] | Best Val:[91.75] Update Test:[90.94] at Epoch:[51] | lr:0.000785
BIAS:[0.70] | Model:[GCN] Epoch:[58/100] Loss:[0.0672] Train:[97.69] val:[91.38] Test:[91.00] | Best Val:[91.75] Update Test:[90.94] at Epoch:[51] | lr:0.000754
BIAS:[0.70] | Model:[GCN] Epoch:[59/100] Loss:[0.0598] Train:[97.98] val:[92.00] Test:[90.19] | Best Val:[92.00] Update Test:[90.19] at Epoch:[59] | lr:0.000724
BIAS:[0.70] | Model:[GCN] Epoch:[60/100] Loss:[0.0479] Train:[98.73] val:[91.38] Test:[91.50] | Best Val:[92.00] Update Test:[90.19] at Epoch:[59] | lr:0.000694
BIAS:[0.70] | Model:[GCN] Epoch:[61/100] Loss:[0.0546] Train:[98.20] val:[90.75] Test:[90.38] | Best Val:[92.00] Update Test:[90.19] at Epoch:[59] | lr:0.000665
BIAS:[0.70] | Model:[GCN] Epoch:[62/100] Loss:[0.0475] Train:[98.46] val:[90.88] Test:[89.81] | Best Val:[92.00] Update Test:[90.19] at Epoch:[59] | lr:0.000635
BIAS:[0.70] | Model:[GCN] Epoch:[63/100] Loss:[0.0428] Train:[98.78] val:[91.75] Test:[89.94] | Best Val:[92.00] Update Test:[90.19] at Epoch:[59] | lr:0.000606
BIAS:[0.70] | Model:[GCN] Epoch:[64/100] Loss:[0.0455] Train:[98.73] val:[90.38] Test:[91.06] | Best Val:[92.00] Update Test:[90.19] at Epoch:[59] | lr:0.000578
BIAS:[0.70] | Model:[GCN] Epoch:[65/100] Loss:[0.0389] Train:[98.96] val:[89.12] Test:[88.19] | Best Val:[92.00] Update Test:[90.19] at Epoch:[59] | lr:0.000550
BIAS:[0.70] | Model:[GCN] Epoch:[66/100] Loss:[0.0402] Train:[98.68] val:[87.75] Test:[88.88] | Best Val:[92.00] Update Test:[90.19] at Epoch:[59] | lr:0.000522
BIAS:[0.70] | Model:[GCN] Epoch:[67/100] Loss:[0.0422] Train:[98.59] val:[92.38] Test:[89.62] | Best Val:[92.38] Update Test:[89.62] at Epoch:[67] | lr:0.000495
BIAS:[0.70] | Model:[GCN] Epoch:[68/100] Loss:[0.0273] Train:[99.27] val:[91.25] Test:[91.31] | Best Val:[92.38] Update Test:[89.62] at Epoch:[67] | lr:0.000468
BIAS:[0.70] | Model:[GCN] Epoch:[69/100] Loss:[0.0281] Train:[99.30] val:[90.50] Test:[90.31] | Best Val:[92.38] Update Test:[89.62] at Epoch:[67] | lr:0.000442
BIAS:[0.70] | Model:[GCN] Epoch:[70/100] Loss:[0.0286] Train:[99.34] val:[91.50] Test:[90.12] | Best Val:[92.38] Update Test:[89.62] at Epoch:[67] | lr:0.000416
BIAS:[0.70] | Model:[GCN] Epoch:[71/100] Loss:[0.0204] Train:[99.68] val:[91.88] Test:[90.75] | Best Val:[92.38] Update Test:[89.62] at Epoch:[67] | lr:0.000391
BIAS:[0.70] | Model:[GCN] Epoch:[72/100] Loss:[0.0197] Train:[99.62] val:[91.25] Test:[91.00] | Best Val:[92.38] Update Test:[89.62] at Epoch:[67] | lr:0.000367
BIAS:[0.70] | Model:[GCN] Epoch:[73/100] Loss:[0.0181] Train:[99.66] val:[92.38] Test:[91.25] | Best Val:[92.38] Update Test:[89.62] at Epoch:[67] | lr:0.000343
BIAS:[0.70] | Model:[GCN] Epoch:[74/100] Loss:[0.0160] Train:[99.68] val:[91.38] Test:[90.25] | Best Val:[92.38] Update Test:[89.62] at Epoch:[67] | lr:0.000320
BIAS:[0.70] | Model:[GCN] Epoch:[75/100] Loss:[0.0184] Train:[99.66] val:[91.50] Test:[90.94] | Best Val:[92.38] Update Test:[89.62] at Epoch:[67] | lr:0.000297
BIAS:[0.70] | Model:[GCN] Epoch:[76/100] Loss:[0.0168] Train:[99.73] val:[92.88] Test:[90.88] | Best Val:[92.88] Update Test:[90.88] at Epoch:[76] | lr:0.000275
BIAS:[0.70] | Model:[GCN] Epoch:[77/100] Loss:[0.0124] Train:[99.91] val:[91.88] Test:[91.19] | Best Val:[92.88] Update Test:[90.88] at Epoch:[76] | lr:0.000254
BIAS:[0.70] | Model:[GCN] Epoch:[78/100] Loss:[0.0110] Train:[99.87] val:[92.00] Test:[90.25] | Best Val:[92.88] Update Test:[90.88] at Epoch:[76] | lr:0.000234
BIAS:[0.70] | Model:[GCN] Epoch:[79/100] Loss:[0.0113] Train:[99.77] val:[92.88] Test:[90.88] | Best Val:[92.88] Update Test:[90.88] at Epoch:[76] | lr:0.000214
BIAS:[0.70] | Model:[GCN] Epoch:[80/100] Loss:[0.0122] Train:[99.84] val:[92.25] Test:[90.12] | Best Val:[92.88] Update Test:[90.88] at Epoch:[76] | lr:0.000196
BIAS:[0.70] | Model:[GCN] Epoch:[81/100] Loss:[0.0103] Train:[99.87] val:[92.75] Test:[91.50] | Best Val:[92.88] Update Test:[90.88] at Epoch:[76] | lr:0.000177
BIAS:[0.70] | Model:[GCN] Epoch:[82/100] Loss:[0.0085] Train:[99.95] val:[92.25] Test:[91.06] | Best Val:[92.88] Update Test:[90.88] at Epoch:[76] | lr:0.000160
BIAS:[0.70] | Model:[GCN] Epoch:[83/100] Loss:[0.0090] Train:[99.95] val:[93.00] Test:[91.12] | Best Val:[93.00] Update Test:[91.12] at Epoch:[83] | lr:0.000144
BIAS:[0.70] | Model:[GCN] Epoch:[84/100] Loss:[0.0098] Train:[99.93] val:[92.38] Test:[90.75] | Best Val:[93.00] Update Test:[91.12] at Epoch:[83] | lr:0.000128
BIAS:[0.70] | Model:[GCN] Epoch:[85/100] Loss:[0.0075] Train:[99.96] val:[93.00] Test:[91.06] | Best Val:[93.00] Update Test:[91.12] at Epoch:[83] | lr:0.000114
BIAS:[0.70] | Model:[GCN] Epoch:[86/100] Loss:[0.0084] Train:[99.96] val:[92.50] Test:[91.50] | Best Val:[93.00] Update Test:[91.12] at Epoch:[83] | lr:0.000100
BIAS:[0.70] | Model:[GCN] Epoch:[87/100] Loss:[0.0095] Train:[99.84] val:[92.75] Test:[91.31] | Best Val:[93.00] Update Test:[91.12] at Epoch:[83] | lr:0.000087
BIAS:[0.70] | Model:[GCN] Epoch:[88/100] Loss:[0.0094] Train:[99.89] val:[92.38] Test:[91.12] | Best Val:[93.00] Update Test:[91.12] at Epoch:[83] | lr:0.000075
BIAS:[0.70] | Model:[GCN] Epoch:[89/100] Loss:[0.0064] Train:[99.98] val:[92.62] Test:[91.50] | Best Val:[93.00] Update Test:[91.12] at Epoch:[83] | lr:0.000064
BIAS:[0.70] | Model:[GCN] Epoch:[90/100] Loss:[0.0066] Train:[99.98] val:[92.38] Test:[91.00] | Best Val:[93.00] Update Test:[91.12] at Epoch:[83] | lr:0.000054
BIAS:[0.70] | Model:[GCN] Epoch:[91/100] Loss:[0.0065] Train:[99.96] val:[92.75] Test:[91.31] | Best Val:[93.00] Update Test:[91.12] at Epoch:[83] | lr:0.000045
BIAS:[0.70] | Model:[GCN] Epoch:[92/100] Loss:[0.0069] Train:[99.98] val:[92.38] Test:[90.88] | Best Val:[93.00] Update Test:[91.12] at Epoch:[83] | lr:0.000036
BIAS:[0.70] | Model:[GCN] Epoch:[93/100] Loss:[0.0072] Train:[99.96] val:[92.38] Test:[91.12] | Best Val:[93.00] Update Test:[91.12] at Epoch:[83] | lr:0.000029
BIAS:[0.70] | Model:[GCN] Epoch:[94/100] Loss:[0.0067] Train:[99.96] val:[92.50] Test:[91.12] | Best Val:[93.00] Update Test:[91.12] at Epoch:[83] | lr:0.000023
BIAS:[0.70] | Model:[GCN] Epoch:[95/100] Loss:[0.0070] Train:[100.00] val:[91.75] Test:[91.06] | Best Val:[93.00] Update Test:[91.12] at Epoch:[83] | lr:0.000017
BIAS:[0.70] | Model:[GCN] Epoch:[96/100] Loss:[0.0062] Train:[99.98] val:[92.25] Test:[91.12] | Best Val:[93.00] Update Test:[91.12] at Epoch:[83] | lr:0.000013
BIAS:[0.70] | Model:[GCN] Epoch:[97/100] Loss:[0.0067] Train:[99.98] val:[92.12] Test:[91.12] | Best Val:[93.00] Update Test:[91.12] at Epoch:[83] | lr:0.000009
BIAS:[0.70] | Model:[GCN] Epoch:[98/100] Loss:[0.0074] Train:[99.93] val:[92.88] Test:[91.19] | Best Val:[93.00] Update Test:[91.12] at Epoch:[83] | lr:0.000007
BIAS:[0.70] | Model:[GCN] Epoch:[99/100] Loss:[0.0077] Train:[99.91] val:[92.62] Test:[91.12] | Best Val:[93.00] Update Test:[91.12] at Epoch:[83] | lr:0.000005
BIAS:[0.70] | Model:[GCN] Epoch:[100/100] Loss:[0.0068] Train:[99.98] val:[92.38] Test:[91.19] | Best Val:[93.00] Update Test:[91.12] at Epoch:[83] | lr:0.000005
syd: BIAS:[0.70] | Best Val acc:[93.00] Test acc:[91.12] at epoch:[83]
step_size..................................................................0.001
min_lr.....................................................................5e-06
pretrain......................................................................30
data_num....................................................................2000
node_num......................................................................15
max_degree....................................................................10
feature_dim...................................................................-1
noise........................................................................0.1
num_classes....................................................................4
shape_num......................................................................1
bias.........................................................................0.7
penalty_weight...............................................................0.1
train_type..................................................................base
epochs.......................................................................100
batch_size...................................................................128
the............................................................................0
with_random.................................................................True
eval_random................................................................False
normalize..................................................................False
save_model.................................................................False
inference..................................................................False
without_node_attention.....................................................False
without_edge_attention.....................................................False
k..............................................................................3
layers.........................................................................3
c............................................................................0.5
o............................................................................1.0
co...........................................................................0.5
harf_hidden..................................................................0.5
cat_or_add...................................................................add
num_layers.....................................................................3
folds.........................................................................10
fc_num.......................................................................222
data_root...................................................................data
save_dir...................................................................debug
dataset.....................................................................NCI1
epoch_select............................................................test_max
model..................................................................CausalGCN
hidden.......................................................................128
seed.........................................................................666
lr.........................................................................0.002
lr_decay_factor..............................................................0.5
lr_decay_step_size...........................................................500
weight_decay...................................................................0
global_pool..................................................................sum

----------------------------------------------------------------------------------------------------
| graph: Tree-house | nodes num:246 | edges num:542 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: BA-house | nodes num:230 | edges num:996 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: Tree-cycle | nodes num:247 | edges num:542 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: BA-cycle | nodes num:231 | edges num:996 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: Tree-grid | nodes num:247 | edges num:544 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: BA-grid | nodes num:231 | edges num:998 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: Tree-diamond | nodes num:247 | edges num:546 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: BA-diamond | nodes num:231 | edges num:1000 |
----------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
Train Total:5596
| Tree: House:979  , Cycle:420  , Grids:420  , Diams:420   
| BA  : House:420  , Cycle:979  , Grids:979  , Diams:979   
| All : House:1399 , Cycle:1399 , Grids:1399 , Diams:1399  
| BIAS: House:70.0%, Cycle:30.0%, Grids:30.0%, Diams:30.0%
------------------------------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
Val    Total:800
| Tree: House:140  , Cycle:60   , Grids:60   , Diams:60    
| BA  : House:60   , Cycle:140  , Grids:140  , Diams:140   
| All : House:200  , Cycle:200  , Grids:200  , Diams:200   
| BIAS: House:70.0%, Cycle:30.0%, Grids:30.0%, Diams:30.0%
------------------------------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
Test   Total:1600
| Tree: House:200  , Cycle:200  , Grids:200  , Diams:200   
| BA  : House:200  , Cycle:200  , Grids:200  , Diams:200   
| All : House:400  , Cycle:400  , Grids:400  , Diams:400   
| BIAS: House:50.0%, Cycle:50.0%, Grids:50.0%, Diams:50.0%
------------------------------------------------------------------------------------------------------------------------------------------------------
BIAS:[0.70] | Model:[CausalGCN] Epoch:[1/100] Loss:[1.1852=0.0177+0.7374+0.8780] Train:[69.39] val:[75.75] Test:[75.00] | Update Test:[co:68.31,c:24.94,o:75.00] at Epoch:[1] | lr:0.002000
BIAS:[0.70] | Model:[CausalGCN] Epoch:[2/100] Loss:[0.7094=0.0020+0.4576+0.5016] Train:[82.11] val:[79.38] Test:[76.50] | Update Test:[co:75.44,c:25.25,o:76.50] at Epoch:[2] | lr:0.001998
BIAS:[0.70] | Model:[CausalGCN] Epoch:[3/100] Loss:[0.6324=0.0008+0.4107+0.4426] Train:[83.35] val:[83.12] Test:[83.31] | Update Test:[co:79.31,c:25.19,o:83.31] at Epoch:[3] | lr:0.001996
BIAS:[0.70] | Model:[CausalGCN] Epoch:[4/100] Loss:[0.5385=0.0007+0.3483+0.3797] Train:[86.15] val:[83.62] Test:[83.69] | Update Test:[co:80.25,c:25.56,o:83.69] at Epoch:[4] | lr:0.001992
BIAS:[0.70] | Model:[CausalGCN] Epoch:[5/100] Loss:[0.5051=0.0004+0.3281+0.3534] Train:[86.99] val:[83.38] Test:[85.62] | Update Test:[co:80.25,c:25.56,o:83.69] at Epoch:[4] | lr:0.001988
BIAS:[0.70] | Model:[CausalGCN] Epoch:[6/100] Loss:[0.4912=0.0005+0.3172+0.3475] Train:[87.60] val:[82.38] Test:[81.62] | Update Test:[co:80.25,c:25.56,o:83.69] at Epoch:[4] | lr:0.001982
BIAS:[0.70] | Model:[CausalGCN] Epoch:[7/100] Loss:[0.4408=0.0003+0.2848+0.3117] Train:[89.47] val:[88.00] Test:[88.94] | Update Test:[co:89.00,c:24.12,o:88.94] at Epoch:[7] | lr:0.001976
BIAS:[0.70] | Model:[CausalGCN] Epoch:[8/100] Loss:[0.4279=0.0003+0.2775+0.3005] Train:[89.40] val:[87.62] Test:[89.00] | Update Test:[co:89.00,c:24.12,o:88.94] at Epoch:[7] | lr:0.001969
BIAS:[0.70] | Model:[CausalGCN] Epoch:[9/100] Loss:[0.3853=0.0002+0.2488+0.2728] Train:[90.17] val:[87.00] Test:[88.56] | Update Test:[co:89.00,c:24.12,o:88.94] at Epoch:[7] | lr:0.001960
BIAS:[0.70] | Model:[CausalGCN] Epoch:[10/100] Loss:[0.3878=0.0002+0.2495+0.2764] Train:[90.60] val:[70.50] Test:[72.94] | Update Test:[co:89.00,c:24.12,o:88.94] at Epoch:[7] | lr:0.001951
BIAS:[0.70] | Model:[CausalGCN] Epoch:[11/100] Loss:[0.3329=0.0002+0.2113+0.2431] Train:[92.10] val:[91.00] Test:[91.62] | Update Test:[co:90.12,c:25.31,o:91.62] at Epoch:[11] | lr:0.001941
BIAS:[0.70] | Model:[CausalGCN] Epoch:[12/100] Loss:[0.3340=0.0002+0.2135+0.2407] Train:[92.23] val:[87.12] Test:[87.56] | Update Test:[co:90.12,c:25.31,o:91.62] at Epoch:[11] | lr:0.001930
BIAS:[0.70] | Model:[CausalGCN] Epoch:[13/100] Loss:[0.3319=0.0002+0.2109+0.2416] Train:[92.07] val:[91.12] Test:[92.19] | Update Test:[co:91.56,c:31.31,o:92.19] at Epoch:[13] | lr:0.001918
BIAS:[0.70] | Model:[CausalGCN] Epoch:[14/100] Loss:[0.2803=0.0002+0.1762+0.2080] Train:[93.30] val:[78.00] Test:[79.94] | Update Test:[co:91.56,c:31.31,o:92.19] at Epoch:[13] | lr:0.001905
BIAS:[0.70] | Model:[CausalGCN] Epoch:[15/100] Loss:[0.2861=0.0002+0.1820+0.2081] Train:[93.71] val:[91.50] Test:[91.94] | Update Test:[co:89.75,c:25.25,o:91.94] at Epoch:[15] | lr:0.001891
BIAS:[0.70] | Model:[CausalGCN] Epoch:[16/100] Loss:[0.2667=0.0001+0.1679+0.1974] Train:[94.09] val:[89.38] Test:[90.56] | Update Test:[co:89.75,c:25.25,o:91.94] at Epoch:[15] | lr:0.001877
BIAS:[0.70] | Model:[CausalGCN] Epoch:[17/100] Loss:[0.2609=0.0001+0.1650+0.1918] Train:[94.17] val:[91.12] Test:[91.25] | Update Test:[co:89.75,c:25.25,o:91.94] at Epoch:[15] | lr:0.001861
BIAS:[0.70] | Model:[CausalGCN] Epoch:[18/100] Loss:[0.2464=0.0001+0.1554+0.1819] Train:[94.62] val:[93.12] Test:[93.06] | Update Test:[co:91.25,c:25.81,o:93.06] at Epoch:[18] | lr:0.001845
BIAS:[0.70] | Model:[CausalGCN] Epoch:[19/100] Loss:[0.2363=0.0001+0.1494+0.1737] Train:[94.41] val:[91.12] Test:[93.31] | Update Test:[co:91.25,c:25.81,o:93.06] at Epoch:[18] | lr:0.001828
BIAS:[0.70] | Model:[CausalGCN] Epoch:[20/100] Loss:[0.2314=0.0001+0.1456+0.1716] Train:[94.75] val:[92.88] Test:[92.94] | Update Test:[co:91.25,c:25.81,o:93.06] at Epoch:[18] | lr:0.001809
BIAS:[0.70] | Model:[CausalGCN] Epoch:[21/100] Loss:[0.2190=0.0001+0.1365+0.1650] Train:[95.28] val:[92.25] Test:[93.44] | Update Test:[co:91.25,c:25.81,o:93.06] at Epoch:[18] | lr:0.001791
BIAS:[0.70] | Model:[CausalGCN] Epoch:[22/100] Loss:[0.2025=0.0001+0.1277+0.1495] Train:[95.55] val:[85.88] Test:[86.56] | Update Test:[co:91.25,c:25.81,o:93.06] at Epoch:[18] | lr:0.001771
BIAS:[0.70] | Model:[CausalGCN] Epoch:[23/100] Loss:[0.2089=0.0001+0.1323+0.1531] Train:[95.34] val:[93.50] Test:[93.50] | Update Test:[co:92.81,c:23.69,o:93.50] at Epoch:[23] | lr:0.001751
BIAS:[0.70] | Model:[CausalGCN] Epoch:[24/100] Loss:[0.2102=0.0001+0.1321+0.1563] Train:[95.25] val:[92.25] Test:[92.56] | Update Test:[co:92.81,c:23.69,o:93.50] at Epoch:[23] | lr:0.001730
BIAS:[0.70] | Model:[CausalGCN] Epoch:[25/100] Loss:[0.2343=0.0001+0.1497+0.1691] Train:[94.60] val:[91.25] Test:[91.81] | Update Test:[co:92.81,c:23.69,o:93.50] at Epoch:[23] | lr:0.001708
BIAS:[0.70] | Model:[CausalGCN] Epoch:[26/100] Loss:[0.1877=0.0001+0.1178+0.1396] Train:[95.85] val:[94.62] Test:[94.00] | Update Test:[co:94.75,c:24.88,o:94.00] at Epoch:[26] | lr:0.001685
BIAS:[0.70] | Model:[CausalGCN] Epoch:[27/100] Loss:[0.1711=0.0000+0.1079+0.1263] Train:[96.00] val:[93.75] Test:[93.75] | Update Test:[co:94.75,c:24.88,o:94.00] at Epoch:[26] | lr:0.001662
BIAS:[0.70] | Model:[CausalGCN] Epoch:[28/100] Loss:[0.1700=0.0001+0.1065+0.1269] Train:[96.27] val:[94.62] Test:[94.44] | Update Test:[co:94.75,c:24.88,o:94.00] at Epoch:[26] | lr:0.001638
BIAS:[0.70] | Model:[CausalGCN] Epoch:[29/100] Loss:[0.1650=0.0000+0.1031+0.1237] Train:[96.41] val:[94.50] Test:[94.44] | Update Test:[co:94.75,c:24.88,o:94.00] at Epoch:[26] | lr:0.001614
BIAS:[0.70] | Model:[CausalGCN] Epoch:[30/100] Loss:[0.1525=0.0000+0.0937+0.1177] Train:[96.62] val:[93.50] Test:[93.88] | Update Test:[co:94.75,c:24.88,o:94.00] at Epoch:[26] | lr:0.001589
BIAS:[0.70] | Model:[CausalGCN] Epoch:[31/100] Loss:[0.1566=0.0000+0.0979+0.1174] Train:[96.69] val:[83.62] Test:[83.75] | Update Test:[co:94.75,c:24.88,o:94.00] at Epoch:[26] | lr:0.001563
BIAS:[0.70] | Model:[CausalGCN] Epoch:[32/100] Loss:[0.1516=0.0001+0.0934+0.1164] Train:[97.00] val:[90.88] Test:[89.56] | Update Test:[co:94.75,c:24.88,o:94.00] at Epoch:[26] | lr:0.001537
BIAS:[0.70] | Model:[CausalGCN] Epoch:[33/100] Loss:[0.1450=0.0001+0.0901+0.1096] Train:[96.93] val:[92.75] Test:[91.44] | Update Test:[co:94.75,c:24.88,o:94.00] at Epoch:[26] | lr:0.001510
BIAS:[0.70] | Model:[CausalGCN] Epoch:[34/100] Loss:[0.1625=0.0001+0.1040+0.1170] Train:[96.27] val:[93.12] Test:[93.56] | Update Test:[co:94.75,c:24.88,o:94.00] at Epoch:[26] | lr:0.001483
BIAS:[0.70] | Model:[CausalGCN] Epoch:[35/100] Loss:[0.1385=0.0000+0.0876+0.1019] Train:[97.05] val:[93.75] Test:[93.94] | Update Test:[co:94.75,c:24.88,o:94.00] at Epoch:[26] | lr:0.001455
BIAS:[0.70] | Model:[CausalGCN] Epoch:[36/100] Loss:[0.1174=0.0000+0.0721+0.0904] Train:[97.46] val:[90.38] Test:[92.88] | Update Test:[co:94.75,c:24.88,o:94.00] at Epoch:[26] | lr:0.001427
BIAS:[0.70] | Model:[CausalGCN] Epoch:[37/100] Loss:[0.1226=0.0000+0.0759+0.0934] Train:[97.32] val:[94.50] Test:[93.50] | Update Test:[co:94.75,c:24.88,o:94.00] at Epoch:[26] | lr:0.001399
BIAS:[0.70] | Model:[CausalGCN] Epoch:[38/100] Loss:[0.1195=0.0000+0.0747+0.0895] Train:[97.52] val:[91.62] Test:[92.50] | Update Test:[co:94.75,c:24.88,o:94.00] at Epoch:[26] | lr:0.001370
BIAS:[0.70] | Model:[CausalGCN] Epoch:[39/100] Loss:[0.1125=0.0000+0.0696+0.0856] Train:[97.61] val:[92.50] Test:[92.75] | Update Test:[co:94.75,c:24.88,o:94.00] at Epoch:[26] | lr:0.001340
BIAS:[0.70] | Model:[CausalGCN] Epoch:[40/100] Loss:[0.0961=0.0000+0.0580+0.0761] Train:[98.14] val:[94.38] Test:[95.06] | Update Test:[co:94.75,c:24.88,o:94.00] at Epoch:[26] | lr:0.001311
BIAS:[0.70] | Model:[CausalGCN] Epoch:[41/100] Loss:[0.0845=0.0000+0.0501+0.0687] Train:[98.36] val:[91.12] Test:[90.38] | Update Test:[co:94.75,c:24.88,o:94.00] at Epoch:[26] | lr:0.001281
BIAS:[0.70] | Model:[CausalGCN] Epoch:[42/100] Loss:[0.0962=0.0000+0.0579+0.0766] Train:[98.02] val:[92.25] Test:[95.12] | Update Test:[co:94.75,c:24.88,o:94.00] at Epoch:[26] | lr:0.001251
BIAS:[0.70] | Model:[CausalGCN] Epoch:[43/100] Loss:[0.1197=0.0000+0.0721+0.0951] Train:[97.59] val:[94.00] Test:[95.06] | Update Test:[co:94.75,c:24.88,o:94.00] at Epoch:[26] | lr:0.001220
BIAS:[0.70] | Model:[CausalGCN] Epoch:[44/100] Loss:[0.0907=0.0001+0.0556+0.0702] Train:[98.05] val:[93.25] Test:[95.06] | Update Test:[co:94.75,c:24.88,o:94.00] at Epoch:[26] | lr:0.001189
BIAS:[0.70] | Model:[CausalGCN] Epoch:[45/100] Loss:[0.0836=0.0000+0.0510+0.0653] Train:[98.21] val:[94.00] Test:[94.12] | Update Test:[co:94.75,c:24.88,o:94.00] at Epoch:[26] | lr:0.001159
BIAS:[0.70] | Model:[CausalGCN] Epoch:[46/100] Loss:[0.0706=0.0000+0.0421+0.0569] Train:[98.77] val:[92.25] Test:[94.19] | Update Test:[co:94.75,c:24.88,o:94.00] at Epoch:[26] | lr:0.001128
BIAS:[0.70] | Model:[CausalGCN] Epoch:[47/100] Loss:[0.0767=0.0000+0.0466+0.0603] Train:[98.27] val:[91.62] Test:[90.88] | Update Test:[co:94.75,c:24.88,o:94.00] at Epoch:[26] | lr:0.001096
BIAS:[0.70] | Model:[CausalGCN] Epoch:[48/100] Loss:[0.0642=0.0000+0.0371+0.0543] Train:[98.95] val:[92.12] Test:[92.06] | Update Test:[co:94.75,c:24.88,o:94.00] at Epoch:[26] | lr:0.001065
BIAS:[0.70] | Model:[CausalGCN] Epoch:[49/100] Loss:[0.0677=0.0000+0.0411+0.0532] Train:[98.59] val:[95.12] Test:[95.31] | Update Test:[co:94.19,c:25.00,o:95.31] at Epoch:[49] | lr:0.001034
BIAS:[0.70] | Model:[CausalGCN] Epoch:[50/100] Loss:[0.0809=0.0000+0.0501+0.0617] Train:[98.18] val:[90.75] Test:[91.00] | Update Test:[co:94.19,c:25.00,o:95.31] at Epoch:[49] | lr:0.001003
BIAS:[0.70] | Model:[CausalGCN] Epoch:[51/100] Loss:[0.0609=0.0000+0.0357+0.0504] Train:[98.75] val:[95.25] Test:[95.31] | Update Test:[co:95.25,c:25.37,o:95.31] at Epoch:[51] | lr:0.000971
BIAS:[0.70] | Model:[CausalGCN] Epoch:[52/100] Loss:[0.0533=0.0000+0.0314+0.0438] Train:[99.00] val:[93.12] Test:[93.88] | Update Test:[co:95.25,c:25.37,o:95.31] at Epoch:[51] | lr:0.000940
BIAS:[0.70] | Model:[CausalGCN] Epoch:[53/100] Loss:[0.0387=0.0000+0.0225+0.0325] Train:[99.36] val:[94.88] Test:[95.44] | Update Test:[co:95.25,c:25.37,o:95.31] at Epoch:[51] | lr:0.000909
BIAS:[0.70] | Model:[CausalGCN] Epoch:[54/100] Loss:[0.0373=0.0000+0.0209+0.0328] Train:[99.41] val:[94.50] Test:[95.50] | Update Test:[co:95.25,c:25.37,o:95.31] at Epoch:[51] | lr:0.000877
BIAS:[0.70] | Model:[CausalGCN] Epoch:[55/100] Loss:[0.0421=0.0000+0.0240+0.0361] Train:[99.20] val:[94.50] Test:[95.38] | Update Test:[co:95.25,c:25.37,o:95.31] at Epoch:[51] | lr:0.000846
BIAS:[0.70] | Model:[CausalGCN] Epoch:[56/100] Loss:[0.0512=0.0000+0.0293+0.0438] Train:[98.96] val:[92.88] Test:[93.88] | Update Test:[co:95.25,c:25.37,o:95.31] at Epoch:[51] | lr:0.000816
BIAS:[0.70] | Model:[CausalGCN] Epoch:[57/100] Loss:[0.0360=0.0000+0.0205+0.0310] Train:[99.37] val:[95.00] Test:[95.31] | Update Test:[co:95.25,c:25.37,o:95.31] at Epoch:[51] | lr:0.000785
BIAS:[0.70] | Model:[CausalGCN] Epoch:[58/100] Loss:[0.0336=0.0000+0.0185+0.0303] Train:[99.46] val:[95.25] Test:[95.56] | Update Test:[co:95.25,c:25.37,o:95.31] at Epoch:[51] | lr:0.000754
BIAS:[0.70] | Model:[CausalGCN] Epoch:[59/100] Loss:[0.0304=0.0000+0.0157+0.0294] Train:[99.61] val:[94.62] Test:[95.25] | Update Test:[co:95.25,c:25.37,o:95.31] at Epoch:[51] | lr:0.000724
BIAS:[0.70] | Model:[CausalGCN] Epoch:[60/100] Loss:[0.0281=0.0000+0.0149+0.0263] Train:[99.57] val:[95.62] Test:[95.50] | Update Test:[co:95.00,c:24.62,o:95.50] at Epoch:[60] | lr:0.000694
BIAS:[0.70] | Model:[CausalGCN] Epoch:[61/100] Loss:[0.0250=0.0000+0.0138+0.0224] Train:[99.62] val:[95.00] Test:[95.81] | Update Test:[co:95.00,c:24.62,o:95.50] at Epoch:[60] | lr:0.000665
BIAS:[0.70] | Model:[CausalGCN] Epoch:[62/100] Loss:[0.0228=0.0000+0.0122+0.0213] Train:[99.73] val:[95.25] Test:[95.19] | Update Test:[co:95.00,c:24.62,o:95.50] at Epoch:[60] | lr:0.000635
BIAS:[0.70] | Model:[CausalGCN] Epoch:[63/100] Loss:[0.0181=0.0000+0.0098+0.0166] Train:[99.82] val:[95.62] Test:[95.00] | Update Test:[co:95.00,c:24.62,o:95.50] at Epoch:[60] | lr:0.000606
BIAS:[0.70] | Model:[CausalGCN] Epoch:[64/100] Loss:[0.0188=0.0000+0.0095+0.0185] Train:[99.82] val:[95.00] Test:[95.62] | Update Test:[co:95.00,c:24.62,o:95.50] at Epoch:[60] | lr:0.000578
BIAS:[0.70] | Model:[CausalGCN] Epoch:[65/100] Loss:[0.0199=0.0000+0.0108+0.0181] Train:[99.70] val:[95.00] Test:[95.56] | Update Test:[co:95.00,c:24.62,o:95.50] at Epoch:[60] | lr:0.000550
BIAS:[0.70] | Model:[CausalGCN] Epoch:[66/100] Loss:[0.0159=0.0000+0.0086+0.0147] Train:[99.80] val:[95.88] Test:[95.50] | Update Test:[co:94.50,c:24.81,o:95.50] at Epoch:[66] | lr:0.000522
BIAS:[0.70] | Model:[CausalGCN] Epoch:[67/100] Loss:[0.0132=0.0000+0.0072+0.0119] Train:[99.82] val:[95.62] Test:[95.50] | Update Test:[co:94.50,c:24.81,o:95.50] at Epoch:[66] | lr:0.000495
BIAS:[0.70] | Model:[CausalGCN] Epoch:[68/100] Loss:[0.0111=0.0000+0.0054+0.0115] Train:[99.91] val:[94.50] Test:[94.88] | Update Test:[co:94.50,c:24.81,o:95.50] at Epoch:[66] | lr:0.000468
BIAS:[0.70] | Model:[CausalGCN] Epoch:[69/100] Loss:[0.0098=0.0000+0.0050+0.0096] Train:[99.96] val:[95.25] Test:[96.00] | Update Test:[co:94.50,c:24.81,o:95.50] at Epoch:[66] | lr:0.000442
BIAS:[0.70] | Model:[CausalGCN] Epoch:[70/100] Loss:[0.0102=0.0000+0.0054+0.0097] Train:[99.91] val:[95.50] Test:[95.38] | Update Test:[co:94.50,c:24.81,o:95.50] at Epoch:[66] | lr:0.000416
BIAS:[0.70] | Model:[CausalGCN] Epoch:[71/100] Loss:[0.0121=0.0000+0.0062+0.0118] Train:[99.89] val:[95.75] Test:[95.06] | Update Test:[co:94.50,c:24.81,o:95.50] at Epoch:[66] | lr:0.000391
BIAS:[0.70] | Model:[CausalGCN] Epoch:[72/100] Loss:[0.0115=0.0000+0.0057+0.0117] Train:[99.96] val:[95.62] Test:[96.00] | Update Test:[co:94.50,c:24.81,o:95.50] at Epoch:[66] | lr:0.000367
BIAS:[0.70] | Model:[CausalGCN] Epoch:[73/100] Loss:[0.0093=0.0000+0.0045+0.0097] Train:[99.89] val:[95.75] Test:[95.44] | Update Test:[co:94.50,c:24.81,o:95.50] at Epoch:[66] | lr:0.000343
BIAS:[0.70] | Model:[CausalGCN] Epoch:[74/100] Loss:[0.0077=0.0000+0.0038+0.0078] Train:[99.96] val:[95.50] Test:[95.94] | Update Test:[co:94.50,c:24.81,o:95.50] at Epoch:[66] | lr:0.000320
BIAS:[0.70] | Model:[CausalGCN] Epoch:[75/100] Loss:[0.0081=0.0000+0.0041+0.0079] Train:[99.93] val:[95.50] Test:[96.00] | Update Test:[co:94.50,c:24.81,o:95.50] at Epoch:[66] | lr:0.000297
BIAS:[0.70] | Model:[CausalGCN] Epoch:[76/100] Loss:[0.0077=0.0000+0.0040+0.0075] Train:[99.93] val:[96.00] Test:[95.50] | Update Test:[co:95.44,c:24.50,o:95.50] at Epoch:[76] | lr:0.000275
BIAS:[0.70] | Model:[CausalGCN] Epoch:[77/100] Loss:[0.0069=0.0000+0.0034+0.0071] Train:[99.96] val:[95.50] Test:[95.75] | Update Test:[co:95.44,c:24.50,o:95.50] at Epoch:[76] | lr:0.000254
BIAS:[0.70] | Model:[CausalGCN] Epoch:[78/100] Loss:[0.0072=0.0000+0.0035+0.0074] Train:[99.96] val:[95.38] Test:[95.62] | Update Test:[co:95.44,c:24.50,o:95.50] at Epoch:[76] | lr:0.000234
BIAS:[0.70] | Model:[CausalGCN] Epoch:[79/100] Loss:[0.0055=0.0000+0.0027+0.0055] Train:[99.95] val:[95.88] Test:[95.56] | Update Test:[co:95.44,c:24.50,o:95.50] at Epoch:[76] | lr:0.000214
BIAS:[0.70] | Model:[CausalGCN] Epoch:[80/100] Loss:[0.0056=0.0000+0.0029+0.0053] Train:[99.96] val:[96.00] Test:[95.75] | Update Test:[co:95.44,c:24.50,o:95.50] at Epoch:[76] | lr:0.000196
BIAS:[0.70] | Model:[CausalGCN] Epoch:[81/100] Loss:[0.0058=0.0000+0.0030+0.0056] Train:[99.96] val:[95.88] Test:[95.69] | Update Test:[co:95.44,c:24.50,o:95.50] at Epoch:[76] | lr:0.000177
BIAS:[0.70] | Model:[CausalGCN] Epoch:[82/100] Loss:[0.0057=0.0000+0.0027+0.0059] Train:[99.96] val:[95.62] Test:[95.88] | Update Test:[co:95.44,c:24.50,o:95.50] at Epoch:[76] | lr:0.000160
BIAS:[0.70] | Model:[CausalGCN] Epoch:[83/100] Loss:[0.0077=0.0000+0.0038+0.0078] Train:[99.93] val:[95.62] Test:[95.81] | Update Test:[co:95.44,c:24.50,o:95.50] at Epoch:[76] | lr:0.000144
BIAS:[0.70] | Model:[CausalGCN] Epoch:[84/100] Loss:[0.0064=0.0000+0.0031+0.0065] Train:[100.00] val:[96.25] Test:[96.06] | Update Test:[co:95.56,c:24.38,o:96.06] at Epoch:[84] | lr:0.000128
BIAS:[0.70] | Model:[CausalGCN] Epoch:[85/100] Loss:[0.0045=0.0000+0.0022+0.0047] Train:[100.00] val:[95.75] Test:[95.81] | Update Test:[co:95.56,c:24.38,o:96.06] at Epoch:[84] | lr:0.000114
BIAS:[0.70] | Model:[CausalGCN] Epoch:[86/100] Loss:[0.0068=0.0000+0.0036+0.0064] Train:[99.95] val:[96.25] Test:[95.88] | Update Test:[co:95.56,c:24.38,o:96.06] at Epoch:[84] | lr:0.000100
BIAS:[0.70] | Model:[CausalGCN] Epoch:[87/100] Loss:[0.0062=0.0000+0.0031+0.0062] Train:[99.96] val:[95.88] Test:[95.44] | Update Test:[co:95.56,c:24.38,o:96.06] at Epoch:[84] | lr:0.000087
BIAS:[0.70] | Model:[CausalGCN] Epoch:[88/100] Loss:[0.0050=0.0000+0.0024+0.0052] Train:[99.96] val:[95.88] Test:[95.56] | Update Test:[co:95.56,c:24.38,o:96.06] at Epoch:[84] | lr:0.000075
BIAS:[0.70] | Model:[CausalGCN] Epoch:[89/100] Loss:[0.0049=0.0000+0.0024+0.0050] Train:[99.98] val:[95.25] Test:[95.75] | Update Test:[co:95.56,c:24.38,o:96.06] at Epoch:[84] | lr:0.000064
BIAS:[0.70] | Model:[CausalGCN] Epoch:[90/100] Loss:[0.0048=0.0000+0.0023+0.0050] Train:[99.98] val:[95.88] Test:[95.69] | Update Test:[co:95.56,c:24.38,o:96.06] at Epoch:[84] | lr:0.000054
BIAS:[0.70] | Model:[CausalGCN] Epoch:[91/100] Loss:[0.0065=0.0000+0.0035+0.0058] Train:[99.95] val:[95.62] Test:[95.75] | Update Test:[co:95.56,c:24.38,o:96.06] at Epoch:[84] | lr:0.000045
BIAS:[0.70] | Model:[CausalGCN] Epoch:[92/100] Loss:[0.0039=0.0000+0.0019+0.0040] Train:[99.98] val:[96.12] Test:[95.75] | Update Test:[co:95.56,c:24.38,o:96.06] at Epoch:[84] | lr:0.000036
BIAS:[0.70] | Model:[CausalGCN] Epoch:[93/100] Loss:[0.0048=0.0000+0.0023+0.0049] Train:[99.98] val:[95.75] Test:[95.75] | Update Test:[co:95.56,c:24.38,o:96.06] at Epoch:[84] | lr:0.000029
BIAS:[0.70] | Model:[CausalGCN] Epoch:[94/100] Loss:[0.0036=0.0000+0.0018+0.0037] Train:[100.00] val:[95.62] Test:[95.81] | Update Test:[co:95.56,c:24.38,o:96.06] at Epoch:[84] | lr:0.000023
BIAS:[0.70] | Model:[CausalGCN] Epoch:[95/100] Loss:[0.0040=0.0000+0.0019+0.0042] Train:[99.98] val:[95.88] Test:[95.69] | Update Test:[co:95.56,c:24.38,o:96.06] at Epoch:[84] | lr:0.000017
BIAS:[0.70] | Model:[CausalGCN] Epoch:[96/100] Loss:[0.0041=0.0000+0.0020+0.0041] Train:[100.00] val:[95.50] Test:[95.69] | Update Test:[co:95.56,c:24.38,o:96.06] at Epoch:[84] | lr:0.000013
BIAS:[0.70] | Model:[CausalGCN] Epoch:[97/100] Loss:[0.0037=0.0000+0.0017+0.0040] Train:[100.00] val:[95.88] Test:[95.81] | Update Test:[co:95.56,c:24.38,o:96.06] at Epoch:[84] | lr:0.000009
BIAS:[0.70] | Model:[CausalGCN] Epoch:[98/100] Loss:[0.0037=0.0000+0.0020+0.0035] Train:[100.00] val:[95.50] Test:[95.75] | Update Test:[co:95.56,c:24.38,o:96.06] at Epoch:[84] | lr:0.000007
BIAS:[0.70] | Model:[CausalGCN] Epoch:[99/100] Loss:[0.0044=0.0000+0.0021+0.0046] Train:[99.98] val:[95.75] Test:[95.88] | Update Test:[co:95.56,c:24.38,o:96.06] at Epoch:[84] | lr:0.000005
BIAS:[0.70] | Model:[CausalGCN] Epoch:[100/100] Loss:[0.0049=0.0000+0.0025+0.0049] Train:[99.98] val:[95.75] Test:[95.69] | Update Test:[co:95.56,c:24.38,o:96.06] at Epoch:[84] | lr:0.000005
syd: BIAS:[0.70] | Val acc:[95.75] Test acc:[co:95.56,c:24.38,o:96.06] at epoch:[84]
step_size..................................................................0.001
min_lr.....................................................................5e-06
pretrain......................................................................30
data_num....................................................................2000
node_num......................................................................15
max_degree....................................................................10
feature_dim...................................................................-1
noise........................................................................0.1
num_classes....................................................................4
shape_num......................................................................1
bias.........................................................................0.9
penalty_weight...............................................................0.1
train_type..................................................................base
epochs.......................................................................100
batch_size...................................................................128
the............................................................................0
with_random.................................................................True
eval_random................................................................False
normalize..................................................................False
save_model.................................................................False
inference..................................................................False
without_node_attention.....................................................False
without_edge_attention.....................................................False
k..............................................................................3
layers.........................................................................3
c............................................................................0.5
o............................................................................1.0
co...........................................................................0.5
harf_hidden..................................................................0.5
cat_or_add...................................................................add
num_layers.....................................................................3
folds.........................................................................10
fc_num.......................................................................222
data_root...................................................................data
save_dir...................................................................debug
dataset.....................................................................NCI1
epoch_select............................................................test_max
model........................................................................GCN
hidden.......................................................................128
seed.........................................................................666
lr.........................................................................0.002
lr_decay_factor..............................................................0.5
lr_decay_step_size...........................................................500
weight_decay...................................................................0
global_pool..................................................................sum

----------------------------------------------------------------------------------------------------
| graph: Tree-house | nodes num:246 | edges num:542 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: BA-house | nodes num:230 | edges num:996 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: Tree-cycle | nodes num:247 | edges num:542 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: BA-cycle | nodes num:231 | edges num:996 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: Tree-grid | nodes num:247 | edges num:544 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: BA-grid | nodes num:231 | edges num:998 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: Tree-diamond | nodes num:247 | edges num:546 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: BA-diamond | nodes num:231 | edges num:1000 |
----------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
Train Total:5596
| Tree: House:1260 , Cycle:139  , Grids:139  , Diams:139   
| BA  : House:139  , Cycle:1260 , Grids:1260 , Diams:1260  
| All : House:1399 , Cycle:1399 , Grids:1399 , Diams:1399  
| BIAS: House:90.1%, Cycle:9.9%, Grids:9.9%, Diams:9.9%
------------------------------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
Val    Total:796
| Tree: House:180  , Cycle:19   , Grids:19   , Diams:19    
| BA  : House:19   , Cycle:180  , Grids:180  , Diams:180   
| All : House:199  , Cycle:199  , Grids:199  , Diams:199   
| BIAS: House:90.5%, Cycle:9.5%, Grids:9.5%, Diams:9.5%
------------------------------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
Test   Total:1600
| Tree: House:200  , Cycle:200  , Grids:200  , Diams:200   
| BA  : House:200  , Cycle:200  , Grids:200  , Diams:200   
| All : House:400  , Cycle:400  , Grids:400  , Diams:400   
| BIAS: House:50.0%, Cycle:50.0%, Grids:50.0%, Diams:50.0%
------------------------------------------------------------------------------------------------------------------------------------------------------
BIAS:[0.90] | Model:[GCN] Epoch:[1/100] Loss:[0.7844] Train:[67.17] val:[65.08] Test:[43.44] | Best Val:[65.08] Update Test:[43.44] at Epoch:[1] | lr:0.002000
BIAS:[0.90] | Model:[GCN] Epoch:[2/100] Loss:[0.5263] Train:[79.13] val:[78.27] Test:[69.38] | Best Val:[78.27] Update Test:[69.38] at Epoch:[2] | lr:0.001998
BIAS:[0.90] | Model:[GCN] Epoch:[3/100] Loss:[0.4634] Train:[81.47] val:[83.04] Test:[72.19] | Best Val:[83.04] Update Test:[72.19] at Epoch:[3] | lr:0.001996
BIAS:[0.90] | Model:[GCN] Epoch:[4/100] Loss:[0.4161] Train:[83.95] val:[82.41] Test:[70.81] | Best Val:[83.04] Update Test:[72.19] at Epoch:[3] | lr:0.001992
BIAS:[0.90] | Model:[GCN] Epoch:[5/100] Loss:[0.3926] Train:[83.99] val:[80.65] Test:[75.62] | Best Val:[83.04] Update Test:[72.19] at Epoch:[3] | lr:0.001988
BIAS:[0.90] | Model:[GCN] Epoch:[6/100] Loss:[0.3605] Train:[85.44] val:[84.30] Test:[77.75] | Best Val:[84.30] Update Test:[77.75] at Epoch:[6] | lr:0.001982
BIAS:[0.90] | Model:[GCN] Epoch:[7/100] Loss:[0.3545] Train:[86.08] val:[81.53] Test:[73.69] | Best Val:[84.30] Update Test:[77.75] at Epoch:[6] | lr:0.001976
BIAS:[0.90] | Model:[GCN] Epoch:[8/100] Loss:[0.3423] Train:[86.60] val:[85.55] Test:[77.88] | Best Val:[85.55] Update Test:[77.88] at Epoch:[8] | lr:0.001969
BIAS:[0.90] | Model:[GCN] Epoch:[9/100] Loss:[0.3234] Train:[87.38] val:[87.44] Test:[75.12] | Best Val:[87.44] Update Test:[75.12] at Epoch:[9] | lr:0.001960
BIAS:[0.90] | Model:[GCN] Epoch:[10/100] Loss:[0.3289] Train:[87.10] val:[86.06] Test:[82.31] | Best Val:[87.44] Update Test:[75.12] at Epoch:[9] | lr:0.001951
BIAS:[0.90] | Model:[GCN] Epoch:[11/100] Loss:[0.2882] Train:[88.97] val:[84.67] Test:[77.94] | Best Val:[87.44] Update Test:[75.12] at Epoch:[9] | lr:0.001941
BIAS:[0.90] | Model:[GCN] Epoch:[12/100] Loss:[0.2883] Train:[89.17] val:[67.96] Test:[59.69] | Best Val:[87.44] Update Test:[75.12] at Epoch:[9] | lr:0.001930
BIAS:[0.90] | Model:[GCN] Epoch:[13/100] Loss:[0.2901] Train:[88.99] val:[88.57] Test:[81.19] | Best Val:[88.57] Update Test:[81.19] at Epoch:[13] | lr:0.001918
BIAS:[0.90] | Model:[GCN] Epoch:[14/100] Loss:[0.2889] Train:[89.03] val:[87.69] Test:[84.00] | Best Val:[88.57] Update Test:[81.19] at Epoch:[13] | lr:0.001905
BIAS:[0.90] | Model:[GCN] Epoch:[15/100] Loss:[0.2839] Train:[89.44] val:[86.31] Test:[82.88] | Best Val:[88.57] Update Test:[81.19] at Epoch:[13] | lr:0.001891
BIAS:[0.90] | Model:[GCN] Epoch:[16/100] Loss:[0.2575] Train:[90.64] val:[87.06] Test:[80.69] | Best Val:[88.57] Update Test:[81.19] at Epoch:[13] | lr:0.001877
BIAS:[0.90] | Model:[GCN] Epoch:[17/100] Loss:[0.2364] Train:[90.71] val:[87.94] Test:[85.19] | Best Val:[88.57] Update Test:[81.19] at Epoch:[13] | lr:0.001861
BIAS:[0.90] | Model:[GCN] Epoch:[18/100] Loss:[0.2310] Train:[90.96] val:[90.33] Test:[81.75] | Best Val:[90.33] Update Test:[81.75] at Epoch:[18] | lr:0.001845
BIAS:[0.90] | Model:[GCN] Epoch:[19/100] Loss:[0.2243] Train:[91.73] val:[91.71] Test:[84.25] | Best Val:[91.71] Update Test:[84.25] at Epoch:[19] | lr:0.001828
BIAS:[0.90] | Model:[GCN] Epoch:[20/100] Loss:[0.2121] Train:[92.42] val:[90.20] Test:[83.62] | Best Val:[91.71] Update Test:[84.25] at Epoch:[19] | lr:0.001809
BIAS:[0.90] | Model:[GCN] Epoch:[21/100] Loss:[0.2040] Train:[92.76] val:[90.20] Test:[82.69] | Best Val:[91.71] Update Test:[84.25] at Epoch:[19] | lr:0.001791
BIAS:[0.90] | Model:[GCN] Epoch:[22/100] Loss:[0.2112] Train:[92.33] val:[89.32] Test:[85.94] | Best Val:[91.71] Update Test:[84.25] at Epoch:[19] | lr:0.001771
BIAS:[0.90] | Model:[GCN] Epoch:[23/100] Loss:[0.1895] Train:[93.46] val:[92.59] Test:[88.19] | Best Val:[92.59] Update Test:[88.19] at Epoch:[23] | lr:0.001751
BIAS:[0.90] | Model:[GCN] Epoch:[24/100] Loss:[0.1767] Train:[93.58] val:[86.56] Test:[80.81] | Best Val:[92.59] Update Test:[88.19] at Epoch:[23] | lr:0.001730
BIAS:[0.90] | Model:[GCN] Epoch:[25/100] Loss:[0.1863] Train:[93.32] val:[88.57] Test:[85.56] | Best Val:[92.59] Update Test:[88.19] at Epoch:[23] | lr:0.001708
BIAS:[0.90] | Model:[GCN] Epoch:[26/100] Loss:[0.1763] Train:[93.48] val:[91.96] Test:[83.00] | Best Val:[92.59] Update Test:[88.19] at Epoch:[23] | lr:0.001685
BIAS:[0.90] | Model:[GCN] Epoch:[27/100] Loss:[0.1575] Train:[94.67] val:[90.95] Test:[86.38] | Best Val:[92.59] Update Test:[88.19] at Epoch:[23] | lr:0.001662
BIAS:[0.90] | Model:[GCN] Epoch:[28/100] Loss:[0.1582] Train:[94.37] val:[93.22] Test:[86.44] | Best Val:[93.22] Update Test:[86.44] at Epoch:[28] | lr:0.001638
BIAS:[0.90] | Model:[GCN] Epoch:[29/100] Loss:[0.1450] Train:[94.87] val:[90.08] Test:[82.06] | Best Val:[93.22] Update Test:[86.44] at Epoch:[28] | lr:0.001614
BIAS:[0.90] | Model:[GCN] Epoch:[30/100] Loss:[0.1610] Train:[94.26] val:[92.09] Test:[88.00] | Best Val:[93.22] Update Test:[86.44] at Epoch:[28] | lr:0.001589
BIAS:[0.90] | Model:[GCN] Epoch:[31/100] Loss:[0.1475] Train:[94.53] val:[92.46] Test:[84.56] | Best Val:[93.22] Update Test:[86.44] at Epoch:[28] | lr:0.001563
BIAS:[0.90] | Model:[GCN] Epoch:[32/100] Loss:[0.1478] Train:[94.48] val:[90.83] Test:[87.44] | Best Val:[93.22] Update Test:[86.44] at Epoch:[28] | lr:0.001537
BIAS:[0.90] | Model:[GCN] Epoch:[33/100] Loss:[0.1286] Train:[95.28] val:[93.09] Test:[89.75] | Best Val:[93.22] Update Test:[86.44] at Epoch:[28] | lr:0.001510
BIAS:[0.90] | Model:[GCN] Epoch:[34/100] Loss:[0.1292] Train:[95.59] val:[92.59] Test:[86.12] | Best Val:[93.22] Update Test:[86.44] at Epoch:[28] | lr:0.001483
BIAS:[0.90] | Model:[GCN] Epoch:[35/100] Loss:[0.1239] Train:[95.73] val:[91.21] Test:[89.69] | Best Val:[93.22] Update Test:[86.44] at Epoch:[28] | lr:0.001455
BIAS:[0.90] | Model:[GCN] Epoch:[36/100] Loss:[0.1188] Train:[95.73] val:[91.58] Test:[88.88] | Best Val:[93.22] Update Test:[86.44] at Epoch:[28] | lr:0.001427
BIAS:[0.90] | Model:[GCN] Epoch:[37/100] Loss:[0.1192] Train:[95.98] val:[92.59] Test:[87.81] | Best Val:[93.22] Update Test:[86.44] at Epoch:[28] | lr:0.001399
BIAS:[0.90] | Model:[GCN] Epoch:[38/100] Loss:[0.1121] Train:[96.03] val:[91.96] Test:[85.94] | Best Val:[93.22] Update Test:[86.44] at Epoch:[28] | lr:0.001370
BIAS:[0.90] | Model:[GCN] Epoch:[39/100] Loss:[0.1073] Train:[96.46] val:[91.83] Test:[88.56] | Best Val:[93.22] Update Test:[86.44] at Epoch:[28] | lr:0.001340
BIAS:[0.90] | Model:[GCN] Epoch:[40/100] Loss:[0.0931] Train:[96.80] val:[92.59] Test:[87.19] | Best Val:[93.22] Update Test:[86.44] at Epoch:[28] | lr:0.001311
BIAS:[0.90] | Model:[GCN] Epoch:[41/100] Loss:[0.0916] Train:[96.94] val:[93.22] Test:[89.44] | Best Val:[93.22] Update Test:[86.44] at Epoch:[28] | lr:0.001281
BIAS:[0.90] | Model:[GCN] Epoch:[42/100] Loss:[0.0828] Train:[97.02] val:[92.34] Test:[90.00] | Best Val:[93.22] Update Test:[86.44] at Epoch:[28] | lr:0.001251
BIAS:[0.90] | Model:[GCN] Epoch:[43/100] Loss:[0.0911] Train:[96.82] val:[88.82] Test:[88.44] | Best Val:[93.22] Update Test:[86.44] at Epoch:[28] | lr:0.001220
BIAS:[0.90] | Model:[GCN] Epoch:[44/100] Loss:[0.0836] Train:[97.07] val:[93.22] Test:[88.94] | Best Val:[93.22] Update Test:[86.44] at Epoch:[28] | lr:0.001189
BIAS:[0.90] | Model:[GCN] Epoch:[45/100] Loss:[0.0857] Train:[97.19] val:[91.71] Test:[86.81] | Best Val:[93.22] Update Test:[86.44] at Epoch:[28] | lr:0.001159
BIAS:[0.90] | Model:[GCN] Epoch:[46/100] Loss:[0.0940] Train:[96.68] val:[93.09] Test:[87.69] | Best Val:[93.22] Update Test:[86.44] at Epoch:[28] | lr:0.001128
BIAS:[0.90] | Model:[GCN] Epoch:[47/100] Loss:[0.0758] Train:[97.37] val:[92.09] Test:[90.88] | Best Val:[93.22] Update Test:[86.44] at Epoch:[28] | lr:0.001096
BIAS:[0.90] | Model:[GCN] Epoch:[48/100] Loss:[0.0704] Train:[97.46] val:[93.22] Test:[90.69] | Best Val:[93.22] Update Test:[86.44] at Epoch:[28] | lr:0.001065
BIAS:[0.90] | Model:[GCN] Epoch:[49/100] Loss:[0.0755] Train:[97.36] val:[91.58] Test:[90.00] | Best Val:[93.22] Update Test:[86.44] at Epoch:[28] | lr:0.001034
BIAS:[0.90] | Model:[GCN] Epoch:[50/100] Loss:[0.0625] Train:[98.03] val:[93.34] Test:[88.62] | Best Val:[93.34] Update Test:[88.62] at Epoch:[50] | lr:0.001003
BIAS:[0.90] | Model:[GCN] Epoch:[51/100] Loss:[0.0492] Train:[98.43] val:[92.59] Test:[88.62] | Best Val:[93.34] Update Test:[88.62] at Epoch:[50] | lr:0.000971
BIAS:[0.90] | Model:[GCN] Epoch:[52/100] Loss:[0.0609] Train:[97.61] val:[93.22] Test:[89.62] | Best Val:[93.34] Update Test:[88.62] at Epoch:[50] | lr:0.000940
BIAS:[0.90] | Model:[GCN] Epoch:[53/100] Loss:[0.0619] Train:[97.84] val:[93.22] Test:[86.56] | Best Val:[93.34] Update Test:[88.62] at Epoch:[50] | lr:0.000909
BIAS:[0.90] | Model:[GCN] Epoch:[54/100] Loss:[0.0437] Train:[98.57] val:[92.71] Test:[88.81] | Best Val:[93.34] Update Test:[88.62] at Epoch:[50] | lr:0.000877
BIAS:[0.90] | Model:[GCN] Epoch:[55/100] Loss:[0.0347] Train:[99.07] val:[92.59] Test:[90.38] | Best Val:[93.34] Update Test:[88.62] at Epoch:[50] | lr:0.000846
BIAS:[0.90] | Model:[GCN] Epoch:[56/100] Loss:[0.0367] Train:[98.91] val:[93.72] Test:[89.19] | Best Val:[93.72] Update Test:[89.19] at Epoch:[56] | lr:0.000816
BIAS:[0.90] | Model:[GCN] Epoch:[57/100] Loss:[0.0353] Train:[99.02] val:[94.22] Test:[90.88] | Best Val:[94.22] Update Test:[90.88] at Epoch:[57] | lr:0.000785
BIAS:[0.90] | Model:[GCN] Epoch:[58/100] Loss:[0.0349] Train:[98.82] val:[93.09] Test:[88.94] | Best Val:[94.22] Update Test:[90.88] at Epoch:[57] | lr:0.000754
BIAS:[0.90] | Model:[GCN] Epoch:[59/100] Loss:[0.0289] Train:[99.16] val:[93.22] Test:[90.06] | Best Val:[94.22] Update Test:[90.88] at Epoch:[57] | lr:0.000724
BIAS:[0.90] | Model:[GCN] Epoch:[60/100] Loss:[0.0263] Train:[99.23] val:[92.59] Test:[88.69] | Best Val:[94.22] Update Test:[90.88] at Epoch:[57] | lr:0.000694
BIAS:[0.90] | Model:[GCN] Epoch:[61/100] Loss:[0.0220] Train:[99.52] val:[92.21] Test:[90.00] | Best Val:[94.22] Update Test:[90.88] at Epoch:[57] | lr:0.000665
BIAS:[0.90] | Model:[GCN] Epoch:[62/100] Loss:[0.0221] Train:[99.50] val:[92.96] Test:[89.12] | Best Val:[94.22] Update Test:[90.88] at Epoch:[57] | lr:0.000635
BIAS:[0.90] | Model:[GCN] Epoch:[63/100] Loss:[0.0160] Train:[99.70] val:[93.09] Test:[90.62] | Best Val:[94.22] Update Test:[90.88] at Epoch:[57] | lr:0.000606
BIAS:[0.90] | Model:[GCN] Epoch:[64/100] Loss:[0.0173] Train:[99.59] val:[93.47] Test:[90.31] | Best Val:[94.22] Update Test:[90.88] at Epoch:[57] | lr:0.000578
BIAS:[0.90] | Model:[GCN] Epoch:[65/100] Loss:[0.0218] Train:[99.32] val:[92.34] Test:[89.25] | Best Val:[94.22] Update Test:[90.88] at Epoch:[57] | lr:0.000550
BIAS:[0.90] | Model:[GCN] Epoch:[66/100] Loss:[0.0185] Train:[99.52] val:[93.09] Test:[90.50] | Best Val:[94.22] Update Test:[90.88] at Epoch:[57] | lr:0.000522
BIAS:[0.90] | Model:[GCN] Epoch:[67/100] Loss:[0.0146] Train:[99.75] val:[93.22] Test:[89.75] | Best Val:[94.22] Update Test:[90.88] at Epoch:[57] | lr:0.000495
BIAS:[0.90] | Model:[GCN] Epoch:[68/100] Loss:[0.0130] Train:[99.80] val:[93.97] Test:[88.88] | Best Val:[94.22] Update Test:[90.88] at Epoch:[57] | lr:0.000468
BIAS:[0.90] | Model:[GCN] Epoch:[69/100] Loss:[0.0104] Train:[99.79] val:[92.59] Test:[90.25] | Best Val:[94.22] Update Test:[90.88] at Epoch:[57] | lr:0.000442
BIAS:[0.90] | Model:[GCN] Epoch:[70/100] Loss:[0.0115] Train:[99.84] val:[93.34] Test:[90.25] | Best Val:[94.22] Update Test:[90.88] at Epoch:[57] | lr:0.000416
BIAS:[0.90] | Model:[GCN] Epoch:[71/100] Loss:[0.0103] Train:[99.79] val:[92.71] Test:[90.12] | Best Val:[94.22] Update Test:[90.88] at Epoch:[57] | lr:0.000391
BIAS:[0.90] | Model:[GCN] Epoch:[72/100] Loss:[0.0076] Train:[99.91] val:[93.59] Test:[90.56] | Best Val:[94.22] Update Test:[90.88] at Epoch:[57] | lr:0.000367
BIAS:[0.90] | Model:[GCN] Epoch:[73/100] Loss:[0.0076] Train:[99.96] val:[93.47] Test:[89.62] | Best Val:[94.22] Update Test:[90.88] at Epoch:[57] | lr:0.000343
BIAS:[0.90] | Model:[GCN] Epoch:[74/100] Loss:[0.0063] Train:[99.91] val:[93.47] Test:[90.56] | Best Val:[94.22] Update Test:[90.88] at Epoch:[57] | lr:0.000320
BIAS:[0.90] | Model:[GCN] Epoch:[75/100] Loss:[0.0067] Train:[99.95] val:[93.34] Test:[89.56] | Best Val:[94.22] Update Test:[90.88] at Epoch:[57] | lr:0.000297
BIAS:[0.90] | Model:[GCN] Epoch:[76/100] Loss:[0.0066] Train:[99.95] val:[93.59] Test:[90.19] | Best Val:[94.22] Update Test:[90.88] at Epoch:[57] | lr:0.000275
BIAS:[0.90] | Model:[GCN] Epoch:[77/100] Loss:[0.0065] Train:[99.91] val:[93.72] Test:[89.94] | Best Val:[94.22] Update Test:[90.88] at Epoch:[57] | lr:0.000254
BIAS:[0.90] | Model:[GCN] Epoch:[78/100] Loss:[0.0053] Train:[99.96] val:[93.09] Test:[90.25] | Best Val:[94.22] Update Test:[90.88] at Epoch:[57] | lr:0.000234
BIAS:[0.90] | Model:[GCN] Epoch:[79/100] Loss:[0.0058] Train:[99.93] val:[93.09] Test:[90.12] | Best Val:[94.22] Update Test:[90.88] at Epoch:[57] | lr:0.000214
BIAS:[0.90] | Model:[GCN] Epoch:[80/100] Loss:[0.0056] Train:[99.96] val:[93.47] Test:[90.25] | Best Val:[94.22] Update Test:[90.88] at Epoch:[57] | lr:0.000196
BIAS:[0.90] | Model:[GCN] Epoch:[81/100] Loss:[0.0053] Train:[99.95] val:[93.34] Test:[90.38] | Best Val:[94.22] Update Test:[90.88] at Epoch:[57] | lr:0.000177
BIAS:[0.90] | Model:[GCN] Epoch:[82/100] Loss:[0.0043] Train:[99.96] val:[93.47] Test:[90.25] | Best Val:[94.22] Update Test:[90.88] at Epoch:[57] | lr:0.000160
BIAS:[0.90] | Model:[GCN] Epoch:[83/100] Loss:[0.0054] Train:[99.95] val:[93.47] Test:[90.12] | Best Val:[94.22] Update Test:[90.88] at Epoch:[57] | lr:0.000144
BIAS:[0.90] | Model:[GCN] Epoch:[84/100] Loss:[0.0044] Train:[100.00] val:[93.59] Test:[90.31] | Best Val:[94.22] Update Test:[90.88] at Epoch:[57] | lr:0.000128
BIAS:[0.90] | Model:[GCN] Epoch:[85/100] Loss:[0.0048] Train:[99.93] val:[93.47] Test:[90.56] | Best Val:[94.22] Update Test:[90.88] at Epoch:[57] | lr:0.000114
BIAS:[0.90] | Model:[GCN] Epoch:[86/100] Loss:[0.0044] Train:[99.98] val:[93.72] Test:[90.12] | Best Val:[94.22] Update Test:[90.88] at Epoch:[57] | lr:0.000100
BIAS:[0.90] | Model:[GCN] Epoch:[87/100] Loss:[0.0049] Train:[99.95] val:[93.34] Test:[90.44] | Best Val:[94.22] Update Test:[90.88] at Epoch:[57] | lr:0.000087
BIAS:[0.90] | Model:[GCN] Epoch:[88/100] Loss:[0.0048] Train:[100.00] val:[93.59] Test:[90.06] | Best Val:[94.22] Update Test:[90.88] at Epoch:[57] | lr:0.000075
BIAS:[0.90] | Model:[GCN] Epoch:[89/100] Loss:[0.0037] Train:[99.98] val:[93.84] Test:[90.38] | Best Val:[94.22] Update Test:[90.88] at Epoch:[57] | lr:0.000064
BIAS:[0.90] | Model:[GCN] Epoch:[90/100] Loss:[0.0034] Train:[100.00] val:[93.59] Test:[90.31] | Best Val:[94.22] Update Test:[90.88] at Epoch:[57] | lr:0.000054
BIAS:[0.90] | Model:[GCN] Epoch:[91/100] Loss:[0.0035] Train:[100.00] val:[93.47] Test:[90.38] | Best Val:[94.22] Update Test:[90.88] at Epoch:[57] | lr:0.000045
BIAS:[0.90] | Model:[GCN] Epoch:[92/100] Loss:[0.0033] Train:[99.98] val:[93.47] Test:[90.12] | Best Val:[94.22] Update Test:[90.88] at Epoch:[57] | lr:0.000036
BIAS:[0.90] | Model:[GCN] Epoch:[93/100] Loss:[0.0036] Train:[100.00] val:[93.47] Test:[90.31] | Best Val:[94.22] Update Test:[90.88] at Epoch:[57] | lr:0.000029
BIAS:[0.90] | Model:[GCN] Epoch:[94/100] Loss:[0.0041] Train:[99.95] val:[93.47] Test:[90.25] | Best Val:[94.22] Update Test:[90.88] at Epoch:[57] | lr:0.000023
BIAS:[0.90] | Model:[GCN] Epoch:[95/100] Loss:[0.0046] Train:[99.98] val:[93.72] Test:[90.31] | Best Val:[94.22] Update Test:[90.88] at Epoch:[57] | lr:0.000017
BIAS:[0.90] | Model:[GCN] Epoch:[96/100] Loss:[0.0033] Train:[99.98] val:[93.47] Test:[90.75] | Best Val:[94.22] Update Test:[90.88] at Epoch:[57] | lr:0.000013
BIAS:[0.90] | Model:[GCN] Epoch:[97/100] Loss:[0.0036] Train:[99.98] val:[93.47] Test:[90.12] | Best Val:[94.22] Update Test:[90.88] at Epoch:[57] | lr:0.000009
BIAS:[0.90] | Model:[GCN] Epoch:[98/100] Loss:[0.0032] Train:[100.00] val:[93.47] Test:[90.56] | Best Val:[94.22] Update Test:[90.88] at Epoch:[57] | lr:0.000007
BIAS:[0.90] | Model:[GCN] Epoch:[99/100] Loss:[0.0033] Train:[99.98] val:[93.47] Test:[90.50] | Best Val:[94.22] Update Test:[90.88] at Epoch:[57] | lr:0.000005
BIAS:[0.90] | Model:[GCN] Epoch:[100/100] Loss:[0.0035] Train:[99.96] val:[93.59] Test:[90.25] | Best Val:[94.22] Update Test:[90.88] at Epoch:[57] | lr:0.000005
syd: BIAS:[0.90] | Best Val acc:[94.22] Test acc:[90.88] at epoch:[57]
step_size..................................................................0.001
min_lr.....................................................................5e-06
pretrain......................................................................30
data_num....................................................................2000
node_num......................................................................15
max_degree....................................................................10
feature_dim...................................................................-1
noise........................................................................0.1
num_classes....................................................................4
shape_num......................................................................1
bias.........................................................................0.9
penalty_weight...............................................................0.1
train_type..................................................................base
epochs.......................................................................100
batch_size...................................................................128
the............................................................................0
with_random.................................................................True
eval_random................................................................False
normalize..................................................................False
save_model.................................................................False
inference..................................................................False
without_node_attention.....................................................False
without_edge_attention.....................................................False
k..............................................................................3
layers.........................................................................3
c............................................................................0.5
o............................................................................1.0
co...........................................................................0.5
harf_hidden..................................................................0.5
cat_or_add...................................................................add
num_layers.....................................................................3
folds.........................................................................10
fc_num.......................................................................222
data_root...................................................................data
save_dir...................................................................debug
dataset.....................................................................NCI1
epoch_select............................................................test_max
model..................................................................CausalGCN
hidden.......................................................................128
seed.........................................................................666
lr.........................................................................0.002
lr_decay_factor..............................................................0.5
lr_decay_step_size...........................................................500
weight_decay...................................................................0
global_pool..................................................................sum

----------------------------------------------------------------------------------------------------
| graph: Tree-house | nodes num:246 | edges num:542 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: BA-house | nodes num:230 | edges num:996 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: Tree-cycle | nodes num:247 | edges num:542 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: BA-cycle | nodes num:231 | edges num:996 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: Tree-grid | nodes num:247 | edges num:544 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: BA-grid | nodes num:231 | edges num:998 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: Tree-diamond | nodes num:247 | edges num:546 |
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
| graph: BA-diamond | nodes num:231 | edges num:1000 |
----------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
Train Total:5596
| Tree: House:1260 , Cycle:139  , Grids:139  , Diams:139   
| BA  : House:139  , Cycle:1260 , Grids:1260 , Diams:1260  
| All : House:1399 , Cycle:1399 , Grids:1399 , Diams:1399  
| BIAS: House:90.1%, Cycle:9.9%, Grids:9.9%, Diams:9.9%
------------------------------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
Val    Total:796
| Tree: House:180  , Cycle:19   , Grids:19   , Diams:19    
| BA  : House:19   , Cycle:180  , Grids:180  , Diams:180   
| All : House:199  , Cycle:199  , Grids:199  , Diams:199   
| BIAS: House:90.5%, Cycle:9.5%, Grids:9.5%, Diams:9.5%
------------------------------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------------------------------
Test   Total:1600
| Tree: House:200  , Cycle:200  , Grids:200  , Diams:200   
| BA  : House:200  , Cycle:200  , Grids:200  , Diams:200   
| All : House:400  , Cycle:400  , Grids:400  , Diams:400   
| BIAS: House:50.0%, Cycle:50.0%, Grids:50.0%, Diams:50.0%
------------------------------------------------------------------------------------------------------------------------------------------------------
BIAS:[0.90] | Model:[CausalGCN] Epoch:[1/100] Loss:[1.0805=0.0183+0.6767+0.7893] Train:[71.82] val:[65.45] Test:[59.38] | Update Test:[co:60.19,c:25.69,o:59.38] at Epoch:[1] | lr:0.002000
BIAS:[0.90] | Model:[CausalGCN] Epoch:[2/100] Loss:[0.6478=0.0020+0.4120+0.4695] Train:[83.90] val:[83.92] Test:[78.38] | Update Test:[co:72.50,c:25.75,o:78.38] at Epoch:[2] | lr:0.001998
BIAS:[0.90] | Model:[CausalGCN] Epoch:[3/100] Loss:[0.5580=0.0010+0.3626+0.3897] Train:[86.15] val:[85.05] Test:[76.56] | Update Test:[co:74.12,c:28.69,o:76.56] at Epoch:[3] | lr:0.001996
BIAS:[0.90] | Model:[CausalGCN] Epoch:[4/100] Loss:[0.5007=0.0005+0.3242+0.3525] Train:[87.35] val:[85.05] Test:[83.31] | Update Test:[co:74.12,c:28.69,o:76.56] at Epoch:[3] | lr:0.001992
BIAS:[0.90] | Model:[CausalGCN] Epoch:[5/100] Loss:[0.4602=0.0005+0.3001+0.3197] Train:[88.28] val:[86.81] Test:[82.88] | Update Test:[co:80.88,c:25.44,o:82.88] at Epoch:[5] | lr:0.001988
BIAS:[0.90] | Model:[CausalGCN] Epoch:[6/100] Loss:[0.4439=0.0005+0.2832+0.3209] Train:[89.15] val:[86.31] Test:[78.88] | Update Test:[co:80.88,c:25.44,o:82.88] at Epoch:[5] | lr:0.001982
BIAS:[0.90] | Model:[CausalGCN] Epoch:[7/100] Loss:[0.4175=0.0004+0.2699+0.2949] Train:[89.83] val:[86.56] Test:[83.50] | Update Test:[co:80.88,c:25.44,o:82.88] at Epoch:[5] | lr:0.001976
BIAS:[0.90] | Model:[CausalGCN] Epoch:[8/100] Loss:[0.4017=0.0002+0.2595+0.2843] Train:[90.10] val:[81.28] Test:[77.44] | Update Test:[co:80.88,c:25.44,o:82.88] at Epoch:[5] | lr:0.001969
BIAS:[0.90] | Model:[CausalGCN] Epoch:[9/100] Loss:[0.3754=0.0002+0.2450+0.2607] Train:[91.05] val:[88.32] Test:[88.00] | Update Test:[co:86.94,c:24.69,o:88.00] at Epoch:[9] | lr:0.001960
BIAS:[0.90] | Model:[CausalGCN] Epoch:[10/100] Loss:[0.3527=0.0002+0.2292+0.2469] Train:[91.35] val:[90.33] Test:[87.19] | Update Test:[co:83.44,c:25.19,o:87.19] at Epoch:[10] | lr:0.001951
BIAS:[0.90] | Model:[CausalGCN] Epoch:[11/100] Loss:[0.3332=0.0002+0.2166+0.2330] Train:[92.37] val:[89.07] Test:[84.38] | Update Test:[co:83.44,c:25.19,o:87.19] at Epoch:[10] | lr:0.001941
BIAS:[0.90] | Model:[CausalGCN] Epoch:[12/100] Loss:[0.3849=0.0001+0.2509+0.2679] Train:[90.42] val:[88.94] Test:[82.38] | Update Test:[co:83.44,c:25.19,o:87.19] at Epoch:[10] | lr:0.001930
BIAS:[0.90] | Model:[CausalGCN] Epoch:[13/100] Loss:[0.3209=0.0001+0.2084+0.2248] Train:[92.23] val:[90.20] Test:[83.38] | Update Test:[co:83.44,c:25.19,o:87.19] at Epoch:[10] | lr:0.001918
BIAS:[0.90] | Model:[CausalGCN] Epoch:[14/100] Loss:[0.3170=0.0001+0.2046+0.2247] Train:[92.19] val:[91.33] Test:[86.06] | Update Test:[co:84.81,c:26.44,o:86.06] at Epoch:[14] | lr:0.001905
BIAS:[0.90] | Model:[CausalGCN] Epoch:[15/100] Loss:[0.2983=0.0001+0.1928+0.2107] Train:[92.89] val:[91.71] Test:[88.56] | Update Test:[co:86.38,c:25.00,o:88.56] at Epoch:[15] | lr:0.001891
BIAS:[0.90] | Model:[CausalGCN] Epoch:[16/100] Loss:[0.2672=0.0001+0.1717+0.1909] Train:[93.85] val:[92.71] Test:[89.56] | Update Test:[co:89.81,c:24.44,o:89.56] at Epoch:[16] | lr:0.001877
BIAS:[0.90] | Model:[CausalGCN] Epoch:[17/100] Loss:[0.2801=0.0001+0.1789+0.2023] Train:[93.64] val:[89.95] Test:[86.12] | Update Test:[co:89.81,c:24.44,o:89.56] at Epoch:[16] | lr:0.001861
BIAS:[0.90] | Model:[CausalGCN] Epoch:[18/100] Loss:[0.2727=0.0001+0.1749+0.1955] Train:[93.71] val:[89.20] Test:[88.75] | Update Test:[co:89.81,c:24.44,o:89.56] at Epoch:[16] | lr:0.001845
BIAS:[0.90] | Model:[CausalGCN] Epoch:[19/100] Loss:[0.2521=0.0001+0.1615+0.1809] Train:[94.12] val:[93.09] Test:[85.62] | Update Test:[co:87.06,c:24.31,o:85.62] at Epoch:[19] | lr:0.001828
BIAS:[0.90] | Model:[CausalGCN] Epoch:[20/100] Loss:[0.2293=0.0001+0.1442+0.1701] Train:[94.85] val:[91.71] Test:[88.94] | Update Test:[co:87.06,c:24.31,o:85.62] at Epoch:[19] | lr:0.001809
BIAS:[0.90] | Model:[CausalGCN] Epoch:[21/100] Loss:[0.2331=0.0001+0.1482+0.1697] Train:[94.60] val:[92.71] Test:[90.94] | Update Test:[co:87.06,c:24.31,o:85.62] at Epoch:[19] | lr:0.001791
BIAS:[0.90] | Model:[CausalGCN] Epoch:[22/100] Loss:[0.2522=0.0001+0.1609+0.1825] Train:[93.96] val:[92.46] Test:[87.56] | Update Test:[co:87.06,c:24.31,o:85.62] at Epoch:[19] | lr:0.001771
BIAS:[0.90] | Model:[CausalGCN] Epoch:[23/100] Loss:[0.2147=0.0001+0.1362+0.1568] Train:[94.94] val:[93.84] Test:[87.25] | Update Test:[co:87.75,c:23.31,o:87.25] at Epoch:[23] | lr:0.001751
BIAS:[0.90] | Model:[CausalGCN] Epoch:[24/100] Loss:[0.2043=0.0001+0.1277+0.1530] Train:[95.57] val:[93.72] Test:[88.69] | Update Test:[co:87.75,c:23.31,o:87.25] at Epoch:[23] | lr:0.001730
BIAS:[0.90] | Model:[CausalGCN] Epoch:[25/100] Loss:[0.1866=0.0001+0.1173+0.1386] Train:[95.82] val:[94.47] Test:[91.12] | Update Test:[co:89.94,c:24.38,o:91.12] at Epoch:[25] | lr:0.001708
BIAS:[0.90] | Model:[CausalGCN] Epoch:[26/100] Loss:[0.1840=0.0001+0.1143+0.1393] Train:[96.02] val:[94.35] Test:[90.81] | Update Test:[co:89.94,c:24.38,o:91.12] at Epoch:[25] | lr:0.001685
BIAS:[0.90] | Model:[CausalGCN] Epoch:[27/100] Loss:[0.1608=0.0001+0.1001+0.1214] Train:[96.52] val:[91.83] Test:[87.00] | Update Test:[co:89.94,c:24.38,o:91.12] at Epoch:[25] | lr:0.001662
BIAS:[0.90] | Model:[CausalGCN] Epoch:[28/100] Loss:[0.1712=0.0001+0.1063+0.1297] Train:[96.32] val:[93.34] Test:[88.94] | Update Test:[co:89.94,c:24.38,o:91.12] at Epoch:[25] | lr:0.001638
BIAS:[0.90] | Model:[CausalGCN] Epoch:[29/100] Loss:[0.1607=0.0001+0.1005+0.1202] Train:[96.44] val:[93.84] Test:[90.25] | Update Test:[co:89.94,c:24.38,o:91.12] at Epoch:[25] | lr:0.001614
BIAS:[0.90] | Model:[CausalGCN] Epoch:[30/100] Loss:[0.1664=0.0001+0.1031+0.1265] Train:[96.50] val:[92.71] Test:[88.75] | Update Test:[co:89.94,c:24.38,o:91.12] at Epoch:[25] | lr:0.001589
BIAS:[0.90] | Model:[CausalGCN] Epoch:[31/100] Loss:[0.1455=0.0001+0.0900+0.1110] Train:[96.87] val:[94.60] Test:[92.69] | Update Test:[co:90.31,c:24.94,o:92.69] at Epoch:[31] | lr:0.001563
BIAS:[0.90] | Model:[CausalGCN] Epoch:[32/100] Loss:[0.1316=0.0001+0.0818+0.0995] Train:[97.16] val:[94.35] Test:[91.50] | Update Test:[co:90.31,c:24.94,o:92.69] at Epoch:[31] | lr:0.001537
BIAS:[0.90] | Model:[CausalGCN] Epoch:[33/100] Loss:[0.1177=0.0001+0.0718+0.0917] Train:[97.48] val:[93.59] Test:[90.62] | Update Test:[co:90.31,c:24.94,o:92.69] at Epoch:[31] | lr:0.001510
BIAS:[0.90] | Model:[CausalGCN] Epoch:[34/100] Loss:[0.1375=0.0001+0.0853+0.1044] Train:[97.00] val:[87.19] Test:[89.38] | Update Test:[co:90.31,c:24.94,o:92.69] at Epoch:[31] | lr:0.001483
BIAS:[0.90] | Model:[CausalGCN] Epoch:[35/100] Loss:[0.1189=0.0001+0.0741+0.0895] Train:[97.50] val:[93.09] Test:[88.69] | Update Test:[co:90.31,c:24.94,o:92.69] at Epoch:[31] | lr:0.001455
BIAS:[0.90] | Model:[CausalGCN] Epoch:[36/100] Loss:[0.1109=0.0001+0.0695+0.0827] Train:[97.59] val:[86.43] Test:[83.56] | Update Test:[co:90.31,c:24.94,o:92.69] at Epoch:[31] | lr:0.001427
BIAS:[0.90] | Model:[CausalGCN] Epoch:[37/100] Loss:[0.1303=0.0001+0.0807+0.0992] Train:[97.28] val:[90.95] Test:[87.12] | Update Test:[co:90.31,c:24.94,o:92.69] at Epoch:[31] | lr:0.001399
BIAS:[0.90] | Model:[CausalGCN] Epoch:[38/100] Loss:[0.1029=0.0001+0.0626+0.0804] Train:[97.75] val:[94.10] Test:[91.62] | Update Test:[co:90.31,c:24.94,o:92.69] at Epoch:[31] | lr:0.001370
BIAS:[0.90] | Model:[CausalGCN] Epoch:[39/100] Loss:[0.0865=0.0001+0.0522+0.0685] Train:[98.43] val:[92.84] Test:[94.31] | Update Test:[co:90.31,c:24.94,o:92.69] at Epoch:[31] | lr:0.001340
BIAS:[0.90] | Model:[CausalGCN] Epoch:[40/100] Loss:[0.0798=0.0001+0.0464+0.0668] Train:[98.59] val:[94.85] Test:[90.12] | Update Test:[co:91.12,c:24.62,o:90.12] at Epoch:[40] | lr:0.001311
BIAS:[0.90] | Model:[CausalGCN] Epoch:[41/100] Loss:[0.0738=0.0000+0.0439+0.0597] Train:[98.55] val:[94.85] Test:[92.38] | Update Test:[co:91.12,c:24.62,o:90.12] at Epoch:[40] | lr:0.001281
BIAS:[0.90] | Model:[CausalGCN] Epoch:[42/100] Loss:[0.0731=0.0000+0.0439+0.0584] Train:[98.64] val:[94.35] Test:[90.38] | Update Test:[co:91.12,c:24.62,o:90.12] at Epoch:[40] | lr:0.001251
BIAS:[0.90] | Model:[CausalGCN] Epoch:[43/100] Loss:[0.0852=0.0000+0.0511+0.0683] Train:[98.27] val:[93.09] Test:[88.81] | Update Test:[co:91.12,c:24.62,o:90.12] at Epoch:[40] | lr:0.001220
BIAS:[0.90] | Model:[CausalGCN] Epoch:[44/100] Loss:[0.0711=0.0000+0.0414+0.0594] Train:[98.62] val:[94.22] Test:[92.06] | Update Test:[co:91.12,c:24.62,o:90.12] at Epoch:[40] | lr:0.001189
BIAS:[0.90] | Model:[CausalGCN] Epoch:[45/100] Loss:[0.0616=0.0000+0.0367+0.0498] Train:[98.75] val:[92.96] Test:[93.50] | Update Test:[co:91.12,c:24.62,o:90.12] at Epoch:[40] | lr:0.001159
BIAS:[0.90] | Model:[CausalGCN] Epoch:[46/100] Loss:[0.0489=0.0000+0.0287+0.0403] Train:[99.16] val:[94.47] Test:[89.88] | Update Test:[co:91.12,c:24.62,o:90.12] at Epoch:[40] | lr:0.001128
BIAS:[0.90] | Model:[CausalGCN] Epoch:[47/100] Loss:[0.0554=0.0001+0.0325+0.0457] Train:[98.91] val:[94.47] Test:[93.06] | Update Test:[co:91.12,c:24.62,o:90.12] at Epoch:[40] | lr:0.001096
BIAS:[0.90] | Model:[CausalGCN] Epoch:[48/100] Loss:[0.0594=0.0001+0.0356+0.0475] Train:[98.89] val:[94.10] Test:[93.25] | Update Test:[co:91.12,c:24.62,o:90.12] at Epoch:[40] | lr:0.001065
BIAS:[0.90] | Model:[CausalGCN] Epoch:[49/100] Loss:[0.0528=0.0000+0.0298+0.0461] Train:[98.96] val:[94.35] Test:[91.31] | Update Test:[co:91.12,c:24.62,o:90.12] at Epoch:[40] | lr:0.001034
BIAS:[0.90] | Model:[CausalGCN] Epoch:[50/100] Loss:[0.0557=0.0000+0.0321+0.0472] Train:[98.84] val:[94.10] Test:[91.81] | Update Test:[co:91.12,c:24.62,o:90.12] at Epoch:[40] | lr:0.001003
BIAS:[0.90] | Model:[CausalGCN] Epoch:[51/100] Loss:[0.0416=0.0000+0.0242+0.0348] Train:[99.25] val:[94.60] Test:[92.50] | Update Test:[co:91.12,c:24.62,o:90.12] at Epoch:[40] | lr:0.000971
BIAS:[0.90] | Model:[CausalGCN] Epoch:[52/100] Loss:[0.0356=0.0000+0.0206+0.0298] Train:[99.43] val:[91.71] Test:[92.31] | Update Test:[co:91.12,c:24.62,o:90.12] at Epoch:[40] | lr:0.000940
BIAS:[0.90] | Model:[CausalGCN] Epoch:[53/100] Loss:[0.0393=0.0000+0.0218+0.0348] Train:[99.29] val:[93.59] Test:[91.56] | Update Test:[co:91.12,c:24.62,o:90.12] at Epoch:[40] | lr:0.000909
BIAS:[0.90] | Model:[CausalGCN] Epoch:[54/100] Loss:[0.0236=0.0000+0.0130+0.0212] Train:[99.71] val:[94.35] Test:[94.12] | Update Test:[co:91.12,c:24.62,o:90.12] at Epoch:[40] | lr:0.000877
BIAS:[0.90] | Model:[CausalGCN] Epoch:[55/100] Loss:[0.0284=0.0000+0.0157+0.0254] Train:[99.66] val:[94.85] Test:[92.50] | Update Test:[co:91.12,c:24.62,o:90.12] at Epoch:[40] | lr:0.000846
BIAS:[0.90] | Model:[CausalGCN] Epoch:[56/100] Loss:[0.0212=0.0000+0.0119+0.0186] Train:[99.79] val:[95.23] Test:[92.88] | Update Test:[co:91.94,c:25.50,o:92.88] at Epoch:[56] | lr:0.000816
BIAS:[0.90] | Model:[CausalGCN] Epoch:[57/100] Loss:[0.0199=0.0000+0.0106+0.0186] Train:[99.73] val:[94.72] Test:[92.88] | Update Test:[co:91.94,c:25.50,o:92.88] at Epoch:[56] | lr:0.000785
BIAS:[0.90] | Model:[CausalGCN] Epoch:[58/100] Loss:[0.0233=0.0000+0.0121+0.0225] Train:[99.70] val:[94.97] Test:[92.00] | Update Test:[co:91.94,c:25.50,o:92.88] at Epoch:[56] | lr:0.000754
BIAS:[0.90] | Model:[CausalGCN] Epoch:[59/100] Loss:[0.0152=0.0000+0.0078+0.0147] Train:[99.87] val:[94.85] Test:[93.69] | Update Test:[co:91.94,c:25.50,o:92.88] at Epoch:[56] | lr:0.000724
BIAS:[0.90] | Model:[CausalGCN] Epoch:[60/100] Loss:[0.0117=0.0000+0.0054+0.0126] Train:[99.95] val:[95.35] Test:[93.31] | Update Test:[co:93.06,c:23.62,o:93.31] at Epoch:[60] | lr:0.000694
BIAS:[0.90] | Model:[CausalGCN] Epoch:[61/100] Loss:[0.0159=0.0000+0.0088+0.0142] Train:[99.77] val:[95.35] Test:[93.31] | Update Test:[co:93.06,c:23.62,o:93.31] at Epoch:[60] | lr:0.000665
BIAS:[0.90] | Model:[CausalGCN] Epoch:[62/100] Loss:[0.0106=0.0000+0.0053+0.0106] Train:[99.95] val:[94.85] Test:[93.25] | Update Test:[co:93.06,c:23.62,o:93.31] at Epoch:[60] | lr:0.000635
BIAS:[0.90] | Model:[CausalGCN] Epoch:[63/100] Loss:[0.0093=0.0000+0.0044+0.0098] Train:[99.96] val:[95.10] Test:[92.81] | Update Test:[co:93.06,c:23.62,o:93.31] at Epoch:[60] | lr:0.000606
BIAS:[0.90] | Model:[CausalGCN] Epoch:[64/100] Loss:[0.0088=0.0000+0.0042+0.0091] Train:[99.95] val:[95.48] Test:[92.88] | Update Test:[co:92.94,c:24.69,o:92.88] at Epoch:[64] | lr:0.000578
BIAS:[0.90] | Model:[CausalGCN] Epoch:[65/100] Loss:[0.0078=0.0000+0.0039+0.0079] Train:[99.93] val:[94.72] Test:[93.00] | Update Test:[co:92.94,c:24.69,o:92.88] at Epoch:[64] | lr:0.000550
BIAS:[0.90] | Model:[CausalGCN] Epoch:[66/100] Loss:[0.0102=0.0000+0.0056+0.0092] Train:[99.91] val:[95.10] Test:[93.75] | Update Test:[co:92.94,c:24.69,o:92.88] at Epoch:[64] | lr:0.000522
BIAS:[0.90] | Model:[CausalGCN] Epoch:[67/100] Loss:[0.0083=0.0000+0.0041+0.0082] Train:[99.93] val:[94.35] Test:[94.00] | Update Test:[co:92.94,c:24.69,o:92.88] at Epoch:[64] | lr:0.000495
BIAS:[0.90] | Model:[CausalGCN] Epoch:[68/100] Loss:[0.0100=0.0000+0.0050+0.0099] Train:[99.89] val:[94.85] Test:[93.69] | Update Test:[co:92.94,c:24.69,o:92.88] at Epoch:[64] | lr:0.000468
BIAS:[0.90] | Model:[CausalGCN] Epoch:[69/100] Loss:[0.0082=0.0000+0.0036+0.0090] Train:[99.98] val:[95.35] Test:[93.19] | Update Test:[co:92.94,c:24.69,o:92.88] at Epoch:[64] | lr:0.000442
BIAS:[0.90] | Model:[CausalGCN] Epoch:[70/100] Loss:[0.0056=0.0000+0.0024+0.0063] Train:[99.98] val:[94.97] Test:[93.81] | Update Test:[co:92.94,c:24.69,o:92.88] at Epoch:[64] | lr:0.000416
BIAS:[0.90] | Model:[CausalGCN] Epoch:[71/100] Loss:[0.0053=0.0000+0.0023+0.0060] Train:[100.00] val:[94.97] Test:[93.19] | Update Test:[co:92.94,c:24.69,o:92.88] at Epoch:[64] | lr:0.000391
BIAS:[0.90] | Model:[CausalGCN] Epoch:[72/100] Loss:[0.0054=0.0000+0.0027+0.0054] Train:[99.98] val:[95.23] Test:[94.06] | Update Test:[co:92.94,c:24.69,o:92.88] at Epoch:[64] | lr:0.000367
BIAS:[0.90] | Model:[CausalGCN] Epoch:[73/100] Loss:[0.0065=0.0000+0.0033+0.0063] Train:[99.95] val:[94.97] Test:[92.88] | Update Test:[co:92.94,c:24.69,o:92.88] at Epoch:[64] | lr:0.000343
BIAS:[0.90] | Model:[CausalGCN] Epoch:[74/100] Loss:[0.0060=0.0000+0.0029+0.0062] Train:[99.96] val:[94.72] Test:[93.06] | Update Test:[co:92.94,c:24.69,o:92.88] at Epoch:[64] | lr:0.000320
BIAS:[0.90] | Model:[CausalGCN] Epoch:[75/100] Loss:[0.0048=0.0000+0.0022+0.0052] Train:[100.00] val:[95.48] Test:[93.25] | Update Test:[co:92.94,c:24.69,o:92.88] at Epoch:[64] | lr:0.000297
BIAS:[0.90] | Model:[CausalGCN] Epoch:[76/100] Loss:[0.0040=0.0000+0.0019+0.0042] Train:[99.98] val:[95.35] Test:[93.25] | Update Test:[co:92.94,c:24.69,o:92.88] at Epoch:[64] | lr:0.000275
BIAS:[0.90] | Model:[CausalGCN] Epoch:[77/100] Loss:[0.0034=0.0000+0.0016+0.0035] Train:[100.00] val:[95.10] Test:[93.38] | Update Test:[co:92.94,c:24.69,o:92.88] at Epoch:[64] | lr:0.000254
BIAS:[0.90] | Model:[CausalGCN] Epoch:[78/100] Loss:[0.0035=0.0000+0.0016+0.0039] Train:[100.00] val:[95.35] Test:[93.50] | Update Test:[co:92.94,c:24.69,o:92.88] at Epoch:[64] | lr:0.000234
BIAS:[0.90] | Model:[CausalGCN] Epoch:[79/100] Loss:[0.0029=0.0000+0.0011+0.0034] Train:[100.00] val:[95.60] Test:[93.06] | Update Test:[co:93.12,c:27.12,o:93.06] at Epoch:[79] | lr:0.000214
BIAS:[0.90] | Model:[CausalGCN] Epoch:[80/100] Loss:[0.0032=0.0000+0.0017+0.0030] Train:[99.98] val:[95.35] Test:[93.25] | Update Test:[co:93.12,c:27.12,o:93.06] at Epoch:[79] | lr:0.000196
BIAS:[0.90] | Model:[CausalGCN] Epoch:[81/100] Loss:[0.0025=0.0000+0.0012+0.0026] Train:[100.00] val:[95.48] Test:[93.62] | Update Test:[co:93.12,c:27.12,o:93.06] at Epoch:[79] | lr:0.000177
BIAS:[0.90] | Model:[CausalGCN] Epoch:[82/100] Loss:[0.0032=0.0000+0.0014+0.0036] Train:[100.00] val:[95.48] Test:[93.44] | Update Test:[co:93.12,c:27.12,o:93.06] at Epoch:[79] | lr:0.000160
BIAS:[0.90] | Model:[CausalGCN] Epoch:[83/100] Loss:[0.0029=0.0000+0.0014+0.0031] Train:[99.98] val:[95.10] Test:[93.19] | Update Test:[co:93.12,c:27.12,o:93.06] at Epoch:[79] | lr:0.000144
BIAS:[0.90] | Model:[CausalGCN] Epoch:[84/100] Loss:[0.0030=0.0000+0.0014+0.0033] Train:[100.00] val:[95.35] Test:[93.38] | Update Test:[co:93.12,c:27.12,o:93.06] at Epoch:[79] | lr:0.000128
BIAS:[0.90] | Model:[CausalGCN] Epoch:[85/100] Loss:[0.0025=0.0000+0.0011+0.0027] Train:[100.00] val:[95.23] Test:[93.25] | Update Test:[co:93.12,c:27.12,o:93.06] at Epoch:[79] | lr:0.000114
BIAS:[0.90] | Model:[CausalGCN] Epoch:[86/100] Loss:[0.0028=0.0000+0.0014+0.0028] Train:[99.98] val:[95.23] Test:[93.88] | Update Test:[co:93.12,c:27.12,o:93.06] at Epoch:[79] | lr:0.000100
BIAS:[0.90] | Model:[CausalGCN] Epoch:[87/100] Loss:[0.0028=0.0000+0.0013+0.0029] Train:[100.00] val:[95.10] Test:[93.38] | Update Test:[co:93.12,c:27.12,o:93.06] at Epoch:[79] | lr:0.000087
BIAS:[0.90] | Model:[CausalGCN] Epoch:[88/100] Loss:[0.0023=0.0000+0.0010+0.0024] Train:[100.00] val:[95.35] Test:[93.75] | Update Test:[co:93.12,c:27.12,o:93.06] at Epoch:[79] | lr:0.000075
BIAS:[0.90] | Model:[CausalGCN] Epoch:[89/100] Loss:[0.0023=0.0000+0.0010+0.0024] Train:[100.00] val:[95.10] Test:[93.75] | Update Test:[co:93.12,c:27.12,o:93.06] at Epoch:[79] | lr:0.000064
BIAS:[0.90] | Model:[CausalGCN] Epoch:[90/100] Loss:[0.0022=0.0000+0.0010+0.0023] Train:[100.00] val:[95.35] Test:[93.50] | Update Test:[co:93.12,c:27.12,o:93.06] at Epoch:[79] | lr:0.000054
BIAS:[0.90] | Model:[CausalGCN] Epoch:[91/100] Loss:[0.0025=0.0000+0.0011+0.0027] Train:[100.00] val:[95.35] Test:[93.44] | Update Test:[co:93.12,c:27.12,o:93.06] at Epoch:[79] | lr:0.000045
BIAS:[0.90] | Model:[CausalGCN] Epoch:[92/100] Loss:[0.0023=0.0000+0.0010+0.0025] Train:[100.00] val:[95.60] Test:[93.44] | Update Test:[co:93.12,c:27.12,o:93.06] at Epoch:[79] | lr:0.000036
BIAS:[0.90] | Model:[CausalGCN] Epoch:[93/100] Loss:[0.0021=0.0000+0.0010+0.0022] Train:[100.00] val:[95.35] Test:[93.50] | Update Test:[co:93.12,c:27.12,o:93.06] at Epoch:[79] | lr:0.000029
BIAS:[0.90] | Model:[CausalGCN] Epoch:[94/100] Loss:[0.0020=0.0000+0.0010+0.0020] Train:[100.00] val:[95.35] Test:[93.69] | Update Test:[co:93.12,c:27.12,o:93.06] at Epoch:[79] | lr:0.000023
BIAS:[0.90] | Model:[CausalGCN] Epoch:[95/100] Loss:[0.0021=0.0000+0.0010+0.0021] Train:[100.00] val:[95.48] Test:[93.62] | Update Test:[co:93.12,c:27.12,o:93.06] at Epoch:[79] | lr:0.000017
BIAS:[0.90] | Model:[CausalGCN] Epoch:[96/100] Loss:[0.0018=0.0000+0.0008+0.0020] Train:[100.00] val:[95.48] Test:[93.50] | Update Test:[co:93.12,c:27.12,o:93.06] at Epoch:[79] | lr:0.000013
BIAS:[0.90] | Model:[CausalGCN] Epoch:[97/100] Loss:[0.0025=0.0000+0.0013+0.0024] Train:[99.98] val:[95.60] Test:[93.56] | Update Test:[co:93.12,c:27.12,o:93.06] at Epoch:[79] | lr:0.000009
BIAS:[0.90] | Model:[CausalGCN] Epoch:[98/100] Loss:[0.0024=0.0000+0.0011+0.0025] Train:[100.00] val:[95.35] Test:[93.38] | Update Test:[co:93.12,c:27.12,o:93.06] at Epoch:[79] | lr:0.000007
BIAS:[0.90] | Model:[CausalGCN] Epoch:[99/100] Loss:[0.0027=0.0000+0.0013+0.0027] Train:[100.00] val:[95.60] Test:[93.50] | Update Test:[co:93.12,c:27.12,o:93.06] at Epoch:[79] | lr:0.000005
BIAS:[0.90] | Model:[CausalGCN] Epoch:[100/100] Loss:[0.0027=0.0000+0.0015+0.0024] Train:[99.98] val:[95.48] Test:[93.50] | Update Test:[co:93.12,c:27.12,o:93.06] at Epoch:[79] | lr:0.000005
syd: BIAS:[0.90] | Val acc:[95.48] Test acc:[co:93.12,c:27.12,o:93.06] at epoch:[79]
